[{"title":"Shell 基础语法","date":"2025-09-07T16:00:00.000Z","path":"2025/Linux/Shell基础语法/","text":"Shell 语言的基础语法，包括基础知识（变量、打印、运算符）、流程控制（分支、循环）和模块化（函数封装、文件封装、参数传递）三个部分。 本篇文章是 Shell脚本基础 的增强版。 一、基础知识1.1 变量变量定义1234567891011121314# 使用变量，建议方式$&#123;var&#125;# 在变量名var后是空格时才可用如下方式$var# 字符串的定义var_string=&quot;hello world&quot;# 只读变量declare -r var_namereadonly var_name# 删除变量uset var_name 变量赋值12345678910# 除了显式赋值，也可以将命令的结果存入到变量，如下就是将`ls /etc`的结果存到到了file_arrayfile_array=$( ls /etc )# 也可以使用` 命令 `方式file_array=` ls /etc `# 应用:循环访问文件for file in $( ls /etc )do # do somethingdone 数组变量12345678910111213141516# 数组的定义array_var=(val0 val1 val2)# 单独定义每个元素array_var[0]=val0array_var[1]=val1# 获取所有元素$&#123;array_var[@]&#125;# 获取数组的长度/元素个数$&#123;#array_var[@]&#125;$&#123;#array_var[*]&#125;# 获取单个元素长度$&#123;#array_var[n]&#125; 1.2 打印echoShell 的 echo 指令与 PHP 的 echo 指令类似，都是用于字符串的输出。命令格式： 1echo string 显示普通字符串: echo &quot;It is a test&quot; 这里的双引号完全可以省略（echo It is a test） 显示转义字符 echo &quot;\\&quot;It is a test\\&quot;&quot; 结果将是：”It is a test”，同样双引号也可以省略 显示变量 read 命令从标准输入中读取一行,并把输入行的每个字段的值指定给 shell 变量 1234567#!/bin/shread nameecho &quot;$name It is a test&quot;# 以上代码保存为 test.sh, name 接收标准输入的变量，结果将是:[root@www ~]# sh test.shOK #标准输入OK It is a test #输出 显示换行 echo -e &quot;OK! \\n&quot; # -e 开启转义echo &quot;It is a test&quot; 输出结果： OK! It is a test 显示不换行 #!/bin/sh echo -e &quot;OK! \\c&quot; # -e 开启转义 \\c 不换行 echo &quot;It is a test&quot; 输出结果： OK! It is a test 显示结果定向至文件 echo &quot;It is a test&quot; &gt; myfile 原样输出字符串，不进行转义或取变量(用单引号) echo &#39;$name\\&quot;&#39; 输出结果：$name&quot; 显示命令执行结果（这里因为无法打印出原字符所以加了转义符，实际不需要转义） echo date&#96;&#96;，注意： 这里使用的是反引号&#96;，而不是单引号’。结束时显示日期：Thu Jul 24 10:08:46 CST 2014 printfprintf 命令模仿 C 程序库（library）里的 printf() 程序。printf 由 POSIX 标准所定义，因此使用 printf 的脚本比使用 echo 移植性好。 printf 使用引用文本或空格分隔的参数，外面可以在 printf 中使用格式化字符串，还可以制定字符串的宽度、左右对齐方式等。默认的 printf 不会像 echo 自动添加换行符，我们可以手动添加 \\n。 语法： 12345678910111213141516171819202122232425262728printf format-string [arguments...]# 参数说明# format-string: 为格式控制字符串# arguments: 为参数列表。$ printf &quot;Hello, Shell\\n&quot;Hello, Shellprintf &quot;%-10s %-8s %-4s\\n&quot; 姓名 性别 体重kgprintf &quot;%-10s %-8s %-4.2f\\n&quot; 郭靖 男 66.1234printf &quot;%-10s %-8s %-4.2f\\n&quot; 杨过 男 48.6543printf &quot;%-10s %-8s %-4.2f\\n&quot; 郭芙 女 47.9876&gt;&gt;&gt;姓名 性别 体重kg郭靖 男 66.12杨过 男 48.65郭芙 女 47.99# format-string为双引号printf &quot;%d %s\\n&quot; 1 &quot;abc&quot;# 单引号与双引号效果一样printf &#x27;%d %s\\n&#x27; 1 &quot;abc&quot;# 没有引号也可以输出printf %s abcdef# 格式只指定了一个参数，但多出的参数仍然会按照该格式输出，format-string 被重用printf %s abc def# 如果没有 arguments，那么 %s 用NULL代替，%d 用 0 代替printf &quot;%s and %d \\n&quot; printf 转义序列： 序列 说明 \\a 警告字符，通常为 ASCII 的 BEL 字符 \\b 后退 \\c 抑制（不显示）输出结果中任何结尾的换行字符（只在 %b 格式指示符控制下的参数字符串中有效），而且，任何留在参数里的字符、任何接下来的参数以及任何留在格式字符串中的字符，都被忽略 \\f 换页（formfeed） \\n 换行 \\r 回车（Carriage return） \\t 水平制表符 \\v 垂直制表符 \\ 一个字面上的反斜杠字符 \\ddd 表示 1 到 3 位数八进制值的字符。仅在格式字符串中有效 \\0ddd 表示 1 到 3 位的八进制值字符 1.3 运算符算数运算符 运算符 说明 举例 + 加法 expr $a + $b 结果为 30。 - 减法 expr $a - $b 结果为 -10。 * 乘法 expr $a * $b 结果为 200。 &#x2F; 除法 expr $b &#x2F; $a 结果为 2。 % 取余 expr $b % $a 结果为 0。 &#x3D; 赋值 a&#x3D;$b 把变量 b 的值赋给 a。 &#x3D;&#x3D; 相等。用于比较两个数字，相同则返回 true。 [ b ] 返回 false。 !&#x3D; 不相等。用于比较两个数字，不相同则返回 true。 [ b ] 返回 true。 关系运算符 关系运算符只用于比较数字之间的关系，不支持字符串，除非字符串的值是数字 假定 a &#x3D;10, b &#x3D; 20 运算符 说明 举例 -eq 检测两个数是否相等，相等返回 true。 [ $a -eq $b ] 返回 false。 -ne 检测两个数是否不相等，不相等返回 true。 [ $a -ne $b ] 返回 true。 -gt 检测左边的数是否大于右边的，如果是，则返回 true。 [ $a -gt $b ] 返回 false。 -lt 检测左边的数是否小于右边的，如果是，则返回 true。 [ $a -lt $b ] 返回 true。 -ge 检测左边的数是否大于等于右边的，如果是，则返回 true。 [ $a -ge $b ] 返回 false。 -le 检测左边的数是否小于等于右边的，如果是，则返回 true。 [ $a -le $b ] 返回 true。 布尔运算符假定 a &#x3D;10, b &#x3D; 20 运算符 说明 举例 ! 非运算，表达式为 true 则返回 false，否则返回 true。 [ ! false ] 返回 true。 -o 或运算，有一个表达式为 true 则返回 true。 [ $a -lt 20 -o $b -gt 100 ] 返回 true。 -a 与运算，两个表达式都为 true 才返回 true。 [ $a -lt 20 -a $b -gt 100 ] 返回 false。 逻辑运算符假定 a &#x3D;10, b &#x3D; 20 运算符 说明 举例 &amp;&amp; 逻辑的 AND [[ $a -lt 100 &amp;&amp; $b -gt 100 ]] 返回 false 注意需要两个嵌套的中括号 字符串运算符假定 var1&#x3D;”abc”，var2&#x3D;”efg” 运算符 说明 举例 &#x3D; 检测字符串相等返回 true [ $var1 &#x3D; $var2 ] 返回 false !&#x3D; 检测字符串不相等返回 true [ $var1 !&#x3D; $var2 ] 返回 true -z 检测字符串长度为 0 返回 true [ -z $var1 ] 返回 false -n 检测字符串长度不为 0 返回 true [ -n $var1 ] 返回 true ${} 检测字符串不为空返回 true [ $var1 ] 返回 true 文件测试运算符使用方法：- file_name 操作符 说明 -e 检测文件是否存在 -d 检测目录是否存在 -f 普通文件检测（既不是目录，也不是设备文件） -r 文件可读检测 -w 文件可写检测 -x 文件可执行检测 -b 块设备检测 -c 字符设备检测 -p 有名管道检测 -s 文件大小是否为 0 -S 文件是否是 socket 连接 -L 文件是否存在并且是一个符号链接 -g 文件 SGID 位检测 -u 文件 SUID 位检测 -k 文件粘滞位（Sticky Bit）检测 二、流程控制2.1 分支if-else12345678910111213141516171819202122# ifif condition; then commandfi# 写一行if [ $(ps -ef | grep -c &quot;ssh&quot;) -gt 1 ]; then echo &quot;true&quot;; fi# if elseif condition; then command1else command2fi# if else-if elseif condition1; then command1elif condition2; then command2else commandNfi 分支注意事项： condition 的表示 if else 的 […] 判断语句中大于使用 -gt，小于使用 -lt（数值） 如果使用 ((…)) 作为判断语句，大于和小于可以直接使用 &gt; 和 &lt;。 case … esaccase … esac 为多选择语句，与其他语言中的 switch … case 语句类似，是一种多分支选择结构，每个 case 分支用右圆括号开始，用 两个分号 ;; 表示 break，即执行结束，跳出整个 case … esac 语句，esac（就是 case 反过来）作为结束标记。 1234567891011121314case 值 in模式1) command1 command2 ... commandN ;;模式2) command1 command2 ... commandN ;;esac 如果无一匹配模式，使用星号 * 捕获该值，再执行后面的命令 示例： 123456789101112131415echo &#x27;输入 1 到 4 之间的数字:&#x27;echo &#x27;你输入的数字为:&#x27;read aNumcase $aNum in 1) echo &#x27;你选择了 1&#x27; ;; 2) echo &#x27;你选择了 2&#x27; ;; 3) echo &#x27;你选择了 3&#x27; ;; 4) echo &#x27;你选择了 4&#x27; ;; *) echo &#x27;你没有输入 1 到 4 之间的数字&#x27; ;;esac 2.2 循环循环包括 for 循环、while 循环、无限循环和 util 循环。 for 循环123456789101112131415161718192021for var in item1 item2 ... itemNdo command1 command2 ... commandNdone# 一行for var in item1 item2 ... itemN; do command1; command2… done;# 示例for loop in 1 2 3 4 5do echo &quot;The value is: $loop&quot;done&gt;&gt;&gt;The value is: 1The value is: 2The value is: 3The value is: 4The value is: 5 while 循环12345678910111213141516171819while conditiondo commanddone# 示例#!/bin/bashint=1while(( $int&lt;=5 ))do echo $int let &quot;int++&quot;done&gt;&gt;&gt;12345 无限循环1234567891011121314# 1while :do commanddone# 2while truedo commanddone# 3for (( ; ; )) until 循环12345678910111213141516171819until conditiondo commanddone# 示例#!/bin/basha=0until [ ! $a -lt 5 ]do echo $a a=`expr $a + 1`done&gt;&gt;&gt;01234 三、模块化3.1 函数封装函数格式： 12345678[ function ] funname [()]&#123; action; [return int;]&#125; 说明： 可以带 function fun() 定义，也可以直接 fun() 定义，不带任何参数 参数返回，可以显示加：return 返回，如果不加，将以最后一条命令运行结果，作为返回值。 return 后跟数值 n（范围：0-255） 3.2 文件封装可以将某一部分内容放到一个文件里，作为一个更大的模块的封装。注意在调用该文件执行的时候，是启动了一个子 shell 来对文件进行解释操作的。 3.3 内容传递模块之间的交互主要可以通过管道，参数，文件传递等方式 管道管道方式是在调用多个函数的时候，将前一个命令的输出作为下一个命令的输入。管道传递的内容需要后一个命令具有解析输入的功能，一般后一个命令是 Linux 自带的命令。 参数参数是在函数调用时可能用到的，用于不同模块内容的交互（参入主要是传入模块内容） 参数访问： 在函数体内部，通过 $n 的形式来获取参数的值，例如， $1 表示第一个参数，$2 表示第二个参数… 示例： 1234567891011121314#!/bin/bash# author:菜鸟教程# url:www.runoob.comfunWithParam()&#123; echo &quot;第一个参数为 $1 !&quot; echo &quot;第二个参数为 $2 !&quot; echo &quot;第十个参数为 $10 !&quot; echo &quot;第十个参数为 $&#123;10&#125; !&quot; echo &quot;第十一个参数为 $&#123;11&#125; !&quot; echo &quot;参数总数有 $# 个!&quot; echo &quot;作为一个字符串输出所有参数 $* !&quot;&#125;funWithParam 1 2 3 4 5 6 7 8 9 34 73 参数处理： 使用 for 循环，遍历所有的参数，设置相应的标志位 text12345678910111213# 对所有的参数预处理，得到参数标志arg1_flag=0for arg in $&#123;*&#125;do if [ $&#123;arg&#125; = &quot;arg1&quot; ]; then arg1_flag=1 fidone# 根据参数标志判断是否执行某项操作if [ $&#123;arg1_flag&#125; == 1 ]; then # do somethingfi 参数表示：（对外） 在对外展示 shell 脚本可以处理的参数的时候，需要对可选项等作出表示，shell 命令使用不同的括号来表示不同类型的参数 []：内容可写可不写 {}：必须要从{}中选择一个参数 &lt;&gt;：必选 特殊参数字符： 参数处理 说明 $# 传递到脚本或函数的参数个数 $* 以一个单字符串显示所有向脚本传递的参数 $$ 脚本运行的当前进程 ID 号 $! 后台运行的最后一个进程的 ID 号 $@ 与 $* 相同，但是使用时加引号，并在引号中返回每个参数。 $- 显示 Shell 使用的当前选项，与 set 命令功能相同。 $? 显示最后命令的退出状态。0 表示没有错误，其他任何值表明有错误。 文件传递文件传递方式是将某些文本内容写入到文件，然后另一个命令或者模块利用该文件进行进一步的操作。 文件的用法： 传递内容——写入到文件内容并由另一个模块或者命令读取 设标志位——作为一个同步标志，控制运行流程 参考【1】Shell 教程 【2】括号中的可选、必选表示","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.delta1037.cn/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://www.delta1037.cn/tags/Shell/"}]},{"title":"系统论八大原理和思考","date":"2025-09-06T16:00:00.000Z","path":"2025/System/系统论八大原理和思考/","text":"利用结构特征分解系统；利用行为特征分析系统边界；利用演化特征分析系统内部演化；利用整体特征做系统类比分析，利用模式快速分析新系统 一、八大原理1.1 整体性（1+1&gt;2）系统的整体功能不等于各部分的简单相加，而是通过相互作用产生新的特性（涌现性）。 解释涌现性：系统在整体层面出现新的性质，无法从单个部分预测 大脑：单个神经元只能传递电信号，但数十亿神经元组合就能产生意识、思维。 蚁群：单只蚂蚁行为简单，但整个蚁群能建造复杂巢穴、分工协作。 市场经济：单个消费者和企业的决策相互作用，形成价格波动和经济周期。 示例 企业管理： 各部门（研发、生产、销售）单独运作效率有限，但协同合作能推出爆款产品。 失败案例：诺基亚各部门各自优化，但缺乏整体协调，最终被智能手机淘汰。 城市规划： 交通、住房、商业区单独规划可能导致拥堵，整体优化才能提高城市运行效率。 1.2 层次性（系统嵌套系统）系统由多个层次组成，高层次支配低层次，低层次支撑高层次。 解释 自然界： 原子 → 分子 → 细胞 → 组织 → 器官 → 生物体 → 生态系统 例如：DNA（分子层）控制蛋白质合成（细胞层），进而影响器官功能。 社会系统： 个人 → 家庭 → 社区 → 城市 → 国家 → 全球社会 示例 组织管理： 公司架构：CEO（战略层）→ 部门经理（管理层）→ 员工（执行层）。 失败案例：如果高层过度干预底层执行（如微软早期“层级过多”导致创新停滞）。 软件工程： 操作系统（底层）→ 应用程序（中层）→ 用户界面（高层）。 优化案例：Linux 采用模块化设计，各层独立优化，提高稳定性。 1.3 开放性（系统必须与外界交换）封闭系统会走向混乱（熵增），开放系统通过输入输出维持稳定。 解释 物理系统： 热水瓶是封闭系统，热量逐渐散失（熵增）。 人体是开放系统，通过进食、呼吸维持生命（负熵流）。 经济系统： 闭关锁国的国家经济衰退（如清朝）。 改革开放的国家经济增长（如中国 1978 年后）。 示例 企业管理： 封闭企业（如柯达）拒绝数码技术，最终破产。 开放企业（如苹果）整合外部技术（触屏、ARM 芯片）成功。 个人成长： 封闭学习（只读课本） vs. 开放学习（实践、交流、跨学科）。 1.4 目的性（系统有目标导向）系统行为趋向某个目标，可能是自组织（自然系统）或他组织（人工系统） 解释 自组织目的： 生物进化（适者生存）、市场经济（利润最大化）。 他组织目的： 机器（按程序运行）、公司（按战略目标执行）。 示例 AI 训练： 强化学习（AlphaGo）通过目标（赢棋）自我优化策略。 政策制定： 政府设定“碳中和”目标，引导企业调整能源结构。 1.5 突变性（量变 → 质变）微小变化积累到临界点，系统突然进入新状态。 解释 自然界： 水加热到 100℃ 突然沸腾（相变）。 地震（板块应力积累到临界点突然释放）。 社会系统： 股市崩盘（投资者恐慌情绪积累到临界点）。 示例 商业创新： 数码相机技术积累多年，最终突然淘汰胶卷（柯达破产）。 社会运动： 阿拉伯之春（长期压迫导致突发动荡）。 1.6 稳定性（负反馈维持平衡）系统通过自我调节抵抗干扰，保持动态平衡。 解释 生物系统： 人体体温恒定（出汗&#x2F;发抖调节）。 经济系统： 通货膨胀时央行加息抑制过热。 示例 供应链管理： 丰田“Just-in-Time”生产 + 安全库存，平衡效率与稳定性。 生态保护： 引入天敌（如澳洲用狐狸控制兔子泛滥）。 1.7 自组织（无序 → 有序）解释 自然界： 雪花结晶、蜂巢结构。 社会系统： 语言演化、比特币（去中心化货币）。 示例 企业管理： 谷歌“20% 时间”政策，让员工自发创新（Gmail、AdSense 由此诞生）。 城市规划： 传统规划（政府主导） vs. 自组织城市（如东京小巷自然形成商业区）。 1.8 相似性（跨系统共性）不同系统可能遵循相同规律。 解释 分形： 树枝、血管、河流分支模式相似。 网络科学： 互联网、社交网络、神经网络都有“小世界”特性。 示例 商业策略： 借鉴生态系统“共生”概念，建立企业联盟（如英特尔 + 微软 Wintel 联盟）。 AI 设计： 神经网络模仿人脑神经元连接方式。（或许是人类根据现有的物理规律导致的结果推导出相似的可行的系统，如果只是凭空想象，不深入理解底层逻辑，很难构造出类似的系统。毕竟现有的系统是经过超长时间演化来的。人类对底层还是了解太少了） 二、思考2.1 原理分类 结构特征：描述系统的构成方式 整体性：系统与部分的关系。系统由部分组成，但是大于部分 层次性：系统的嵌套结构。大系统中可以划分小系统 行为特征：描述系统行为（对外，边界） 开放性：与环境的交互 目的性：行为的方向性 演化特征：描述系统演化（内部变化） 突变性和稳定性：演化的矛盾统一 自组织：无序到有序的机制 整体特征：全局上 相似性：系统和系统之间是相似的（或许是因为底层物理规律是一样的） 利用结构特征分解系统；利用行为特征分析系统边界；利用演化特征分析系统内部演化；利用整体特征做系统类比分析，利用模式快速分析新系统","tags":[{"name":"系统论","slug":"系统论","permalink":"https://www.delta1037.cn/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BA/"}]},{"title":"面试-算法 Hot 100","date":"2025-09-04T16:00:00.000Z","path":"2025/Algorithm/面试-算法Hot100/","text":"LeetCode Hot 100 题目记录 LeetCode 热题 100 哈希 1. 两数之和：使用字典保存出现过的数字及其坐标，判断 target - new_val 是否在集合里即可 49. 字母异位词分组：将字符串排序，作为 key，将相同 key 的字符串存储成列表（主要就是排序后的字符串 ss 作为 key） 128. 最长连续序列：将数组放到集合里，判别起始数字开始的最大长度（判断是否是起始数字可以看上一个数字在不在集合里） 双指针 283. 移动零：使用 gap 统计 0 的个数，也就是向前覆盖的差值，最后将末尾赋值成 0 就可以了 11. 盛最多水的容器：设置左右两个指针，向内收缩两边高度较小的一个，维护这个过程中的盛水容量最大值（原理：较小的指针不会再作为容器边界） 15. 三数之和：坐标 i 维护最左侧数字位置，l 和 r 在右侧区间找和为 target 的两个数字，并跳过相同的数字 42. 接雨水：维护单调减栈，如果出现单调增，计算形成的空区间（栈顶为底，弹出后的栈顶作为左位置，待 push 元素作为右位置）能够装的雨水量 滑动窗口 3. 无重复字符的最长子串：维护字母统计窗口，使用双指针维护滑动窗口内不会出现重复的字符，记录双指针之间的最大距离 438. 找到字符串中所有字母异位词：统计待匹配字符串的 p_counter，统计被匹配字符串 s 的 n 个值（滑动窗口初始化），依次移动 s 上的滑动窗口（维护滑动窗口），判断 s_counter 是否等于 p_counter 即可 字串 560. 和为 K 的子数组：记录前缀和，两个前缀和相减等于 target，将前缀和保存成字典即可（需要记录指定前缀和的数量） 239. 滑动窗口最大值： 76. 最小覆盖子串：对目标串建立字典，使用双指针，移动 r 的过程看是否满足字典匹配（check），如果匹配开始移动 l，记录 l 的最右位置，记录此时 l 与 r 之间的距离，并保存最小距离时的字串 普通数组 53. 最大子数组和：动态规划，dp[i] &#x3D; max(nums[i], dp[i-1]+nums[i])，也就是前一个是负数就不加入到后续的最大和子数组了 56. 合并区间：逐个判断是否能与上一个 merged 区间合并，如果合并不了将上一个 merged 区间归档 189. 轮转数组：旋转三次，注意 k 对 n 取模即可 238. 除自身以外数组的乘积：从左向右递乘LR，从右向左递乘RL，然后记录 LR[i-1]* RL[i+1]（注意边界即可） 41. 缺失的第一个正数： 矩阵 73. 矩阵置零：统计横向为 0 的 set 和 纵向为 0 的 set，遍历两个 set 分别设置对应行或者列为 0 54. 螺旋矩阵：一共 n * n 个元素，设置四个轮转方向，遇到 flag 就转向（flag 可以设置为一个最小值 - 1） 48. 旋转图像：四个值轮转（找四个特殊点计算关系） 240. 搜索二维矩阵 II：类似于二分查找树，右上角作为根节点 链表 160. 相交链表：统计长度，让长的链表先移动，等长之后一起移动（移动前判别节点是否相等） 206. 反转链表：使用 pre 节点记录上一个，使用 p 记录本节点（初始化为 head ），逐个处理即可 234. 回文链表：链表计数，反转后半部分，使用快慢指针逐个判别 141. 环形链表：使用快慢指针判断（先转移指针，在判断是否是相同的指针） 142. 环形链表 II：使用快慢指针判别，重置 f 指针，一步一步移动直到相等（需要排除节点个数小于1且没有环的情况） 21. 合并两个有序链表：选择较小的逐个合并即可 2. 两数相加：reverse 两个数字，节点逐个相加（节点合并，短链表合到长链表上），然后再 reverse 回来 19. 删除链表的倒数第 N 个结点：统计链表长度 L，设置 p 移动 L - N - 1 长度，然后跳过下一个节点即可 24. 两两交换链表中的节点： 25. K 个一组翻转链表 138. 随机链表的复制： 148. 排序链表：归并排序思想（对子链表统计长度，分成两部分，分别排序） 23. 合并 K 个升序链表：ListNode.lt &#x3D; lambda a, b : a.val &lt; b.val，定义节点的比较函数，使用堆对链表头节点排序 146. LRU 缓存： 二叉树 94. 二叉树的中序遍历：递归进行中序遍历即可；非递归，使用栈保存节点（cur指针一直往左，否则弹出节点往右移动一个，记录弹出节点的值） 104. 二叉树的最大深度：层次遍历，记录最大层数；递归方法，向上返回左右节点深度 226. 翻转二叉树：空时返回，否则递归反转左右并赋给右左 101. 对称二叉树：当前节点值判别 + 四个节点两两对应的判别 543. 二叉树的直径：当左右节点都是 None 时，返回直径为 0，否则计算非空左右的直径，相加即为总直径（保存最大值），向上返回最大直径 102. 二叉树的层序遍历：使用队列逐层遍历即可 108. 将有序数组转换为二叉搜索树：构建build函数，传入中序左右位置，每次选中间节点作为根节点，逐级构建 98. 验证二叉搜索树：中序遍历，判断元素是否是严格递增的 230. 二叉搜索树中第 K 小的元素：中序遍历，取 k - 1 199. 二叉树的右视图：层序遍历，每次取最后一个 114. 二叉树展开为链表： 105. 从前序与中序遍历序列构造二叉树：前序第一个节点是中间节点，找到该节点在中序中的位置 &amp; 计算左子树大小 &amp; 前序遍历拆分 &amp; 中序遍历拆分，分别构建左右子树即可 437. 路径总和 III：记录路径的前缀和字典（前缀和个数），判断target - 当前前缀是否在前缀和字典里，并统计数量即可（注意退出当前节点需要删除当前的前缀和） 236. 二叉树的最近公共祖先：自底向上收缩树，遇到 None 和 p q 向上收缩，判断当前节点的左右情况，如果一边为 None，祖先（或者p q）在另一边，如果两边都不是 None，说明当前节点就是祖先，向上返回即可 124. 二叉树中的最大路径和：返回左右路径与 0 相比的最大值，计算左右路径与根节点相加的路径和（记录这个过程中的最大值） 栈 84. 柱状图中最大的矩形：单调增栈，确定每一个元素的左右边界（遇到减的元素，当前元素就是栈顶的右边界；加入元素前，栈顶元素就是当前元素的左边界） 多维动态规划 139. 单词拆分：i 是字符串目标位置，j 是字符串切分起始位置，判断 j 处是否能切分，如果能切分，更新 i 位置能否切分 140. 单词拆分 II：i 是字符串目标位置，j 是字符串切分起始位置，判断 j 处是否能切分，如果能切分，更新 i 位置的切分字符串，并更新 i 位置是否能切分（带记录的动态规划）","tags":[{"name":"算法","slug":"算法","permalink":"https://www.delta1037.cn/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"面试-算法基础","date":"2024-12-03T16:00:00.000Z","path":"2024/Project/面试-算法基础/","text":"记录算法基础内容：数据结构基础、一些比较重要的题目、问的较多的原理和 Python 刷算法的基础操作。 基础参考算法通关手册（LeetCode） 算法题目 记录一些比较重要的题目 数组： 1. 两数之和：使用 hash 表来存储其中一个数字，然后找另一个数字即可 15. 三数之和：第一层循环作为第一个数字（跳过相同的数字），后边使用双指针，查找三数相加等于 0 的元组（在等于 0 的条件内部，双指针跳过相同的数字） 415. 字符串相加：逆序，逐个字符处理即可 28. 找出字符串中第一个匹配项的下标：KMP 算法，先生成 next 数组，然后再根据 next 数组来判别匹配的大小 5. 最长回文子串：最长回文（马拉车或者动态规划），动态规划方法单独考虑两个字符相邻的情况（i 从小到大，j从大到小） 912. 排序数组：快速排序实现（设置 flag，从右侧找小于 flag 填到 flag_idx_l，从左侧找大于 flag 填到 flag_idx_h，最后将 flag 回填） 215. 数组中的第 K 个最大元素：快速排序的应用，只排需要的部分（这个题可能要用三路快排，要不然有一个变态样例过不了） 347. 前 K 个高频元素：Top-K，先统计频率，再使用优先队列排序 128. 最长连续序列：构建 hash 表，遍历元素找到以该元素为起点的最长连续序列（起点判断方法是看上一个元素在不在，如果有上一个元素则该元素就不是起点） 链表： 21. 合并两个有序链表：创建新的头 h 和移动 p，依次续上两个链表中值比较大的节点（选择节点后并向后移动游标） 328. 奇偶链表：创建两个链表，分成奇节点和偶节点续上，最后将其中一个链表续到另一个末尾 92. 反转链表 II：设置游标 + 上一个节点指针，逐个逆转即可 25. K 个一组翻转链表：循环，判断位置并截断，子函数反转，再对接到新链表上 142. 环形链表 II：快慢指针判断是否有环；将 slow 重置到 head，再一步一步走，与 fast 相遇的时候就是环的入口 二叉树： 236. 二叉树的最近公共祖先：向上传递 NULL 或者目标节点或者祖先（三种情况），递归操作，如果一边为 NULL 则肯定在另一边（另一边可能也没有），如果两边都不是 NULL（p 和 q 就是从两边传上来的） 则说明本节点就是祖先 226. 翻转二叉树：每个节点交换左右子树即可（递归操作） 687. 最长同值路径：分别判断左右最长，然后合并求跨当前节点最长；向上返回左右最长之一（注意最长路径是边数，不是节点数） 501. 二叉搜索树中的众数：二叉搜素树中序遍历是是有序的数组 124. 二叉树中的最大路径和：DFS 遍历，记录左右节点的值与 0（忽略子节点） 相比的较大值，计算左右与当前节点相加的值并记录最大值，向上返回根节点+左右节点中的较大值 LCR 145. 判断对称二叉树：check 当前节点是否相等，递归遍历左与右对比，右与左对比 二叉树遍历：前序、中序、后续（递归 or 非递归——使用栈）；层序——队列 二叉树还原：中序 + 前序或者后续；如果是前序 + 后续则存在多种情况 平衡二叉树：树的高度平衡（旋转方法，也就是代码中的操作流程） 红黑树：相对平衡二叉树（AVL）旋转次数变少，效率更高（增加、删除操作比查找操作多的情况下） 手写子典树：树节点分叉（分叉类型，可以是字母类型，边上代表字母） + 终止标记（标记单词结束）子典树 图： 207. 课程表：map 记录 next，数组记录入度；首次将入度为 0 的节点加入到队列，依次处理队列，处理 map 中该值并修改入度数组，将新入度 0 加入到队列；判断入度数组是否全为 0 即可 547. 省份数量：并查集（并查集，记住基本函数即可）。初始省份数量是节点个数，每次进行合并操作减 1。 1971. 寻找图中是否存在路径：并查集（并查集，记住基本函数即可）。如果存在路径，则起始和结束节点属于同一个根节点 695. 岛屿的最大面积：深度优先搜索，搜索过的点设置为 0（标记）。转向序列（{0，1}，{1，0}，{0，-1}，{-1，0}） 动态规划 &amp; 贪心： 2435. 矩阵中和能被 K 整除的路径：二维动态规划，将 mod 值作为第三个状态 300. 最长递增子序列：简单动态规划 121. 买卖股票的最佳时机：记录最小值，计算与最小值之间的差值 122. 买卖股票的最佳时机 II：记录每一段上升区间 53. 最大子数组和：动态规划，记录某个位置结尾数组和，找到最大值 回溯： 93. 复原 IP 地址：回溯方法，查找起点开始的 1-3 个字符，判断是否是有效字符，追加到总 path 里 栈 &amp; 队列： 20. 有效的括号：栈操作（如果不用栈怎么解决？） 接雨水：维护单调递减栈，遇到增量值时拿出来计算与左挡板距离，和底部元素高度差 两个栈实现队列：两个栈倒来倒去就可以了 两个队列实现栈：用辅助队列实现弹出操作（出队直到剩余一个，即弹出的数据） 设计： 146. LRU 缓存：map 存储 key 和 Node* 的映射关系，方便快速找到 Node*；双向链表维护节点访问顺序（如果节点超了就从末尾删一个）。 get（没有返回-1；访问到挪到双向链表头部）；put（没有，添加进去，并判断容量，删除超的；有，更新，挪到头部） 带过期时间的 LRU 算法：将过期时间使用另一个 map 来维护（put 和 get 分别判断过期和重置过期时间）；可以使用一个额外的线程来惰性删除 460.LFU 缓存：最近最少次数使用（将双向链表改成优先队列？） 224. 基本计算器：使用栈来表示当前括号层次的符号，遇到左括号则保存符号到栈，遇到右括号则弹出符号，本质上是表示各层次括号外部的符号 其它： 题目：有一个长度 100 的 01 数组，可以反转 K 个1成为0，求解反转后的最大连续0的长度 解法：滑动窗口算法，统计窗口内1 的数量并记录窗口的最大长度 算法原理哈希表： 哈希算法：加法哈希、乘法哈希、异或哈希、旋转哈希 哈希冲突：链表法（相同的节点后面加链表）；开放寻址法（向后找一个空位置） 红黑树与 AVL 树对比： 红黑树是没那么平衡的平衡树，是查找效率与插入效率的折中 算法操作Python 算法基础操作： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# 列表copy_list = a[:]reverse_list = a[::-1]# 字典d = collections.defaultdict(int)# 计数s_c = Counter(s)# 栈sta = []sta.append(val)val = sta.pop()# 队列q = deque()q.pop()q.popleft()q.append(val)q.appendleft(val)# 集合s = set()s.add(val)s.discard(val)s.remove(val)v = s.pop()# 有序集合from sortedcontainers import SortedLists.add()# 堆import heapq# 默认小顶堆，加负号成大顶堆heap = []heapq.heappush(heap, val)val = heapq.heappop(heap)# node 自定义小于比较器ListNode.__lt__ = lambda a, b : a.val &lt; b.val# 输入处理num = int(input())num_list = [list(map(int, input().split())) for _ in range(lines)]","tags":[{"name":"算法","slug":"算法","permalink":"https://www.delta1037.cn/tags/%E7%AE%97%E6%B3%95/"},{"name":"Python","slug":"Python","permalink":"https://www.delta1037.cn/tags/Python/"}]},{"title":"面试-基础知识","date":"2024-12-03T16:00:00.000Z","path":"2024/Project/面试-基础知识/","text":"记录面试的基础知识（要点速记），用于面试前的速览（临阵磨枪） 一、操作系统Linux 进程进程和线程：进程（资源分配单位）、线程（最小调度单位） 线程：创建开销小、上下文切换快 线程和协程：协程是用户级轻量级线程，没有内核态切换开销 C++ 20 协程：一种特殊的可重入函数（挂起或者恢复运行） 进程和程序：进程（程序的一次执行过程、动态）、程序（静态，代表算法实体） 进程状态：创建、就绪、运行、阻塞、停止 运行-&gt;就绪：时间片用完 or 被高优先级进程抢占 运行-&gt;阻塞：IO 请求 or 等待资源 or 等待事件 孤儿进程、僵尸进程： 孤儿进程：父进程挂，子进程被 init 收养 僵尸进程：子进程挂，父进程没回收子进程 解决：杀死父进程；建立子进程时就脱离父子关系（fork 两次，运行孙子，关闭父亲：手动制作孤儿） 进程间协作关系：通信（交换数据）、互斥（处理资源竞争）、同步（协调点） 通信：共享内存、消息队列、Socket、管道、信号 共享内存同步：信号量 互斥：互斥锁（自旋锁、读写锁）、信号量 互斥锁：用于保护共享资源，确保同一时刻只有一个线程可以访问资源 信号量：控制对有限数量资源的访问，允许同时访问资源 同步：信号量、条件变量、事件、屏障 线程安全： 本质：存在资源共享 &amp; 数据竞争，原子性问题（操作不能原子性的完成） 解决：同步机制，原子操作 进程切换过程：保存上下文、更新 PCB、新进程 + 更新 PCB、更新内存数据结构 进程管理： 进程描述：PCB &#x3D;&#x3D; task_struct 进程管理：进程描述节点构建成进程队列，根据队列在 CPU 上调度 进程调度：调度的对象就是 task_struct，使用调度器（Deadline 调度器 &gt; RT 调度器 &gt; CFS 调度器）调度 进程绑定：将进程绑定到指定的 CPU 核心上运行 作用：减少调度开销 亲和性：软亲和性、硬亲和性 操作：命令（taskset）；API 接口（sched_setaffinity、sched_getaffinity） 锁类型：互斥锁、自旋锁、读写锁、自适应锁（尝试获取一定次数，获取不到就休眠；互斥和自旋的折中选择） 锁的实现原理： 互斥锁：使用 CAS，如果 swap 不成功，则线程进入队列同等优先级队列末尾（休眠） 自旋锁：通过 TAS，设置 flag 原子操作实现： 硬件指令：TAS（Test-and-Set）、CAS（Compare-and-Swap）、Fetch-and-Add、Exchange 自旋锁：底层是 TAS 互斥锁：底层是 CAS 信号量：底层是 Fetch-and-Add 和 Fetch-and-Sub CAS：原子的更新值，等于预期值才更新 问题：ABA 问题（无法识别这种情况） 死锁四个必要条件： 互斥条件：资源一次只能被一个进程使用 不可抢占：资源不能被强制剥夺 占有等待条件：占有资源的同时等待其它资源 循环等待条件：等待进程形成循环链 死锁问题： 死锁避免：按照顺序加锁（避免死锁）；银行家算法 死锁处理：设置锁的获取时间上限（主动放弃策略）；监测并中断线程——看门狗（被动放弃策略，丢失上下文，处理结构做反馈处理） 场景-三个线程轮流打印：使用锁 + 条件变量，条件变量控制轮到那个线程打印数据（打印后更新要打印的线程 id），notify 其它线程 12345678910111213141516171819202122232425#include &lt;mutex&gt;#include &lt;condition_variable&gt;std::mutex mtx;std::condition_variable cv;int current = 0; // 当前应该打印的线程编号void printNumber(int id, int total) &#123; for (int i = 0; i &lt; total; ++i) &#123; std::unique_lock&lt;std::mutex&gt; lock(mtx); cv.wait(lock, [id] &#123; return current == id; &#125;); std::cout &lt;&lt; &quot;Thread &quot; &lt;&lt; id + 1 &lt;&lt; &quot;: &quot; &lt;&lt; (id + 1) &lt;&lt; std::endl; // 更新当前应该打印的线程编号 current = (current + 1) % 3; // 通知下一个线程 cv.notify_all(); &#125;&#125;std::thread t1(printNumber, 0, total);t1.join(); 多核一致性： 缓存与内存一致性：写直达（同时写内存和缓存）、写回（写缓存） 缓存一致性：总线嗅探 + MESI 协议（降低总线压力） Linux 内存局部性原理：（缓存、内存、文件系统、数据库） 时间局部性：较短的时间间隔，程序会访问同一个位置 空间局部性：较短的时间间隔，程序会访问相邻的位置 虚拟内存结构：内核空间、栈、文件映射与匿名映射（内存映射区、动态链接库）、堆、BSS（未初始化的）、数据段（初始化的）、代码段。Linux 物理内存管理 变量存储区：BSS 段存储了未初始化的全局变量（或者初始化为0的）；数据段存储了初始化的全局变量（初始化不为0） 分段：权限管理 虚拟内存： 段页式：（段选择再分页：逻辑地址、线性地址、物理地址） TLB 缓存，与 MMU 模块交互 虚拟地址转物理地址： 步骤：虚拟地址分解（页号+页内偏移）、查找页表（根据页号获取物理页帧号，可能是多级的页表）、生成物理地址（物理页帧号 X 页大小 + 页内偏移） 多级页表：减少页表占用内存空间（按需加载部分的页表） TLB：（Translation Lookaside Buffer）加速地址转换的缓存（MMU中的），缓存了最近使用的映射关系 物理页不存在：进行页面置换，将页从磁盘加载到物理内存 虚拟内存比物理内存大： 机制：分页机制（不是所有的页都在物理内存）；内存交换（换出不适用的页） 页面置换： 算法：FIFO（先进先出）、LRU（最近最少使用：实现略复杂）、LFU（最不经常使用：可能导致新页面会置换） 虚拟内存作用：隔离保护、共享内存、简化程序设计（无需关心实际分布）、支持大内存、提高内存利用率 线程内存： 共享：文件等公用资源、堆、数据段（全局变量和静态变量）、代码段 独享：栈 进程 fork：拷贝 PCB（父进程的一个副本），子进程独占代码段、数据段和堆栈内存（一开始共享，写操作才为子进程分配内存空间（COW）） fork 后父进程返回子进程 ID（用于追踪子进程）；子进程返回 0（区分父子进程） fork 配合 exec：exec 将替换现有的程序，相互配合用来创建新进程 COW：推迟或者避免数据拷贝（redis 用来创建内容映像） clone：可以指定在创建新进程时指定哪些资源共享或者哪些资源复制（适用于创建线程，或者细粒度控制资源共享的场景） 栈帧： 作用：支持函数调用和返回 内容：局部变量、参、返回地址 Linux IOIO 模型：阻塞、非阻塞、IO 多路复用、信号驱动、异步 IO（aio、io_uring） 异步 IO：发起 IO 操作之后可以去干别的事 作用：允许应用同时处理多个请求；不需要多余的操作（不断观察状态之类的，即非阻塞的情形） 多路复用：提高 I&#x2F;O 操作效率的机制（目标端：一个进程能同时监听多个文件描述符；源端：非阻塞 IO 大量发起系统调用） select：数量有限（1024-32、2028-64）、轮询查找就绪 fd，效率低、fds 集合拷贝，高并发不适用 poll：解决了数量有限问题、无需每次重建 fds 集合 epoll：红黑树跟踪 fds、事件驱动机制，返回就绪 fd，无需再轮询 零拷贝技术： 通用场景 DMA：负责将数据从磁盘搬到内存（减轻 CPU 负担），CPU 告诉 DMA 搬运细节 文件传输：零拷贝技术 流程：磁盘 -&gt; 内核 -&gt; 用户 -&gt; socket -&gt; 网卡 mmap + write：mmap 后用户空间和内核空间共享文件缓冲区，write 时从文件缓冲区搬运到 socket 缓冲区（CPU）；mmap 映射和 socket 搬到网卡都是 DMA sendfile：磁盘到内核缓冲区（DMA），缓冲区描述传递给 socket 缓冲区，SG-DMA 将内核缓冲区拷贝到网卡缓冲区 Linux 内核Linux 启动：BIOS&#x2F;UEFI，BIOS 读取 MBR，读取主引导记录找到激活的主分区，MBR 将控制权交给 PBR （Grub），Grub 一阶段（准备硬件）、Grub 二阶段（准备内核）、内核引导（使用 initramfs（或者 initrd.img） 中的驱动程序和工具来挂载真正的根文件系统），系统初始化 内核态、用户态：内核态运行系统与硬件交互；用户态运行用户程序 目的：防止用户进程误操作或者恶意破坏操作系统 切换：系统调用、异常、外部设备中断 减少系统调用（减少切换过程，提高性能）：无锁编程、协程（单线程内部调度） 内核态、用户态切换过程：保护用户态上下文，切换到内核态，执行系统调用，恢复用户态上下文，返回用户态 存储系统：虚拟文件系统、设备映射器、通用块层、IO 调度程序、块设备驱动 Linux 编程链接库： 动态链接库：运行时加载 作用：减少可执行文件大小；提高可重用性，减少内存空间占用，即多个进程共享动态链接库；动态更新依赖库文件 链接：指向库文件的符号引用和重定位信息 运行：.dynamic 查找和加载依赖的库文件，解析可执行文件中的符号引用 静态链接库：编译器加入到可执行文件中 调优：追踪系统调用、性能优化命令 嵌入式中断：事件触发，暂停当前程序，转而处理事件 中断类型：软件中断、硬件中断、定时器中断、异常中断 中断流程：中断请求、中断响应、中断服务、中断返回 中断优先级：用于决定多个中断请求同时发生的情况，高优先级优先处理 避免中断嵌套：禁用中断、设置中断优先级 中断向量表：中断服务地址，发生中断时，根据中断号查找向量表，跳转到对应的程序入口执行 嵌入式存储介质： Flash Memory：例如 eMMC（系统存储） SD 卡：系统存储区 RAM：DRAM 和 SRAM voatitle 关键字：应用场景（防止编译器对变量的优化，即编译器假设该值不会发生改变） 硬件寄存器访问：值可能被外部修改，随时读取最新的值 中断服务程序：中断中修改值，循环中需要及时获取到改值的改动 多线程环境：与中断差不多 二、计算机网络基础七层模型：物理层、数据链路层、网络层、传输层、会话层、表示层、应用层 四层模型：网络接口层、网际层、运输层、应用层 常见协议： 网络层：IP、ICMP、ARP、RARP 传输层：TCP、UDP 应用层：HTTP、DNS、FTP、SMTP 大小端：多字节数据的字节顺序。右侧为小，左侧为大（用指针法判别；或者预定义的宏） 网络协议分层：简化网络通信复杂性，提高系统可维护性和可扩展性。网络设计和实现更加模块化、标准化和易于管理 物理层：物理介质传输 链路层：比特流封装成帧 网络层：包的路由和转发 传输层：端到端的数据传输 会话层：管理不同设备之间的会话（建立、维护和终止） 表示层：数据格式转换、加密和压缩 应用层：提供网络服务和应用程序之间的接口，处理用户请求和响应 中间人攻击： 防止：加密通信、VPN、多因素认证 TCP&#x2F;UDP区别： TCP：可靠、面向连接、字节流传输、全双工、流量控制、拥塞控制 可靠性：序列号+确认号；超时重传+快速重传；校验和 UDP：不可靠、无连接、报文传输、多对多（包含点到点） 最大长度：2^32&#x3D;65535-20；超过最大长度 sendto 会报错（IP层会分片，由 IP 层负责分片和聚合） 三次握手： 握手流程：客户端发送初始序列号，服务端确认序列号 &amp; 发送自己的序列号，客户端确认服务端序列号 为什么三次（不是两次）：防止重复历史连接（主要，旧SYN连接），同步双方序列号 第三次丢失：服务端重传 SYN-ACK（ACK 是不会重传的） SYN 攻击：把半连接队列打满 解决：增大半连接队列；减少 SYN-ACK 重传次数；记录 IP，丢弃重复请求 每次序号不一样：防止重放攻击和序列号预测；多个连接时避免混淆 四次挥手： 挥手流程：一端主动关闭，发送请求（FIN_WAIT_1）；对端收到发送确认（对端切换到 CLOSE_WAIT，另一端收到确认切换到 FIN_WAIT_2）；对端发送关闭请求（自己切换到 LAST_ACK）；一端回复确认，切换到 TIME_WAIT（等待 2*MSL 关闭连接） 为什么等待 2*MSL：连接可靠性，防止对端没收到重发关闭请求 为什么需要四次：优雅关闭连接 为什么需要 TIME_WAIT：可靠的实现全双工连接终止；允许旧连接数据在网络中消逝 合并成三次（② 和 ③ 合并）：服务端没有数据要发送 + 开启了 TCP 延迟确认机制 流量控制：（作用于接收者）通过滑动窗口控制发送方的流量；接收方反馈自己的状态让发送方调整滑动窗口大小 拥塞控制： （作用于网络）通过拥塞窗口控制发送速率，窗口通过网络拥塞程度调整 慢启动、拥塞避免；快速重传，快速恢复 监听同一个端口： 主进程 + work 子进程（惊群问题，Nginx 使用 accept_mutex 锁解决）：主进程执行 bind()、listen() 初始化套接字，然后 fork 新的子进程。在这些子进程中，通过 accept&#x2F;epoll_wait 同一个套接字来进行请求处理 多进程 + SO_REUSEPORT： 目的：内核级的负载均衡；用于滚动升级（发送信号给旧进程不再处理请求） HTTP&#x2F;HTTPSHTTP 连接过程：URL 处理、DNS 查询（浏览器缓存、本地、DNS 请求）、建立连接发送请求、接收响应、呈现页面 请求报文：请求行、请求头、空行、请求体 响应报文：状态行、响应头、空行、响应体 HTTP 请求方法：GET、POST、OPTION、HEAD、PUT、DELETE GET：用于请求数据，URL传递参数（安全性低，长度限制），幂等的 POST：用于提交数据，请求体传递参数，非幂等（可能） HTTPS 加密过程：获取公钥证书、验证证书、发送会话密钥（公钥加密）、使用会话密钥建立加密连接 HTTPS 连接过程：先三次握手建立连接，再走 TLS 握手（加密连接过程），使用会话密钥建立加密连接 Session、Cookie、Token： Session：服务器保存的结构，跟踪用户状态 Cookie：客户端保存用户信息机制，是 Session 的一种实现 Token：令牌，服务端用来判断是哪个用户 HTTP 版本： HTTP 1.0：短连接（每次请求建立一次TCP连接），不支持流水线（一次只能发送一个请求） HTTP 1.1：持久连接（一个TCP连接上可以发送多个请求和响应），支持流水线（一次发多个请求） HTTP 2：二进制传输，多路复用、头部压缩 HTTP 3：基于 QUIC（基于UDP的可靠传输） QUIC：可靠 UDP 方案（数据包确认+重传机制），确认方法是乱序确认（通过offset 拼接数据） DNSDNS 查询过程：（递归 + 迭代），与本地域名服务器是递归查询的过程；本地域名服务器到根域名服务器或者顶级域名服务器是迭代查询的过程（减轻顶级域名服务器或者根服务器的压力） 三、数据库缓存Redis 持久化策略：AOF、RDB AOF：文件大；恢复慢；实时性高 RDB：文件小；恢复快；实时性低 数据库概念BTree 索引和 B+Tree 索引： B+Tree 非叶子节点不存储数据 聚簇索引和非聚簇索引： 聚簇索引：索引和数据放到一起存储，叶子节点保留了数据行 优缺点：减少磁盘 IO；插入速度依赖插入顺序 非聚簇索引：索引和数据分开存储，叶子节点存储了指向数据的指针 索引覆盖：从非主键索引树上就能查到数据，无需进行二次主键索引树查找 联合索引：遵循最左原则 四大范式： 1NF：无重复的列 2NF：属性完全依赖主键 3NF：属性不依赖于其它非主属性 4NF：禁止主键列和非主键列一对多关系不受约束 数据库优化数据库结构优化： 范式优化：表设计合理化（3NF），消除冗余（节省空间） 反范式优化：适当增加冗余（减少 JOIN） 拆分表：减少全表扫描，缩短查询时间（按月分表） SQL 语句优化： where 语句： 避免 !&#x3D; 和 &lt;&gt; 操作（将全表扫描） 避免堆字段 null 判断（将全表扫描） 创建索引（经常判别的字段） 慢日志记录：mysqldumpslow 分表、分区： 场景：超大表，SQL 语句已经无法继续优化 操作： 分表：手动将数据分割，创建子表 分区：自动将数据散列，没有子表 读写分离： 场景：小幅提升写性能，大幅提高读性能 操作：依赖于数据库的主从复制，主数据库处理写，从数据库处理读（将SQL通过逻辑判断或者中间件选择读写数据库执行语句） 存储过程： 定义：SQL 语句和控制语句的预编译集合，保存在数据库中，可以调用执行 场景：模块化设计；执行速度快 pg_repack： 目标：在线清理表空间，解决大量更新引起表膨胀问题 四、软件设计面向对象设计面向对象六大原则： 单一职责原则：一个类只干一件事 开闭原则：类对扩展开放、对修改封闭 里氏替换原则：父类可以替换成子类（就是子类不能覆盖父类方法） 依赖倒置原则：依赖抽象编程（具体类之间不发生依赖关系） 接口隔离原则：类的依赖应该建立在最小范围接口上 迪米特原则：一个对象应该对其它对象有最少的了解（低耦合、高内聚） 设计模式23 种设计模式： 工厂方法：深信服组项目，日志分析系统有不同的数据来源，使用工厂方法来设计这个模块，方便管理和新增新的数据源 单例：深信服组项目，日志控制组件的设计（只有一个实例，减少资源消耗；不适用于变化的对象） 懒汉：静态局部变量 懒汉：双层互斥锁（返回智能指针） 懒汉：call_once 饿汉：代码一运行就创建实例（全局静态变量） 状态：文件系统项目，不同的磁盘设备状态执行同一操作时会有不同的效果（磁盘已挂载状态和磁盘未挂载状态执行磁盘挂载操作，已挂载状态就直接返回已挂载了） 应用设计模式： 插件化编程：通过动态加载功能模块（插件）来增强主程序功能的软件设计策略。通过制定标准化接口，确保插件和主程序之间的兼容性与独立性。提高软件灵活性和可扩展性。 动态观测：在应用中植入数据观测接口和数据观测控制（通过宏来选择是否植入数据观测代码，保证正式发布的应用的安全性），使用 Socket 套接字与其通信获取应用实时数据。 模块设计 看门狗： 目的：监控持有锁的线程是否活跃 设计：注册接口（线程注册信息和看门狗处理接口），喂狗接口（线程通过该接口喂自己的狗），看门狗监控线程运行状态（如果线程很久没动就可以通过注册的处理接口来做线程销毁），反注册接口；看门狗处理接口（安全释放资源）+ 终止线程 内存池： 目的：提前申请内存，减少内存的频繁申请和释放 设计：内存对齐、线程安全性 线程池： 目的：提前创建线程，减少线程的创建和销毁 考虑：线程个数（IO密集型&#x2F;CPU密集型、系统负载、队列任务个数）。IO 密集型设置线程个数为 2N；CPU 密集型设置为 N+1 设计：任务队列（存储任务）、工作线程（从任务队列拿任务并执行）；接口设计（初始化，提交任务——任务需要的资源，任务完成后的回调接口） LRU 缓存： 目的：优先资源下的缓存淘汰策略（缓存达到上限时，淘汰最近最少使用的数据） 设计：put 接口 和 get 接口 负载均衡： 文件系统： 大文件分割成小文件，分布在多个磁盘上（通过文件分片实现负载均衡）；或者使用 RAID 0 来实现多个磁盘条带化存储，提高读写性能 算法：加权轮询算法 限流器： 作用：限流 设计：令牌桶、漏桶、滑动窗口计数 幂等性： 作用：无论调用多少次接口，都得到相同的结果 设计：标识 一致性哈希 Reactor、Proactor ID 生成器 无锁队列 秒杀系统 方案设计 多线程、分治 断点续传： 客户端请求携带需要的数据范围，服务端根据需要的数据范围发送部分数据 提高吞吐量： 并行化：并行传输（多个连接）、异步传输（无需返回确认） 优化协议：使用 HTTP&#x2F;2 多路复用、使用 UDP 传输 优化 TCP ：增大 TCP 流量窗口 服务端负载均衡：多个服务端处理，分散负载 设计知识模块：复杂的系统进行分解： 划分标准：功能独立性（相似的功能）、信息隐藏（无需对外部暴露内部信息）、性能考虑（两个部分合成一个）、依赖分析 耦合：模块之间的依赖程度（内容直接调用、共享全局数据区域、通过调用通信） 降低耦合性：模块化设计，信息隐藏 设计流程：需求分析（明确需求和产出）、系统设计（整体架构和结构）、详细设计（模块细节）、编码实现（分模块开发、主流程拓展开发）、测试（单元、集成、系统）、验收、部署和维护 系统设计： 外部边界：提出正确的问题，做出合理的假设（场景，系统需要与外部交换的地方），收集建立系统的必要信息 内部设计：基本场景（系统架构设计），发展场景（系统可扩展性） 软件测试黑盒 &amp; 白盒： 白盒：测试人员可以了解和分析被测软件的内部结构，代码和逻辑 场景：单元测试（分支覆盖率）、集成测试 黑盒：测试人员不了解软件内部结构，只关注软件功能 场景：功能测试、系统测试、验收测试 五、语言知识语言版本C++ 11 新特性：智能指针、Lambda、Function、左值和右值、关键字（final &amp; override、default &amp; delete、explicit、constexpr、enum class） 语言基础编译过程：预处理（#开头的内容、删除注释、添加调试信息）、编译（词法分析、语法分析、语义分析、中间代码生成、目标代码生成）、汇编（将汇编代码转换成机器码）、链接（将目标文件链接到一起形成可执行文件，包括地址和空间分配、符号决议和重定位） static 关键字：限制变量或者函数的作用域 extern 关键字：引用别处定义的变量 static 变量不能被 extern 引用（限制作用域了） 引用和指针： 初始：引用需要绑定变量（指针可以设置为 NULL） 修改：引用初始化不能修改（指针可以修改） 使用：引用可以直接使用，无需解引用（指针需要解引用） malloc 和 new： 语法：C++ 语法、C 语法 方式：malloc 仅分配内存，new 还包括了构造函数初始化过程；malloc 需要传入大小，new 自动计算大小 返回：malloc 返回 void；new 返回对象指针 失败：malloc 返回 null；new 抛出异常 std::bad_alloc 智能指针：自动管理内存的指针，无需手动释放内存，确保对象正确的销毁 std::unique_ptr：独占，内存只能由一个 unique_ptr 拥有，超出作用域自动释放 std::shared_ptr：共享，允许多个 shared_ptr 指向同一个对象，最后一个引用超出作用域自动释放 std::weak_ptr：监视 shared_ptr 的资源是否存在。用来返回 this 指针和循环引用问题 自动释放逻辑：shared_ptr 维护一个引用计数，当创建一个新的实例时引用计数增加，当销毁一个实例时引用计数减小，当引用计数减小到 0 时，此时会自动释放内存（RAII 思想） auto：自动推导变量类型，编译时根据变量的初始化表达式来推导变量的类型 编译时类型推导、推导时忽略引用和 const c++ volatile 关键字：防止编译器优化，每次访问变量都从内存中读取最新的值 内联函数： 优点：减少函数调用开销，类似于宏（都是编译期替换的），但是比宏更安全 缺点：代码膨胀（可执行文件变大），编译时间增加 RAII 思想：Resource Acquisition Is Initialization，资源获取即初始化 思想：利用栈上局部变量的自动析构抱枕资源一定会被释放（例如锁的自动释放、打开的文件自动释放） 异常：如果抛出了异常，局部对象会被析构 错误处理：errno（全局错误代码变量）、perror()（打印当前错误码的文本形式，可以提供前缀）、strerror()（返回当前错误码文本指针） Python GIL 锁：全局解释器锁，属于互斥锁，只允许一个线程保持解释器的控制权 WHY：确保内存对象引用计数的 其它语言：Ruby 垃圾回收： Python 垃圾回收：依赖引用计数 Java 垃圾回收：依赖具体的回收策略 JVM： 优缺点：平台无关性、自动垃圾回收；启动时间长、内存占用高 语言类型： 编译型：通过编译器将源代码转换成机器码（C、C++、Go、Rust） 解释型：代码在运行时由解释器逐行解释并运行（Python、Ruby） 混合型：转换成中间语言，再由 JVM 解释执行（Java） 面向对象面向过程 &amp; 面向对象： 过程：拆分解决问题步骤，实现函数步骤 对象：将问题事物拆分成对象，对象描述事物在解决问题中的行为 C 实现面向对象 &amp; 为什么： 为什么：C 效率高，在资源不是很多的 MCU 场景中使用面向对象的方法来设计程序 面向对象三大特性：封装、继承、多态（实现模块化，可重用） 封装：数据（属性）和数据操作（方法）组合在一个类中 继承：一个类从另一个类获得属性和方法的过程。提高代码复用性和可维护性 多态：不同类的对象使用相同的接口名字，但具有不同的实现特性 C++ 多态：基类的指针在运行时指向派生类对象，并调用派生类的成员函数 实现机制：虚函数（派生类重写基类方法），抽象基类（纯虚函数，实现接口） 条件：通过基类调用虚函数 &amp; 被调用的函数是虚函数且完成对基类虚函数的重写 实现方法：动态多态（虚函数、纯虚函数），静态多态（模板函数、函数重载） 虚函数和纯虚函数：纯虚函数是只定义了一个接口 包含纯虚函数的类叫抽象类，不能被初始化 构造函数 &amp; 析构函数（虚函数）： 构造函数不能是虚函数：对象虚函数表未初始化 析构函数是虚函数：确保通过基类销毁对象时能够正确地调用派生类地析构函数，否则只会调用基类析构函数导致资源泄露 重载、重写和隐藏： 重载：相同作用域有相同的方法名，但是参数变量不同 重写：派生类中重定义基类的方法（扩展基类的功能） 隐藏：派生类隐藏基类中的同名函数（不管参数是不是相同） 菱形继承： 问题：内存重复、命名冲突 解决：虚继承（共同的类在虚函数表中是共享的） 左值和右值： 左值：占据内存的一个可识别的位置 右值：不是左值的就是右值 构造、复制、移动：构造、复制、移动： 构造：构造函数，生成本类 复制：内容的拷贝 移动：内容的转移 复制构造：MyClass(const MyClass&amp; other) 移动构造：MyClass(MyClass&amp;&amp; other) noexcept 复制赋值：MyClass&amp; operator&#x3D;(const MyClass&amp; other) 移动赋值：MyClass&amp; operator&#x3D;(MyClass&amp;&amp; other) noexcept 类型擦除：一种隐藏具体信息的编程技术 方法：基类+虚函数、模板+包装类、std::any（C++ 17） 内存管理内存分配： 堆上分配：brk &amp; sbrk（改变堆大小），malloc &amp; free、calloc 和 realloc、posix_memalign（分配对齐）内存分配-堆 跟踪调试：mtrace 和 muntrace、Valgrind、使用智能指针 栈上分配：alloca 内存分配-栈 内存对齐： 作用：提高 CPU 访问速度 方法：posix_memalign 内存泄漏：申请的内存没有释放 valgrind–memcheck：监听分配和释放内存的函数调用（感知内存泄漏、访问越界、使用未初始化内存、使用已释放内存） 重载 new&#x2F;delete：跟踪调用（在全局父类中进行选择性的重载，要注意多线程的问题） perf：添加 malloc 探针，跟踪分配器事件 自定义设计：上面的都无法跟踪内存块的使用过程。如果参考智能指针，对指针做一层封装，就可以跟踪所有的申请和释放过程了（通过封装宏来增加文件、行号等信息）。不足之处是侵入式编程，重新定义了指针，通过宏来控制是否进行跟踪 Python 内存回收机制： 主动回收： STLSTL 类型： 序列容器：array、vector、deque、list、forward_list 关联容器：set &amp; multiset、map &amp; multimap（红黑树） 无序容器：unordered_*（哈希表） 其它容器：string、pair、tuple 容器适配器：stack、queue、priority_queue 迭代器失效： 序列式容器：删除元素会使后面的迭代器失效，但是 erase 会返回下一个有效的 iterator 链表式容器：删除元素不会导致其它迭代器失效，erase 也会返回下一个有效的 iterator 关联式容器：删除元素不会导致其它迭代器失效（erase 返回值为 NULL） 模板： 目的：同样的代码适用于不同类型下的使用，实现代码复用（泛型编程） 原理：编译阶段根据模板类型确定应该产生什么类 推导：根据模板参数的实际类型推导出模板参数类型 push_back &amp; emplace_back： push_back：接收对象，创建临时对象，移动或者复制 emplace_back：接收构建参数，原地构造对象 vector 扩容机制： size（实际已经使用的）；capacity（已使用+未使用） 扩容方案：两倍扩容（插入空间比原空间小）；插入空间扩容（插入空间比原空间大） 最佳方案：两倍？最佳应该是斐波那契数列，能够复用原来的内存空间 因子越大，分配越多，内存利用率低；因子越小，分配越少，再分配可能性越大 cast 方法： static_cast：编译时类型转换，基本类型、指针类型 dynamic_cast：运行时类型转换，基类转派生类（确实是派生类，否则失败） const_cast：添加或移除变量的const或volatile限定符 reinterpret_cast：低级别类型转换，不考虑指针之间的关系 move &amp; forward：（C++ 11） move：将对象转换成右值引用 forward：完美转发，用于模板编程，保证参数的类型在转发过程中保持不变 std::variant：类型安全的联合体，存储多种已知类型的情况（C++ 17） std::get：通过类型 T 访问 std::variant 中的值。如果当前存储的类型不是 T，会抛出 std::bad_variant_access 异常 std::get_if：返回一个指向 std::variant 中类型为 T 的值的指针。如果当前存储的类型不是 T，返回 nullptr std::visit：使用访问者模式（Visitor Pattern）来处理 std::variant 中的值（std::visit） std::any：存储任意类型的值（C++ 17） 通过 std::any_cast 可以访问当前存储的值，如果当前存储的类型不是 T，会抛出 std::bad_any_cast 异常 工程Make &amp; Makefile： 配置文件：.config 文件，写入配置选项 make &amp; cmake： gcc：编译指令（make 的调用对象） make：执行者，负责按照给定的规则执行构建操作 cmake：协调者，负责生成构建规则，使得 make 和其它构建工具可以完成工作 调试问题GDB 调试原理：通过系统调用 ptrace 实现的 设置断点：断点处指令重写为 INT 3（中断 SIGTRAP），到达之后指令被修改回来 主进程跟踪子进程的所有信息（ptrace实现） 调试方法： 定位问题 &amp; 复现问题 解决问题（查找原因：Google + 官方文档） 记录归档 细节问题最大值的宏：#define MAX(a, b) ((a) &gt; (b) ? (a) : (b)) 问题：展开副作用（自增运算） 解决：使用 inline 内联函数 六、框架Dockerblog.csdn.net&#x2F;FateZRK&#x2F;article&#x2F;details&#x2F;125750830 虚拟化： 定义：一台计算机虚拟为多态逻辑计算机 作用：应用程序和系统内核资源解耦，以操作系统级别隔离，提高资源利用率 瓶颈：每个任务的处理效率会打折扣 Docker 原理： 容器：独立的软件包，包含运行引用程序所需的一切。容器共享操作系统内核 镜像：包含创建容器所有文件和配置（只读的模板） 引擎：负责管理容器的生命周期，包括创建、启动、停止和删除。包括： Docker Daemon：运行主机上的后台服务，管理镜像、容器、网络和存储卷 Docker CLI：命令行工具，与 Docker Daemon 交互 REST API：外部工具与 Docker Daemon 交互接口 运行时：负责运行容器的底层组件。docker 使用 runc 作为容器运行时（标准容器运行时），负责创建和运行容器，并与主机操作系统内核交互 命名空间：Linux 内核提供的一种隔离机制，用于隔离进程的资源。docker 使用命名空间来隔离容器的进程、网络、文件系统、用户和主机名资源，实现容器之间的隔离 控制组：控制组（cgroups）是 Linux 内核提供的一种资源管理机制，用于限制和隔离进程的资源使用（CPU、内存、磁盘 IO） RPCwww.xiaolincoding.com/network/2_http&#x2F;http_rpc.html#%E4%BD%BF%E7%… **RPC **：计算机通信协议，就像调用本地函数一样。隐藏网络通信复杂性，使得分布式系统开发更加简单和直观 RPC 原理：客户端调用、参数序列化、网络传输、服务器接收和执行、结果序列化、网络传输、客户端接收 传输前序列化 RPC 框架：（注册中心、客户端、服务端） gRPC：Google 做的 dubbo：阿里做的，国内最早的 rpc 框架 RPC 与 HTTP： 性能：RPC 更高效（二进制协议），低延迟（通信开销小）；但是 RPC 设计复杂 Kafkakafka 为什么不丢数据： 数据持久化存储 + 副本机制 生产则会确认机制（保证数据写入） 消费者偏移量（确保可以从上次消费位置继续消费）","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.delta1037.cn/tags/Linux/"},{"name":"C/C++","slug":"C-C","permalink":"https://www.delta1037.cn/tags/C-C/"}]},{"title":"无线网卡找不到问题调试","date":"2023-09-10T16:00:00.000Z","path":"2023/Bugsfix/无线网卡找不到问题调试/","text":"在 rock 3a 系列板子上配置无线网，需要单独购买网卡。一开始在淘宝买了一块 Intel 7265 无线网卡（rock 3a 官方限定的，应该其它型号也可以，但是需要注意内核版本），使用体验还可以。后来又采购了一批 rock 3a 的板子，于是又按照原来的单子买了一块 Intel 7265 无线网卡，但是接上去之后找不到无线网卡，以下记录一下排查过程和思考。 一、问题描述硬件环境： Rock 3A 开发板 Intel 7265 无线网卡（M.2 接口） 问题现象： ifconfig 看不到无线网 问题猜测： 最糟糕的情形是硬件是个坏的，买了也很久了没做过测试可能不给换了 其次可能是网卡适配问题，但是为什么另一块网卡可以用呢？ 二、问题排查2.1 硬件排查从网上了解到 lspci 命令可以查看主板（开发板）上接入的 PCI 设备（根据实际应用发现也可以查看 M.2 设备） 123# lspci 输出00:00.0 PCI bridge: Fuzhou Rockchip Electronics Co., Ltd Device 3566 (rev 01)01:00.0 Network controller: Intel Corporation Wireless 7265 (rev 48) 从上面 lspci 的输出可以看出来，应该不是硬件坏了，因为硬件的版本还是可以看到的。 查找到 -k 参数可以看对应的驱动程序，内核模块 123456# lspci -k 输出00:00.0 PCI bridge: Fuzhou Rockchip Electronics Co., Ltd Device 3566 (rev 01) Kernel driver in use: pcieportlspci: Unable to load libkmod resources: error -1201:00.0 Network controller: Intel Corporation Wireless 7265 (rev 48) Subsystem: Intel Corporation Dual Band Wireless-AC 7265 从上面我以为找到了重点：lspci: Unable to load libkmod resources: error -12，但是我在另一块开发板上也发现了同样的问题。 再次使用 -v 参数查看详细的信息： 123456789101112131415161718192021222324252627282930# lspci -v 输出00:00.0 PCI bridge: Fuzhou Rockchip Electronics Co., Ltd Device 3566 (rev 01) (prog-if 00 [Normal decode]) Flags: bus master, fast devsel, latency 0, IRQ 108 Bus: primary=00, secondary=01, subordinate=ff, sec-latency=0 I/O behind bridge: [disabled] Memory behind bridge: 00900000-009fffff [size=1M] Prefetchable memory behind bridge: [disabled] Expansion ROM at 300a00000 [virtual] [disabled] [size=64K] Capabilities: [40] Power Management version 3 Capabilities: [50] MSI: Enable+ Count=16/32 Maskable- 64bit+ Capabilities: [70] Express Root Port (Slot-), MSI 00 Capabilities: [b0] MSI-X: Enable- Count=1 Masked- Capabilities: [100] Advanced Error Reporting Capabilities: [148] Secondary PCI Express Capabilities: [160] L1 PM Substates Capabilities: [170] Vendor Specific Information: ID=0002 Rev=4 Len=100 &lt;?&gt; Kernel driver in use: pcieportlspci: Unable to load libkmod resources: error -1201:00.0 Network controller: Intel Corporation Wireless 7265 (rev 48) Subsystem: Intel Corporation Dual Band Wireless-AC 7265 Flags: fast devsel, IRQ 107 Memory at 300900000 (64-bit, non-prefetchable) [size=8K] Capabilities: [c8] Power Management version 3 Capabilities: [d0] MSI: Enable- Count=1/1 Maskable- 64bit+ Capabilities: [40] Express Endpoint, MSI 00 Capabilities: [100] Advanced Error Reporting Capabilities: [140] Device Serial Number 64-80-99-ff-ff-a8-34-a5 Capabilities: [14c] Latency Tolerance Reporting Capabilities: [154] L1 PM Substates 同样的，这些信息也和另外一块板子上一模一样，没有参考价值。 在使用 -k 参数查看内核信息时，并没有看到有内核信息输出，所以问题是不是出在内核驱动上？于是想到了 dmesg 命令。 2.2 驱动排查dmesg 命令可以查看开机信息，可以看各个模块是否加载成功。查看 dmesg 输出： 123456789101112# dmesg 输出（部分）[ 5.735812] iwlwifi 0000:01:00.0: Direct firmware load for iwlwifi-7265-17.ucode failed with error -2[ 5.735933] iwlwifi 0000:01:00.0: no suitable firmware found![ 5.736069] iwlwifi 0000:01:00.0: iwlwifi-7265-17 is required[ 5.736093] iwlwifi 0000:01:00.0: check git://git.kernel.org/pub/scm/linux/kernel/git/firmware/linux-firmware.git[ 5.969330] usbcore: registered new interface driver btusb[ 5.988375] Bluetooth: hci0: read Intel version: 370810011002270d00[ 5.990701] bluetooth hci0: Direct firmware load for intel/ibt-hw-37.8.10-fw-1.10.2.27.d.bseq failed with error -2[ 5.990737] Bluetooth: hci0: failed to open Intel firmware file: intel/ibt-hw-37.8.10-fw-1.10.2.27.d.bseq (-2)[ 5.993308] Bluetooth: hci0: Intel Bluetooth firmware file: intel/ibt-hw-37.8.bseq[ 5.995534] Bluetooth: hci0: unexpected event for opcode 0xfc2f[ 5.998546] Bluetooth: hci0: Intel firmware patch completed 于是就看到了启动时加载 wifi 固件 iwlwifi-7265-17.ucode 和蓝牙固件 intel/ibt-hw-37.8.10-fw-1.10.2.27.d.bseq 都失败了，这两个模块在 /usr/lib/firmware 中，查看固件目录： 12345678(blockchain_board) root@rock-3a:/usr/lib/firmware# pwd/usr/lib/firmware(blockchain_board) root@rock-3a:/usr/lib/firmware# lsath10k intel iwlwifi-cc-a0-46.ucode rtl8723du_config rtl8821cu_config rtl8852bu_config rtl_btbrcm iwlwifi-7265D-29.ucode iwlwifi-ty-a0-gf-a0-59.ucode rtl8723du_fw rtl8821cu_fw rtl8852bu_fw rtlwifi(blockchain_board) root@rock-3a:/usr/lib/firmware# ls intel/ibt-0041-0041.ddc ibt-0041-0041.sfi ibt-hw-37.8.10-fw-1.10.3.11.e.bseq ibt-hw-37.8.10-fw-22.50.19.14.f.bseq ibt-hw-37.8.bseq(blockchain_board) root@rock-3a:/usr/lib/firmware# 可以看到应该是缺了这两个固件，所以 WIFI 才没有启动成功！从列出来的固件可以看出，无线网卡 7265 只有一个 iwlwifi-7265D-29.ucode 固件，应该是 7265 也有不同的固件版本才导致无线网卡会加载失败吧。蓝牙固件也是，只是版本不一样。 2.3 解决从网上找到这两个固件，放到固件的目录，重启即可解决无线找不到的问题了。 三、思考我们无法一开始就知道是固件版本的问题，只能从整体的结构上去分析问题到底出在哪里。从整体上分析问题要对整体的结构都有所了解，即使不知道细节，也可以将问题定位到一个很小的范围，这样才能更快更好的解决问题。","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.delta1037.cn/tags/Linux/"},{"name":"Kernel","slug":"Kernel","permalink":"https://www.delta1037.cn/tags/Kernel/"}]},{"title":"Matplotlib图像结构","date":"2023-07-28T16:00:00.000Z","path":"2023/Skill/Matplotlib图像结构/","text":"本文简要梳理Matplotlib中的元素；如何使用Subplot和Axes控制子图，以及调整子图之间的间距；最后简要说明了Matplotlib的数据输入和图像输出的控制 一、元素 标题 - Title：图像的名字 图例 - Legend：展示每个数据图像对应的名称 边界 - spines：图四周的框的边界（注意 tick 刻度和所在的线是分离的） 标记 - Marker：图线的标记类型 标签 - Label：一些细节的标识 X 轴标签 Y 轴标签 主刻度标签 副刻度标签 刻度 - tick：标识对应位置的数值 主刻度 副刻度 字体 - font：文字的类型 颜色 - color：线条、文字 二、结构Matplotlib 创建的主体称为 Figure，再 Figure 中可以创建子图，子图中就是一些标签元素和数值元素了。 1234567891011121314 import matplotlib.pyplot as plt # 新建画板 fig = plt.figure() # 新建画布 ax = fig.add_subplot() # or ax = fig.add_axes() # 接下来就可以在ax上绘制图像，或者设置标签等 # 画板与画布：画板是固定的，画布则可以有多个并且位置可以调整 # 可以对fig做画板的控制（设置画板标题、保存画板图像等） 在子图控制中可以通过 plt 添加子图，也可以通过 fig 来添加子图，这两者的区别是 plt 底层还是用的 fig 对象，在源码中有一个 gcf() 函数，会获取当前活跃的 figure（Get the current figure.） 2.1 子图控制对于子图的控制，Matplotlib 中有 Axes 和 Subplot 两种控制方式。 Subplot标准网格布局1234 import matplotlib.pyplot as plt fig = plt.figure(figsize=(20, 10), dpi=1000) # 新建画板 ax = fig.add_subplot(2, 3, idx) # 新建画布 add_subplot 方法里面传入三个数字，前两个数字代表要生成几行几列的子图矩阵，第三个数字代表选中的子图位置。因此 add_subplot 适合排布规范的多子图形式。 另外也可以通过 plt 直接设置网格，并获取到网格轴域 ax 123456789 import matplotlib.pyplot as plt # 两行一列的图 #（但是这种方式已经准备弃用了 # Support for FigureCanvases without a required_interactive_framework attribute was deprecated # in Matplotlib 3.6 and will be removed two minor releases later.） fig, (ax1, ax2) = plt.subplots(2,1) ax1.plot(X, Y1, color=&quot;C1&quot;) ax2.plot(X, Y2, color=&quot;C0&quot;) 自定义网格布局使用 add_gridspec 做更复杂的网格布局（占用多个网格作为一个图） 设置网格的方式： 1234567891011121314 import matplotlib.pyplot as plt fig3 = plt.figure(constrained_layout=True) gs = fig3.add_gridspec(3, 3) f3_ax1 = fig3.add_subplot(gs[0, :]) f3_ax1.set_title(&#x27;gs[0, :]&#x27;) f3_ax2 = fig3.add_subplot(gs[1, :-1]) f3_ax2.set_title(&#x27;gs[1, :-1]&#x27;) f3_ax3 = fig3.add_subplot(gs[1:, -1]) f3_ax3.set_title(&#x27;gs[1:, -1]&#x27;) f3_ax4 = fig3.add_subplot(gs[-1, 0]) f3_ax4.set_title(&#x27;gs[-1, 0]&#x27;) f3_ax5 = fig3.add_subplot(gs[-1, -2]) f3_ax5.set_title(&#x27;gs[-1, -2]&#x27;) 设置比例的方式： 1234567891011 fig5 = plt.figure(constrained_layout=True) widths = [2, 3, 1.5] heights = [1, 3, 2] spec5 = fig5.add_gridspec( ncols=3, nrows=3, width_ratios=widths, height_ratios=heights) for row in range(3): for col in range(3): ax = fig5.add_subplot(spec5[row, col]) Axes画板上新增轴子图12345 import matplotlib.pyplot as plt fig = plt.figure() # 新建画板 ax1 = fig.add_axes([0.1,0.1,0.8,0.8]) # 新建画布 ax2 = fig.add_axes([0.2,0.5,0.4,0.3]) add_axes 方法传入一个位置列表，列表中有四个值，格式如 [left, bottom, width, height]。其中 left 和 bottom 分别表示距离左侧和下边占整张图的比例（0-1 的取值范围），width 和 height 分别表示宽度和高度占整张图的比例（0-1 的取值范围），也就是起始位置是从左下角开始计算的（坐标系原点）。因此 add_axes 方法可以在图上的任意一个位置建立坐标轴并绘制曲线。 子图中新增轴子图 可以用来放大某一个指定区域 123456789101112131415161718192021 # Implementation of matplotlib function import matplotlib.pyplot as plt fig, ax = plt.subplots() ax.plot(range(10)) axin1 = ax.inset_axes( # 相对坐标，由 transform 决定 [0.8, 0.1, 0.15, 0.15]) # transform 默认是 transAxes axin2 = ax.inset_axes( # 数据坐标，由 transform 决定 [5, 7, 2.3, 2.3], transform = ax.transData) ax.set_title( &#x27;matplotlib.axes.Axes.inset_axes() Example&#x27;, fontsize = 14, fontweight =&#x27;bold&#x27;) fig.show() # 会闪退，但是可以savefig # or plt.show() 双轴图 可以在同一块区域使用不同的坐标，场景为多种曲线或者图形需要配置对应的坐标 12345678 # 共用x轴，双纵轴图 new_ax = ax.twinx() # 公用y轴，双横轴图 new_ax = ax.twiny() # 新建两个轴(新画布是右边和上边的轴) new_ax = ax..twinx().twiny() 附加轴子图（colorbar）make_axes_locatable 是 Matplotlib 库中的一个函数，它用于创建一个新的 Axes 对象，并将其放置在主图 Axes 对象旁边的位置，以容纳 colorbar。这个函数通常用于在 Matplotlib 绘图中创建 colorbar。 12345678910111213 from mpl_toolkits.axes_grid1 import make_axes_locatable import matplotlib.pyplot as plt fig, ax = plt.subplots() # ... 画图 ... # 创建附加轴位置、大小、间距 divider = make_axes_locatable(ax) cax = divider.append_axes(&#x27;right&#x27;, size=&#x27;5%&#x27;, pad=0.05) # 在新的 Axes 对象上创建 colorbar plt.colorbar(cax=cax) Axes 和 Subplot 总结 两种对象确实是“你中有我，我中有你”的关系，生成子图（subplot）的时候，必然带着所谓的一套轴域（Axes）。而用轴域（Axes）方法，客观上就是生成了一个可以画图的子图。 add_subplot 方法在生成子图过程，简单明了；而用 add_axes 方法，则生成子图的灵活性更强，完全可以实现 add_subplot 方法的功能，可以控制子图显示位置，甚至实现相互重叠的效果。 通过新增子图获取到轴域就可以对其新增数据，增加图像的细节了。 2.2 间距调整给子图添加标题和坐标轴标签后，子图可能会发生重叠，可以通过如下接口来调整： 12345678910111213141516 # 调整图位置和间距 plt.subplots_adjust( left=None, bottom=None, right=None, top=None, wspace=None, hspace=None) # 整张图位置 # left ： 子图在画板上的左位置（position），默认0.125 # right ： 子图在画板上的右位置（position），默认0.9 # bottom ： 子图在画板上的下位置（position），默认0.1 # top： 子图在画板上的上位置（position），默认0.9 # 间距 # wspace：子图之间的横向间距（padding），默认0.2 # hspace：子图之间的纵向间距（padding），默认0.2 三、数据3.1 输入Matplotlib 只能接收 np.array 格式或者 np.ma.masked_array 格式的数据。不接受类似数组的数据例如 pandas 和 np.matrix 类型的，最好将其转换成 np.array 类型。 pandas 类型转换： 12 a = pandas.DataFrame(np.random.rand(4,5), columns = list(&#x27;abcde&#x27;)) a_asarray = a.values np.matrix 类型转换： 12 b = np.matrix([[1,2],[3,4]]) b_asarray = np.asarray(b) 3.2 输出保存图像到本地文件： 1 plt.savefig(&#x27;pic_name.png&#x27;) 参考python matplotlib 中 axes 与 axis 的区别是什么? ‍","tags":[{"name":"Python","slug":"Python","permalink":"https://www.delta1037.cn/tags/Python/"},{"name":"绘图工具","slug":"绘图工具","permalink":"https://www.delta1037.cn/tags/%E7%BB%98%E5%9B%BE%E5%B7%A5%E5%85%B7/"}]},{"title":"符号未定义实例一则","date":"2023-05-01T16:00:00.000Z","path":"2023/Deploy/符号未定义实例一则/","text":"该示例来源于Github项目**MiniPSI的复现，该项目的编译用到了另一个Github项目MIRACL**编译的静态库文件，但是在连接的过程中总是无法链接，提示符号未定义错误。因为我对CMake文件也不是相当了解，一开始的思路就陷入到了静态库文件的位置是不是设置的有问题，后续依靠着之前看到过的C&#x2F;C++编译的知识，才排查到是C++调用C的库时符号的问题。 一、问题场景**MiniPSI**项目中，作者提供了一个一键安装脚本，但是在项目中确实了脚本中所用到的libOTe/cryptoTools/thirdparty/linux/路径部分，导致一键安装脚本失效。从项目作者的README中了解到，缺失的编译依赖内容是boost和miracl，所以就手动创建该目录，在该目录下进行依赖的编译即可。 Boost库的编译很顺利，毕竟这是一个很知名的库。MIRACL在编译的过程中则遇到了一点问题： MIRACL需要扁平式解压，但是MiniPSI项目中对该项目的依赖具有项目结构：对MiniPSI项目中依赖MIRACL项目的地方修改，去除项目结构部分（头文件目录和静态库目录等等，改为使用根目录即可）。 本次实验环境是CentOS，MIRACL项目的lib文件夹中包含编译Linux库文件的有三个脚本：linux、linux64和linux64_cpp，linux脚本对应着i386 32位系统环境，linux64对应着64位系统环境，linux64_cpp是C++库特供版。在项目编译中，首选的是linux64_cpp，因为MiniPSI是C++的： MiniPSI中需要MIRACL的多线程版本，在MIRACL的文档中有记录，在头文件mirdef.h中添加宏定义MR_GENERIC_MT即可 MIRACL多线程版本只有linux、linux64两个脚本可以实现，但是无法编译一些测试文件，如果不想出现过多的报错可以在脚本文件中把测试文件的编译删除掉。C++版本的linux64_cpp不支持多线程。 二、问题描述使用C版本的编译脚本来编译MIRACL多线程版本，形成一个静态库libmiracl.a（从miracl.a拷贝而来），给libOTE编译的时候用。 在libOTE形成可执行文件的时候（例如frontend_libOTe），这个时候就是要处理一些未定义的符号的时候了（之前的编译都是形成的静态库文件，所以未定义的符号是没有问题的），但是这个时候出现了大量的符号未定义错误： 1234567**../lib/libcryptoTools.a**(Curve.cpp.o): In function `osuCrypto::EccNumber::randomize(osuCrypto::PRNG&amp;)&#x27;:Curve.cpp:(.text._ZN9osuCrypto9EccNumber9randomizeERNS_4PRNGE+0x3a): undefined reference to `zero(bigtype*)&#x27;Curve.cpp:(.text._ZN9osuCrypto9EccNumber9randomizeERNS_4PRNGE+0x10a): undefined reference to `mr_compare(bigtype*, bigtype*)&#x27;Curve.cpp:(.text._ZN9osuCrypto9EccNumber9randomizeERNS_4PRNGE+0x124): undefined reference to `mr_lzero(bigtype*)&#x27;Curve.cpp:(.text._ZN9osuCrypto9EccNumber9randomizeERNS_4PRNGE+0x139): undefined reference to `divide(miracl*, bigtype*, bigtype*, bigtype*)&#x27;Curve.cpp:(.text._ZN9osuCrypto9EccNumber9randomizeERNS_4PRNGE+0x14d): undefined reference to `mr_compare(bigtype*, bigtype*)&#x27;Curve.cpp:(.text._ZN9osuCrypto9EccNumber9randomizeERNS_4PRNGE+0x176): undefined reference to `mr_compare(bigtype*, bigtype*)&#x27; 经过nm命令对库文件符号的观察，缺失的符号应该是在的： 12345678910111213141516➜ miracl git:(master) ✗ nm libmiracl.a | grep compare0000000000002570 T mr_compare U mr_compare U mr_compare U mr_compare00000000000006f0 T zzn2_compare U mr_compare00000000000000a0 T zzn3_compare U mr_compare U mr_compare U mr_compare0000000000001180 T ecn2_compare U mr_compare U zzn2_compare U zzn2_compare00000000000002c0 T zzn4_compare 根据编译frontend_libOTe的输出内容，报错的应该是库文件libcryptoTools.a，去看一下库文件里对应的符号是什么： 123➜ libOTe git:(master) ✗ nm ./lib/libcryptoTools.a | grep compare **U _Z10mr_compareP7bigtypeS0_** U _ZNKSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE7compareEPKc 可以看出来库文件libcryptoTools.a里对应的符号是_Z10mr_compareP7bigtypeS0_，但是libmiracl.a库里对应的符号是mr_compare，说明是C++符号修饰的问题。 上面报未定义的错误undefined reference to zero(bigtype*)’&#96;，我只关注到了函数名称，却没有考虑到要去对应报错的库里看具体的符号名是什么（显示出来的信息和具体库里实际符号名是不一样的），导致我一致在找编译时链接库的问题。 三、问题解决排查到C++调用C的库，那么问题就很明显了，给C库的结构上套一层宏就可以了，表明这些是C的接口，不需要符号修饰。 1234567#ifdef __cplusplusextern &quot;C&quot;&#123;#endif// some api define#ifdef __cplusplus&#125;#endif 四、总结其实如果一开始就能关注到C++调用C的库会有问题，那么整体的过程会顺利很多，但是我先入为主（从输出的信息中看到函数名找不到，一直在找链接问题），认为问题大概率出现在CMake的文件上，一直在排查链接的过程。这个问题的解决过程花费了我几乎一天的时间，书上的知识想要在实际中灵活运用还是有点距离。 排查链接问题还是要自顶向下的排查： 先被链接的库里的缺失的符号是什么样的（库有没有问题，符号有没有导出） 查找可执行文件中对应缺失的符号是什么样的，是否与被链接库的符号一致（符号问题） 查看编译的链接过程，是否没有找到对应的链接库（链接问题）","tags":[{"name":"C/C++","slug":"C-C","permalink":"https://www.delta1037.cn/tags/C-C/"}]},{"title":"pyinstaller打包的exe解包","date":"2023-02-15T16:00:00.000Z","path":"2023/Others/pyinstaller打包的exe解包/","text":"将pyinstaller打包的exe解包： 解非加密的exe 解加密后的exe（打包的python版本要≤3.8） 一、解包依赖 pyinstxtractor（不需要安装）：@(https://github.com/extremecoders-re/pyinstxtractor) uncompyle6（pip安装：pip install uncompyle6）：@(https://github.com/rocky/python-uncompyle6) 解密文件：代码来源未知，只有代码了 uncompyle6不支持3.9，所以解包的对应的exe工程需要在3.8以下 二、解包2.1 从exe文件提取二进制pyc文件2.1.1、下载pyinstxtractor获取到py文件，win11终端中执行 1py .\\pyinstxtractor.py .\\exe_file.exe LOG： 12345678910111213141516171819(py_pack_env) PS H:\\TestRepo\\py_pack\\unpack_test&gt; py .\\pyinstxtractor.py .\\notion_dump_client_no_key.exe[+] Processing .\\notion_dump_client_no_key.exe[+] Pyinstaller version: 2.1+[+] Python version: 309[+] Length of package: 11041731 bytes[+] Found 994 files in CArchive[+] Beginning extraction...please standby[+] Possible entry point: pyiboot01_bootstrap.pyc[+] Possible entry point: pyi_rth_subprocess.pyc[+] Possible entry point: pyi_rth_pkgutil.pyc[+] Possible entry point: pyi_rth_multiprocessing.pyc[+] Possible entry point: pyi_rth_inspect.pyc[+] Possible entry point: pyi_rth__tkinter.pyc[+] Possible entry point: notion_dump_client.pyc[+] Found 395 files in PYZ archive[+] Successfully extracted pyinstaller archive: .\\notion_dump_client_no_key.exeYou can now use a python decompiler on the pyc files within the extracted directory(py_pack_env) PS H:\\TestRepo\\py_pack\\unpack_test&gt; 2.1.2、如果是加密后的exe文件，输出会显示（类似的Extracting as is.） 123456789[!] Error: Failed to decompress PYZ-00.pyz_extracted\\xml\\sax\\expatreader.pyc, probably encrypted. Extracting as is.[!] Error: Failed to decompress PYZ-00.pyz_extracted\\xml\\sax\\handler.pyc, probably encrypted. Extracting as is.[!] Error: Failed to decompress PYZ-00.pyz_extracted\\xml\\sax\\saxutils.pyc, probably encrypted. Extracting as is.[!] Error: Failed to decompress PYZ-00.pyz_extracted\\xml\\sax\\xmlreader.pyc, probably encrypted. Extracting as is.[!] Error: Failed to decompress PYZ-00.pyz_extracted\\xmlrpc\\__init__.pyc, probably encrypted. Extracting as is.[!] Error: Failed to decompress PYZ-00.pyz_extracted\\xmlrpc\\client.pyc, probably encrypted. Extracting as is.[!] Error: Failed to decompress PYZ-00.pyz_extracted\\zipfile.pyc, probably encrypted. Extracting as is.[!] Error: Failed to decompress PYZ-00.pyz_extracted\\zipimport.pyc, probably encrypted. Extracting as is.[+] Successfully extracted pyinstaller archive: .\\notion_dump_client_key.exe 先获取密码（密码文件时解密加密文件后其中的一个pyimod00_crypto_key.pyc文件（在主目录下））先对pyimod00_crypto_key.pyc进行反编译 123456789(py_pack_env) PS H:\\TestRepo\\py_pack\\unpack_test\\notion_dump_client_key.exe_extracted&gt; uncompyle6 pyimod00_crypto_key.pyc# uncompyle6 version 3.8.0# Python bytecode 3.7.0 (3394)# Decompiled from: Python 3.7.8 (tags/v3.7.8:4b47a5b6ba, Jun 28 2020, 08:53:46) [MSC v.1916 64 bit (AMD64)]# Embedded file name: build\\notion_dump_client\\pyimod00_crypto_key.py# Compiled at: 1995-09-28 00:18:56# Size of source mod 2**32: 51 byteskey = &#x27;0000000000123456&#x27;# okay decompiling pyimod00_crypto_key.pyc 可以看出密码是0000000000123456 用（三、解密文件）中的代码对pyinstxtractor解析出来的内容进行解密 确认：代码中的pyc header（magic Number）部分 确认：代码中的passwd（解密密码） 确认：代码中的PYZ-00.pyz_extracted路径位置 假设解密代码文件，存为文件名为decode.py ，并且与exe同级目录，在改目录下执行 1py .\\decode.py 即可获取到所有的pyc文件 2.2 将pyc文件反编译成py文件使用uncompyle6 将pyc文件反编译成py文件即可 1uncompyle6 notion_dump_client.pyc &gt; notion_dump_client.py 三、解密文件解密文件所用代码： 密码部分需要替换 pyc header的magic Number需要替换 1234567891011121314151617181920212223242526272829303132333435import globimport zlibimport tinyaesfrom pathlib import PathCRYPT_BLOCK_SIZE = 16# key obtained from pyimod00_crypto_keykey = bytes(&#x27;passwd&#x27;, &#x27;utf-8&#x27;)for p in Path(&quot;PYZ-00.pyz_extracted&quot;).glob(&quot;**/*.pyc.encrypted&quot;): print(p.with_name(p.stem)) inf = open(p, &#x27;rb&#x27;) # encrypted file input outf = open(p.with_name(p.stem), &#x27;wb&#x27;) # output file # Initialization vector iv = inf.read(CRYPT_BLOCK_SIZE) cipher = tinyaes.AES(key, iv) # Decrypt and decompress plaintext = zlib.decompress(cipher.CTR_xcrypt_buffer(inf.read())) # Write pyc header # The header below is for Python 3.7 outf.write(b&#x27;\\x42\\x0d\\x0d\\x0a\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0&#x27;) # Write decrypted data outf.write(plaintext) inf.close() outf.close() # Delete .pyc.encrypted file p.unlink() 魔数与python版本对照表 获取魔数： 12import importlibprint(importlib.util.MAGIC_NUMBER.hex()) uncompyle6 版本 魔数 python 3.7 \\x42\\x0d\\x0d\\x0a","tags":[{"name":"Python","slug":"Python","permalink":"https://www.delta1037.cn/tags/Python/"},{"name":"解码","slug":"解码","permalink":"https://www.delta1037.cn/tags/%E8%A7%A3%E7%A0%81/"}]},{"title":"Git commit信息规范","date":"2023-02-15T16:00:00.000Z","path":"2023/Project/Gitcommit信息规范/","text":"Git commit信息格式规范 commit信息格式： 1234567&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;# type ：commit类型# scope ： 影响范围# subject ： 具体描述# eg. : fix(DAO): fixed invalid user table indexes. type：type指明git commit的类别，应该使用以下类型，也可根据团队自行增减 『feat』: 新增功能 『fix』: 修复 bug 『docs』: 仅仅修改了文档，比如 README, CHANGELOG等等 『test』: 增加&#x2F;修改测试用例，包括单元测试、集成测试等 『style』: 修改了空行、缩进格式、引用包排序等等（不改变代码逻辑） 『perf』: 优化相关内容，比如提升性能、体验、算法等 『refactor』: 代码重构，「没有新功能或者bug修复」 『chore』: 改变构建流程、或者增加依赖库、工具等 『revert』: 回滚到上一个版本 『merge』: 代码合并 scope（可选）：scope用于说明 commit 影响的范围，根据不同项目有不同层次描述。若没有特殊规定，也可以描述影响的哪些功能等。 subject：subject是commit目的的简短描述，不超过50&#x2F;80个字符，一般git提交的时候会有颜色提示。 若英文用不惯，那么推荐使用中文 若是开源代码，一律推荐统一英文，英文不行可以翻译软件用起来 若是开源代码，可以再附加对应的issue地址 结尾不加标点符号 参考： BOOKMARK","tags":[{"name":"Git","slug":"Git","permalink":"https://www.delta1037.cn/tags/Git/"}]},{"title":"Row size too large (> 8126)","date":"2023-02-11T16:00:00.000Z","path":"2023/Bugsfix/Rowsizetoolarge(-8126)/","text":"MySQL表新增字段时，出现报错：Row size too large (&gt; 8126). Changing some columns to TEXT or BLOB or using ROW_FORMAT=DYNAMIC or ROW_FORMAT=COMPRESSED may help 一、信息1.1 环境给数据表添加一个新的字段。该数据表已经有很多字段了，并且一行的字节长度远大于8126。 在本地搭建的MySQL5.7环境上新增字段并没有出错，所以是远程MySQL版本出现的问题。猜测是innodb_file_format并没有设置成正确格式。 1.2 报错 Row size too large (&gt; 8126). Changing some columns to TEXT or BLOB or using ROW_FORMAT&#x3D;DYNAMIC or ROW_FORMAT&#x3D;COMPRESSED may help 二、解决免重启服务式解决： 12mysql&gt; set GLOBAL innodb_file_per_table = ON;mysql&gt; set GLOBAL innodb_file_format = barracuda; 三、分析InnoDB格式问题： InnoDB目前支持两种命名文件格式，Antelope 和Barracuda。 Antelope是原始 InnoDB文件格式，以前没有名称。它支持表的COMPACT和REDUNDANT行格式InnoDB Barracuda是最新的文件格式。它支持所有InnoDB行格式，包括较新的COMPRESSED和 DYNAMIC行格式。与 COMPRESSED和 DYNAMIC行格式相关的特性包括压缩表、页外列的高效存储以及高达 3072 字节的索引键前缀 ( innodb_large_prefix) 12# 检查表的文件格式和行格式 命令SELECT * FROM INFORMATION_SCHEMA.INNODB_SYS_TABLES; MySQL硬性条件： 65535 bytes is the max row size for mysql. 问题分析： 根据问题的提示，原因肯定是表中的字段长度和超了，所以按照修改提示，将ROW_FORMAT修改为COMPRESSED或者DYNAMIC，但又只有Barracuda文件格式支持，所以先通过set GLOBAL innodb_file_format = barracuda;将InnoDB格式修改，再修改表的ROW_FORMAT格式即可。 总结： 本地使用的版本是MySQL5.7，部署服务器版本是MySQL5.6，通过上面的检查表的文件格式和行格式命令，可以看到本地的InnoDB默认格式就是Barracuda，而远程除一个被修改的表之外，其它的全是Antelope格式，所以出现报错就是InnoDB格式和ROW_FORMAT格式导致的。 参考BOOKMARK BOOKMARK BOOKMARK","tags":[{"name":"Bug","slug":"Bug","permalink":"https://www.delta1037.cn/tags/Bug/"},{"name":"MySQL","slug":"MySQL","permalink":"https://www.delta1037.cn/tags/MySQL/"}]},{"title":"hexo 新增mermaid支持","date":"2023-02-06T16:00:00.000Z","path":"2023/Deploy/hexo新增mermaid支持/","text":"趁着博客整合，修理一下mermaid不支持的问题。 从网上找到了一些教程，但是配置过程中也发现了一些问题，所以在这里记录一下。 一、安装安装插件： 1npm install hexo-filter-mermaid-diagrams 添加配置。在主题目录下的_config.yml文件中新增配置： 123456# mermaid chartmermaid: ## mermaid url https://github.com/knsv/mermaid enable: true # default true version: &quot;7.1.2&quot; # default v7.1.2 options: # find more api options from https://github.com/knsv/mermaid/blob/master/src/mermaidAPI.js #startOnload: true // default true 添加支持。我使用的BuleLake主题js后缀是.ejs（其它类型（.pug、.swig）参考Github说明），在themes\\bluelake\\layout\\_partial\\**after-footer.ejs**中添加如下内容 12345678&lt;% if (theme.mermaid.enable) &#123; %&gt; &lt;script src=&#x27;https://unpkg.com/mermaid@&lt;%= theme.mermaid.version %&gt;/dist/mermaid.min.js&#x27;&gt;&lt;/script&gt; &lt;script&gt; if (window.mermaid) &#123; mermaid.initialize(&#123;theme: &#x27;forest&#x27;&#125;); &#125; &lt;/script&gt;&lt;% &#125; %&gt; 二、使用主题类型：（在上面修改文件时配置）： default - This is the default theme for all diagrams. neutral - This theme is great for black and white documents that will be printed. dark - This theme goes well with dark-colored elements or dark-mode. forest - This theme contains shades of green. base - This is the only theme that can be modified. Use this theme as the base for customizations. 三、注意 mermaid新增配置是修改的主题目录下的文件 需要将根目录配置_config.yml中highlight下的auto_detect设置为true","tags":[{"name":"博客搭建","slug":"博客搭建","permalink":"https://www.delta1037.cn/tags/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"},{"name":"部署","slug":"部署","permalink":"https://www.delta1037.cn/tags/%E9%83%A8%E7%BD%B2/"}]},{"title":"博客更新说明","date":"2023-02-06T16:00:00.000Z","path":"2023/Deploy/博客更新说明/","text":"博客最近整合到了notion统一管理，并更新了hexo和主题版本，正在逐个完善并重新上传之前的博客内容 文章搬运基本完成，删除了一些未完成的文章，之后再挨着整理一下格式即可 notion上的文章之后会拣比较好的搬运到这边来","tags":[{"name":"博客搭建","slug":"博客搭建","permalink":"https://www.delta1037.cn/tags/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"},{"name":"部署","slug":"部署","permalink":"https://www.delta1037.cn/tags/%E9%83%A8%E7%BD%B2/"}]},{"title":"Latex fontspec Error","date":"2023-02-05T16:00:00.000Z","path":"2023/Bugsfix/LatexfontspecError/","text":"latex编译时，出现报错! Package fontspec Error: The font &quot;Microsoft YaHei&quot; cannot be found. 排查问题记录与问题的思考。 一、环境 window11 texlive 2022 一份带有中文的tex文件 12# 中文环境配置\\usepackage[UTF8]&#123;ctex&#125; 二、问题在执行xelatex *.tex时，出现如下报错： 12345678910111213141516171819202122Package biblatex Warning: &#x27;babel/polyglossia&#x27; detected but &#x27;csquotes&#x27; missing.(biblatex) Loading &#x27;csquotes&#x27; recommended.(e:/texlive/2022/texmf-dist/tex/latex/newpx/TeXGyrePagellaX.fontspec)(./main.aux)*geometry* driver: auto-detecting*geometry* detected driver: xetex(e:/texlive/2022/texmf-dist/tex/latex/biblatex/lbx/english.lbx)No file main.bbl.Package hyperref Warning: Rerun to get /PageLabels entry.! Package fontspec Error: The font &quot;Microsoft YaHei&quot; cannot be found.For immediate help type H &lt;return&gt;. ...l.79 ...sep=1cm]&#123;\\Huge\\centering\\bfseries\\sffamily \\parbox[c][][t]&#123;\\paperwidt...? 已知该字体已安装（解决过程中也重装该字体很多次） 三、解决看到! Package fontspec Error: The font &quot;Microsoft YaHei&quot; cannot be found时，判断为字体没有识别，于是尝试重装该字体，重新加载字体缓存等操作，均无效（搞了一下午的字体问题，还把window10上的字体拷贝过来重新安装了）。 恰好手边有另一份带有中文的tex源文件（并不知道其中是如何配置的中文环境，只是有试一试的想法），于是尝试编译，结果成功了。 那么报字体问题的错误，问题根源是否出在字体问题上呢？再回顾模板的下载和修改过程，发现有一段数学符号包是后来添加的： 123456\\usepackage&#123;esint&#125;\\newcommand&#123;\\gt&#125;&#123;\\textgreater&#125;\\newcommand&#123;\\lt&#125;&#123;\\textless&#125;\\usepackage&#123;euler&#125;\\usepackage&#123;newpxtext&#125;\\usepackage&#123;amsmath&#125; 使用排除法（将上面所有的包全注释掉，一个一个添加），发现是newpxtext的问题，去掉该包之后，执行xelatex *.tex时，没有再出现报错。 四、思考虽然终端显示的是字体问题，但是当字体确实没有问题的时候，就要考虑别的方向，做一些并行测试来对比分析（例如上面在另外一份类似的tex工程中尝试编译）。 另外要仔细分析日志，再看日志最后一部分时，可以看到有以下疑点： 123456789101112131415161718192021222324252627(e:/texlive/2022/texmf-dist/tex/latex/realscripts/realscripts.sty))Package biblatex Warning: &#x27;babel/polyglossia&#x27; detected but &#x27;csquotes&#x27; missing.(biblatex) Loading &#x27;csquotes&#x27; recommended.# 1、这里出现的最后的包是newpx，就是newpxtext(e:/texlive/2022/texmf-dist/tex/latex/&lt;font color=&quot;#D44C47&quot;&gt;**newpx**&lt;/font&gt;/TeXGyrePagellaX.fontspec)# 2、这里来看，有几个包含中文的文件都已经通过了，所以有可能不是字体问题&lt;font color=&quot;#D44C47&quot;&gt;(./main.aux (./sub_chapter/01-basic_block.aux)(./sub_chapter/02-advance_block.aux) (./sub_chapter/03-database.aux)(./sub_chapter/04-multi_media.aux) (./sub_chapter/05-insert_block.aux)(./sub_chapter/06-rich_text.aux) (./sub_chapter/07-database_op.aux)(./sub_chapter/08-database_formula.aux))&lt;/font&gt;*geometry* driver: auto-detecting*geometry* detected driver: xetex(e:/texlive/2022/texmf-dist/tex/latex/biblatex/lbx/english.lbx)No file main.bbl.! Package fontspec Error: The font &quot;Microsoft YaHei&quot; cannot be found.For immediate help type H &lt;return&gt;. ...l.79 ...sep=1cm]&#123;\\Huge\\centering\\bfseries\\sffamily \\parbox[c][][t]&#123;\\paperwidt...? 完整的输出日志： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277PS F:\\GitHubRepo\\LatexBook\\Notion_handout_latex&gt; xelatex mainThis is XeTeX, Version 3.141592653-2.6-0.999994 (TeX Live 2022) (preloaded format=xelatex) restricted \\write18 enabled.entering extended mode(./main.texLaTeX2e &lt;2022-11-01&gt; patch level 1L3 programming layer &lt;2023-02-02&gt;(e:/texlive/2022/texmf-dist/tex/latex/base/book.clsDocument Class: book 2022/07/02 v1.4n Standard LaTeX document class(e:/texlive/2022/texmf-dist/tex/latex/base/fleqn.clo)(e:/texlive/2022/texmf-dist/tex/latex/base/bk11.clo)) (./structure.tex(e:/texlive/2022/texmf-dist/tex/latex/graphics/graphicx.sty(e:/texlive/2022/texmf-dist/tex/latex/graphics/keyval.sty)(e:/texlive/2022/texmf-dist/tex/latex/graphics/graphics.sty(e:/texlive/2022/texmf-dist/tex/latex/graphics/trig.sty)(e:/texlive/2022/texmf-dist/tex/latex/graphics-cfg/graphics.cfg)(e:/texlive/2022/texmf-dist/tex/latex/graphics-def/xetex.def)))(e:/texlive/2022/texmf-dist/tex/latex/lipsum/lipsum.sty(e:/texlive/2022/texmf-dist/tex/latex/l3packages/l3keys2e/l3keys2e.sty(e:/texlive/2022/texmf-dist/tex/latex/l3kernel/expl3.sty(e:/texlive/2022/texmf-dist/tex/latex/l3backend/l3backend-xetex.def)))(e:/texlive/2022/texmf-dist/tex/latex/lipsum/lipsum.ltd.tex))(e:/texlive/2022/texmf-dist/tex/latex/pgf/frontendlayer/tikz.sty(e:/texlive/2022/texmf-dist/tex/latex/pgf/basiclayer/pgf.sty(e:/texlive/2022/texmf-dist/tex/latex/pgf/utilities/pgfrcs.sty(e:/texlive/2022/texmf-dist/tex/generic/pgf/utilities/pgfutil-common.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/utilities/pgfutil-latex.def)(e:/texlive/2022/texmf-dist/tex/generic/pgf/utilities/pgfrcs.code.tex(e:/texlive/2022/texmf-dist/tex/generic/pgf/pgf.revision.tex)))(e:/texlive/2022/texmf-dist/tex/latex/pgf/basiclayer/pgfcore.sty(e:/texlive/2022/texmf-dist/tex/latex/pgf/systemlayer/pgfsys.sty(e:/texlive/2022/texmf-dist/tex/generic/pgf/systemlayer/pgfsys.code.tex(e:/texlive/2022/texmf-dist/tex/generic/pgf/utilities/pgfkeys.code.tex(e:/texlive/2022/texmf-dist/tex/generic/pgf/utilities/pgfkeyslibraryfiltered.code.tex)) (e:/texlive/2022/texmf-dist/tex/generic/pgf/systemlayer/pgf.cfg)(e:/texlive/2022/texmf-dist/tex/generic/pgf/systemlayer/pgfsys-xetex.def(e:/texlive/2022/texmf-dist/tex/generic/pgf/systemlayer/pgfsys-dvipdfmx.def(e:/texlive/2022/texmf-dist/tex/generic/pgf/systemlayer/pgfsys-common-pdf.def))))(e:/texlive/2022/texmf-dist/tex/generic/pgf/systemlayer/pgfsyssoftpath.code.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/systemlayer/pgfsysprotocol.code.tex)) (e:/texlive/2022/texmf-dist/tex/latex/xcolor/xcolor.sty(e:/texlive/2022/texmf-dist/tex/latex/graphics-cfg/color.cfg)(e:/texlive/2022/texmf-dist/tex/latex/graphics/mathcolor.ltx))(e:/texlive/2022/texmf-dist/tex/generic/pgf/basiclayer/pgfcore.code.tex(e:/texlive/2022/texmf-dist/tex/generic/pgf/math/pgfmath.code.tex(e:/texlive/2022/texmf-dist/tex/generic/pgf/math/pgfmathutil.code.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/math/pgfmathparser.code.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.code.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.basic.code.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.trigonometric.code.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.random.code.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.comparison.code.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.base.code.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.round.code.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.misc.code.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.integerarithmetics.code.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/math/pgfmathcalc.code.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/math/pgfmathfloat.code.tex))(e:/texlive/2022/texmf-dist/tex/generic/pgf/math/pgfint.code.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepoints.code.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepathconstruct.code.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepathusage.code.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/basiclayer/pgfcorescopes.code.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/basiclayer/pgfcoregraphicstate.code.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/basiclayer/pgfcoretransformations.code.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/basiclayer/pgfcorequick.code.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreobjects.code.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepathprocessing.code.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/basiclayer/pgfcorearrows.code.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreshade.code.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreimage.code.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreexternal.code.tex) (e:/texlive/2022/texmf-dist/tex/generic/pgf/basiclayer/pgfcorelayers.code.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/basiclayer/pgfcoretransparency.code.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepatterns.code.tex) (e:/texlive/2022/texmf-dist/tex/generic/pgf/basiclayer/pgfcorerdf.code.tex))) (e:/texlive/2022/texmf-dist/tex/generic/pgf/modules/pgfmoduleshapes.code.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/modules/pgfmoduleplot.code.tex)(e:/texlive/2022/texmf-dist/tex/latex/pgf/compatibility/pgfcomp-version-0-65.sty)(e:/texlive/2022/texmf-dist/tex/latex/pgf/compatibility/pgfcomp-version-1-18.sty)) (e:/texlive/2022/texmf-dist/tex/latex/pgf/utilities/pgffor.sty(e:/texlive/2022/texmf-dist/tex/latex/pgf/utilities/pgfkeys.sty(e:/texlive/2022/texmf-dist/tex/generic/pgf/utilities/pgfkeys.code.tex))(e:/texlive/2022/texmf-dist/tex/latex/pgf/math/pgfmath.sty(e:/texlive/2022/texmf-dist/tex/generic/pgf/math/pgfmath.code.tex))(e:/texlive/2022/texmf-dist/tex/generic/pgf/utilities/pgffor.code.tex))(e:/texlive/2022/texmf-dist/tex/generic/pgf/frontendlayer/tikz/tikz.code.tex(e:/texlive/2022/texmf-dist/tex/generic/pgf/libraries/pgflibraryplothandlers.code.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/modules/pgfmodulematrix.code.tex)(e:/texlive/2022/texmf-dist/tex/generic/pgf/frontendlayer/tikz/libraries/tikzlibrarytopaths.code.tex)))(e:/texlive/2022/texmf-dist/tex/generic/babel/babel.sty(e:/texlive/2022/texmf-dist/tex/generic/babel/xebabel.def)(e:/texlive/2022/texmf-dist/tex/generic/babel-english/english.ldf))(e:/texlive/2022/texmf-dist/tex/generic/babel/locale/en/babel-english.tex)(e:/texlive/2022/texmf-dist/tex/latex/enumitem/enumitem.sty)(e:/texlive/2022/texmf-dist/tex/latex/booktabs/booktabs.sty)(e:/texlive/2022/texmf-dist/tex/latex/geometry/geometry.sty(e:/texlive/2022/texmf-dist/tex/generic/iftex/ifvtex.sty(e:/texlive/2022/texmf-dist/tex/generic/iftex/iftex.sty)))(e:/texlive/2022/texmf-dist/tex/latex/psnfss/avant.sty)(e:/texlive/2022/texmf-dist/tex/latex/psnfss/mathptmx.sty)(e:/texlive/2022/texmf-dist/tex/latex/microtype/microtype.sty(e:/texlive/2022/texmf-dist/tex/latex/etoolbox/etoolbox.sty)(e:/texlive/2022/texmf-dist/tex/latex/microtype/microtype-xetex.def)(e:/texlive/2022/texmf-dist/tex/latex/microtype/microtype.cfg))(e:/texlive/2022/texmf-dist/tex/latex/base/inputenc.styPackage inputenc Warning: inputenc package ignored with utf8 based engines.) (e:/texlive/2022/texmf-dist/tex/latex/base/fontenc.sty(e:/texlive/2022/texmf-dist/tex/latex/psnfss/t1ptm.fd))(e:/texlive/2022/texmf-dist/tex/latex/biblatex/biblatex.sty(e:/texlive/2022/texmf-dist/tex/generic/pdftexcmds/pdftexcmds.sty(e:/texlive/2022/texmf-dist/tex/generic/infwarerr/infwarerr.sty)(e:/texlive/2022/texmf-dist/tex/generic/ltxcmds/ltxcmds.sty))(e:/texlive/2022/texmf-dist/tex/latex/kvoptions/kvoptions.sty(e:/texlive/2022/texmf-dist/tex/latex/kvsetkeys/kvsetkeys.sty))(e:/texlive/2022/texmf-dist/tex/latex/logreq/logreq.sty(e:/texlive/2022/texmf-dist/tex/latex/logreq/logreq.def))(e:/texlive/2022/texmf-dist/tex/latex/base/ifthen.sty)(e:/texlive/2022/texmf-dist/tex/latex/url/url.sty)(e:/texlive/2022/texmf-dist/tex/latex/biblatex/blx-dm.def)(e:/texlive/2022/texmf-dist/tex/latex/biblatex/blx-unicode.def)(e:/texlive/2022/texmf-dist/tex/latex/biblatex/blx-compat.def)(e:/texlive/2022/texmf-dist/tex/latex/biblatex/biblatex.def)(e:/texlive/2022/texmf-dist/tex/latex/biblatex/bbx/numeric.bbx(e:/texlive/2022/texmf-dist/tex/latex/biblatex/bbx/standard.bbx))(e:/texlive/2022/texmf-dist/tex/latex/biblatex/cbx/numeric.cbx)(e:/texlive/2022/texmf-dist/tex/latex/biblatex/biblatex.cfg)Package biblatex Warning: &#x27;babel&#x27; option is deprecated.(biblatex) Please use &#x27;autolang&#x27; instead.(e:/texlive/2022/texmf-dist/tex/latex/biblatex/blx-case-expl3.sty(e:/texlive/2022/texmf-dist/tex/latex/l3packages/xparse/xparse.sty)))(e:/texlive/2022/texmf-dist/tex/latex/tools/calc.sty)(e:/texlive/2022/texmf-dist/tex/latex/base/makeidx.sty)Writing index file main.idx(e:/texlive/2022/texmf-dist/tex/latex/titlesec/titletoc.sty)(e:/texlive/2022/texmf-dist/tex/latex/fancyhdr/fancyhdr.sty)(e:/texlive/2022/texmf-dist/tex/latex/amsmath/amsmath.styFor additional information on amsmath, use the `?&#x27; option.(e:/texlive/2022/texmf-dist/tex/latex/amsmath/amstext.sty(e:/texlive/2022/texmf-dist/tex/latex/amsmath/amsgen.sty))(e:/texlive/2022/texmf-dist/tex/latex/amsmath/amsbsy.sty)(e:/texlive/2022/texmf-dist/tex/latex/amsmath/amsopn.sty))(e:/texlive/2022/texmf-dist/tex/latex/amsfonts/amsfonts.sty)(e:/texlive/2022/texmf-dist/tex/latex/amsfonts/amssymb.sty)(e:/texlive/2022/texmf-dist/tex/latex/amscls/amsthm.sty)(e:/texlive/2022/texmf-dist/tex/latex/mdframed/mdframed.sty(e:/texlive/2022/texmf-dist/tex/latex/zref/zref-abspage.sty(e:/texlive/2022/texmf-dist/tex/latex/zref/zref-base.sty(e:/texlive/2022/texmf-dist/tex/generic/kvdefinekeys/kvdefinekeys.sty)(e:/texlive/2022/texmf-dist/tex/generic/etexcmds/etexcmds.sty)(e:/texlive/2022/texmf-dist/tex/latex/auxhook/auxhook.sty))(e:/texlive/2022/texmf-dist/tex/latex/base/atbegshi-ltx.sty))(e:/texlive/2022/texmf-dist/tex/latex/needspace/needspace.sty)(e:/texlive/2022/texmf-dist/tex/latex/mdframed/md-frame-0.mdf))(e:/texlive/2022/texmf-dist/tex/latex/hyperref/hyperref.sty(e:/texlive/2022/texmf-dist/tex/generic/pdfescape/pdfescape.sty)(e:/texlive/2022/texmf-dist/tex/latex/hycolor/hycolor.sty)(e:/texlive/2022/texmf-dist/tex/latex/letltxmacro/letltxmacro.sty)(e:/texlive/2022/texmf-dist/tex/latex/hyperref/nameref.sty(e:/texlive/2022/texmf-dist/tex/latex/refcount/refcount.sty)(e:/texlive/2022/texmf-dist/tex/generic/gettitlestring/gettitlestring.sty))(e:/texlive/2022/texmf-dist/tex/latex/hyperref/pd1enc.def)(e:/texlive/2022/texmf-dist/tex/generic/intcalc/intcalc.sty)(e:/texlive/2022/texmf-dist/tex/latex/hyperref/puenc.def)(e:/texlive/2022/texmf-dist/tex/generic/bitset/bitset.sty(e:/texlive/2022/texmf-dist/tex/generic/bigintcalc/bigintcalc.sty)))(e:/texlive/2022/texmf-dist/tex/latex/hyperref/hxetex.def(e:/texlive/2022/texmf-dist/tex/generic/stringenc/stringenc.sty)(e:/texlive/2022/texmf-dist/tex/latex/rerunfilecheck/rerunfilecheck.sty(e:/texlive/2022/texmf-dist/tex/latex/base/atveryend-ltx.sty)(e:/texlive/2022/texmf-dist/tex/generic/uniquecounter/uniquecounter.sty)))Package hyperref Warning: Option `backref&#x27; has already been used,(hyperref) setting the option has no effect on input line 504.Package hyperref Warning: Option `pagebackref&#x27; has already been used,(hyperref) setting the option has no effect on input line 504.Package hyperref Warning: Option `hyperindex&#x27; has already been used,(hyperref) setting the option has no effect on input line 504.Package hyperref Warning: Option `bookmarks&#x27; has already been used,(hyperref) setting the option has no effect on input line 504.(e:/texlive/2022/texmf-dist/tex/latex/bookmark/bookmark.sty(e:/texlive/2022/texmf-dist/tex/latex/bookmark/bkm-dvipdfm.def)))(e:/texlive/2022/texmf-dist/tex/latex/ctex/ctex.sty(e:/texlive/2022/texmf-dist/tex/latex/ctex/ctexhook.sty)(e:/texlive/2022/texmf-dist/tex/latex/ctex/ctexpatch.sty)(e:/texlive/2022/texmf-dist/tex/latex/base/fix-cm.sty(e:/texlive/2022/texmf-dist/tex/latex/base/ts1enc.def))(e:/texlive/2022/texmf-dist/tex/latex/ctex/config/ctexopts.cfg)(e:/texlive/2022/texmf-dist/tex/latex/ctex/engine/ctex-engine-xetex.def(e:/texlive/2022/texmf-dist/tex/xelatex/xecjk/xeCJK.sty(e:/texlive/2022/texmf-dist/tex/latex/l3packages/xtemplate/xtemplate.sty)(e:/texlive/2022/texmf-dist/tex/latex/fontspec/fontspec.sty(e:/texlive/2022/texmf-dist/tex/latex/fontspec/fontspec-xetex.sty(e:/texlive/2022/texmf-dist/tex/latex/base/fontenc.sty)(e:/texlive/2022/texmf-dist/tex/latex/fontspec/fontspec.cfg)))(e:/texlive/2022/texmf-dist/tex/xelatex/xecjk/xeCJK.cfg)))(e:/texlive/2022/texmf-dist/tex/latex/zhnumber/zhnumber.sty(e:/texlive/2022/texmf-dist/tex/latex/zhnumber/zhnumber-utf8.cfg))(e:/texlive/2022/texmf-dist/tex/latex/ctex/scheme/ctex-scheme-chinese.def(e:/texlive/2022/texmf-dist/tex/latex/ctex/config/ctex-name-utf8.cfg))(e:/texlive/2022/texmf-dist/tex/latex/tools/indentfirst.sty)(e:/texlive/2022/texmf-dist/tex/latex/ctex/fontset/ctex-fontset-windows.def))(e:/texlive/2022/texmf-dist/tex/latex/ctex/config/ctex.cfg)(e:/texlive/2022/texmf-dist/tex/latex/esint/esint.sty)(e:/texlive/2022/texmf-dist/tex/latex/euler/euler.styPackage: `euler&#x27; v2.5 &lt;1995/03/05&gt; (FJ and FMi)) (e:/texlive/2022/texmf-dist/tex/latex/newpx/newpxtext.sty`newpxtext&#x27; v1.504, 2022/01/30 Text macros taking advantage of TeXGyre Pagellaand its extensions (msharpe)(e:/texlive/2022/texmf-dist/tex/latex/base/fontenc.sty(e:/texlive/2022/texmf-dist/tex/latex/lm/t1lmr.fd))(e:/texlive/2022/texmf-dist/tex/generic/iftex/ifxetex.sty)(e:/texlive/2022/texmf-dist/tex/generic/iftex/ifluatex.sty)(e:/texlive/2022/texmf-dist/tex/latex/xkeyval/xkeyval.sty(e:/texlive/2022/texmf-dist/tex/generic/xkeyval/xkeyval.tex(e:/texlive/2022/texmf-dist/tex/generic/xkeyval/xkvutils.tex)))(e:/texlive/2022/texmf-dist/tex/latex/base/textcomp.sty)(e:/texlive/2022/texmf-dist/tex/generic/xstring/xstring.sty(e:/texlive/2022/texmf-dist/tex/generic/xstring/xstring.tex))(e:/texlive/2022/texmf-dist/tex/latex/carlisle/scalefnt.sty)(e:/texlive/2022/texmf-dist/tex/latex/realscripts/realscripts.sty))Package biblatex Warning: &#x27;babel/polyglossia&#x27; detected but &#x27;csquotes&#x27; missing.(biblatex) Loading &#x27;csquotes&#x27; recommended.(e:/texlive/2022/texmf-dist/tex/latex/newpx/TeXGyrePagellaX.fontspec)(./main.aux (./sub_chapter/01-basic_block.aux)(./sub_chapter/02-advance_block.aux) (./sub_chapter/03-database.aux)(./sub_chapter/04-multi_media.aux) (./sub_chapter/05-insert_block.aux)(./sub_chapter/06-rich_text.aux) (./sub_chapter/07-database_op.aux)(./sub_chapter/08-database_formula.aux))*geometry* driver: auto-detecting*geometry* detected driver: xetex(e:/texlive/2022/texmf-dist/tex/latex/biblatex/lbx/english.lbx)No file main.bbl.! Package fontspec Error: The font &quot;Microsoft YaHei&quot; cannot be found.For immediate help type H &lt;return&gt;. ...l.79 ...sep=1cm]&#123;\\Huge\\centering\\bfseries\\sffamily \\parbox[c][][t]&#123;\\paperwidt...?","tags":[{"name":"Bug","slug":"Bug","permalink":"https://www.delta1037.cn/tags/Bug/"},{"name":"Latex","slug":"Latex","permalink":"https://www.delta1037.cn/tags/Latex/"}]},{"title":"应用程序设计","date":"2022-03-04T16:00:00.000Z","path":"2022/Project/应用程序设计/","text":"三年工作经验之成果，简要概述了应用程序的设计过程~以下没有参考任何文档，纯属瞎编！ 一、模块划分模块是为了让大型应用程序的结构更加清晰，在对程序进行重构或者修改模块的功能时更加方便。模块一般需要根据功能类型区分，一般功能包括以下几种： 日志记录：用于程序运行过程的打点记录，在程序运行出错时能够定位到出错位置和相关必要数据 DEBUG日志：调试时使用，包括详细的调试信息，程序出错时辅助调试 INFO日志：记录程序运行记录，打卡记录 ERROR日志：记录程序出错记录 数据记录：程序相关的大量数据条目记录，一般与数据库接壤 配置记录：程序配置相关，配置参数则使用文本文件记录（JSON格式、YAML格式等） 会话控制：网络连接模块，用于控制两个程序之间的通信 会话协议：两个程序的会话需要制定明确的会话协议 任务控制：多线程程序 任务启动、停止、回收控制 卡死线程处理 缓存控制：缓存文件数据或者网络数据（辅助快速加载） 1.1 日志记录对于一个日志记录模块，最主要的功能就是提供日志记录功能。其它功能如下： 日志的输出等级：可以选择日志输出的最低等级（低于此等级的日志不输出） 日志输出位置：可以输出到终端、保存到文件。 日志保存到文件时，对于不同模块的日志可以选择保存到到不同的文件；当文件过大时，将日志内容归档管理。 1.2 数据记录在对接到应用程序的上层部分，一般需要根据程序的具体需求定制（比如存储什么数据，许需要哪些数据操作接口（增删查改之类的））。在数据记录的底层部分，可以支持多种数据库类型，方便数据库的切换，或者使用不同的数据库完成不同的需求（瞎猜的，实际没有遇到过）。 该模块可以设计为细腰型结构，包括上层对接具体需求，中层管理，底层聚合多种数据库类型。这种结构一方面是便于新增新的功能或者支持新的数据库；另一方面是方便移植到另一个应用程序上（只需要替换上层部分即可）。细腰型结构示例： graph TD A(数据需求1) --> B(管理) C(数据需求2) --> B(管理) B(管理) --> D[Mysql] B(管理) --> E[SQLITE] 1.3 配置记录配置模块和日志模块一样，都是应用程序的基础。配置用来初始化一些应用程序的参数，如果把这些参数写入到程序内部，那么在需要调整参数的时候就会很麻烦（重新编译程序），所以需要与应用程序隔离的文件来存储一些在程序启动时可能会发生改变的内容。 配置模块需要对应用程序提供的基本功能是根据key来获取对应的值，即获取某个参数的值；配置模块也可以添加一些高级功能，例如向配置文件写入一个参数的值；当程序运行时，如果监测到配置发生改变时，对程序中对应的参数重新初始化。 配置的存储需要与应用程序的语言相适应。C&#x2F;C++一般使用一行即为一个参数配置（使用“：”或者“&#x3D;”隔离参数的key和value）；Python可以很方便的使用json库，所以可以使用JSON文件作为配置文件。 1.4 会话控制会话控制模块一般用于本地或者网络上的两个进程间的通信。通信则一般分为同步和异步方式，同步通信方式就是进程A向进程B索要数据，A等着B完成，然后拿到数据；异步方式是进程A向进程B索要数据，确定B收到索要数据之后A立即返回，B开始准备数据，当B数据准备好之后将数据发送给A，A拿到数据。 会话控制模块一般分为两层，上层是会话协议层，下层是网络传输层，会话协议层主要定义两个程序之间的通信协议（A：你今天吃什么？B：我吃番茄炒鸡蛋），网络传输部分主要是定义信息传输的方式（怎么把”你今天吃什么？“这句话发出去），一般有Socket（TCP&#x2F;UDP）、HTTP等。 graph TD subgraph 从 E(从:会话协议) C(从:网络传输) end subgraph 主 A(主:会话协议) B(主:网络传输) end 1.5 任务控制一般的多任务程序中都需要任务管理，多任务即为多线程任务，多线程任务包括临时任务、持久化任务等等。任务控制模块可以提供任务控制功能，基本的包括启动任务和终止任务，更复杂点的包括任务的活性监测（监测线程是否卡住）。 多任务模块需要考虑的点有： 基本功能： 启动任务：开启一个新的线程，此时需要数据传入和函数传入（不同的类型其处理函数也不一样，处理函数也需要不同的数据，需要考虑的是怎么把开启新线程的接口统一：封装统一的数据结构相对来说是一种扩展性很强的方案） 终止任务：当任务没有分离时，使用的计算机语言一般会提供回收的方式 活性监测：任务开启时注册一个定时器，当定时器结束时说明任务还没有退出（如果进程提前退出则说明该任务实例已经被销毁（注意销毁任务实例的定时器处理）） 1.6 缓存控制缓存控制的目的是存储一些临时性的数据，用来保存数据或者加速访问某些内容。一般应用是可以缓存其它模块的数据内容（比如会话控制的会话数据和任务控制的任务数据）或者需要加速访问的内容（从文件中读取的一些内容、从网络上获取到的内容，这些内容如果重新获取对于一个对运行时间有要求的程序来说时间成本过大。但是要注意，这些内容短期内不会发生变化，如果这些内容每次获取都不一样，那么或许重新获取是无法避免的） 缓存控制的设计比较灵活，一般需要根据实际的应用程序设计（具体问题具体分析）。对于一些常规性的存储内容（其它模块需要存储的数据）则可以统一实现，减少重复造轮子的可能性。 二、逻辑2.1 必要逻辑计算机语言都会（所有的）包含一些必要的逻辑，包括： 数据操作：保存数据、打印数据 顺序执行：逐条执行代码 循环处理：循环执行某段代码 条件处理：根据条件判断是否执行某段代码 函数封装：将某一个小功能封装成函数 2.2 类的概念继承和多态（待补充） 对于含有类概念的计算机语言（C++、Python）： 类的概念比函数封装更进一步。函数封装只会封装单个的功能；类则封装了数据和多个功能，即包含了数据和处理数据的方法。类的一个实例通常称为对象（类可以描述为实例的蓝图，设计图），对象的出现使得类区别于数据和方法的集合。每一个类的对象都有自己的数据空间，使得不同的对象互相隔离。 模块的出现使得同类型的操作得以聚合。例如一个SQLITE数据库操作类，其中数据区域可以包括数据库的位置信息；操作方法包括增删查改等常用方法的集合。 将操作方法聚合成类和聚合成文件（无类）的区别。将操作方法封装成类时，数据定义保存在类中，方法定义保存在类中，当我们操作不同位置的数据库时，可以实例化多个对象，这些对象的区别仅有其中的数据区域（数据库的位置）；将操作方法汇聚成文件时，当我们操作不同位置的数据库时，可以定义空间来存储不同的数据库位置，当调用某一个数据库方法时，需要传入一些必要的内容（例如数据库的位置或者数据库操作句柄）等。 使用类的优势：类将数据定义和方法定义封装到一起，第一是类的进一步封装使得代码边界更加清晰，数据定义易于管理；第二是减少了不必要的外部数据的传入（类初始化时传入并在数据区域统一管理）。 2.3 模块的概念对于含有模块概念的计算机语言： 模块的概念比类的概念更宽泛，类是一种类型（奔驰）的方法的封装，模块可以认为是一类对象（奔驰、奥迪）的封装，实际上模块的分类包括日志记录模块，数据记录模块（里面可能包含了Mysql数据库操作对象和SQLITE数据库操作对象等多种类封装）。 模块的优势：模块将同一属性的内容封装（放）到一起，第一是方便不同模块的管理，方便模块替换（只要对外的API是不改变的，那么模块很容易被替换或者修改内部功能），便于代码的维护（在修改某一部分的功能时，直接到对应的模块修改）； 三、细节计算机语言只是实现目的的一种工具，不同的语言在对模块的实现上有不同的优势，在选用语言来完成某一功能时，需要考虑如下内容： 功能复杂性： 是否需要拆分成不同模块，模块之间的耦合 运行的平台： 运行环境的配置 运行速度要求：编译语言和脚本语言 时间控制精度要求：我之前用Shell写一个程序时，程序的时间很难控制（定时运行） 底层模块依赖：是否有精力进行从砖头开始垒房子，或者快速从墙片开始垒房子（一样结实的） 语言 优势 弱势 平台 分类 C 1、快 1、数据管理2、打地基 1、编译运行 高级 C++ 1、快 1、打地基 1、编译运行 高级 Python 1、库多 1、较慢（边解释边运行） 1、打包运行2、解释器运行 脚本 Shell 1、无需编译 1、数据管理2、复杂处理 1、解释器运行（Linux） 脚本 四、语言组合不同的语言是可以互通的，这样可以解决某一个语言的缺陷。例如Python调用C实现的动态库（以解决Python运行慢的问题）（实例：Numpy底层使用C语言编写，内部解除了GIL（全局解释器锁），其对数组的操作速度不受Python解释器的限制，效率远高于纯Python代码）。 其它代码互相调用的例子不再赘述。 五、程序设计在需求定义完成之后，就可以开始着手程序的架构设计，架构是语言无关的，最终无论用什么语言去实现这个程序都可以，只是存在难易度和细节的调整问题。难易度和细节指的是一个语言是否具有良好的生态（有没有现成的稳健的依赖包，或者自己有没有积攒一些常用的代码段等），另外就是程序在与外部对接的过程，有没有封装良好的接口。 程序架构的设计是基于需求的目标的，是一个有目的的设计。为了完成最终的目标，我们需要让各个模块按照我们目标运作起来。动起来是最基本的，我们还需要考虑之后的维护过程，怎么让代码更好的去维护，另外还有考虑代码的复用性，这些代码能不能封装起来在之后的项目中使用。 软件工程中有一个名为“高内聚、低耦合”的概念，我们在写代码之前就需要考试考虑好这个问题，低耦合是为了让基本不相关的内容分离设计，高内聚是让一个模块恰好做一件事。在低耦合方面，如果日志模块和缓存模块纠缠在一起，再加一个数据库模块的话难道要再重写一个日志模块？再高内聚方面，一个日志模块不需要分散开写成多个部分，日志模块就是提供一个稳定的标准的日志接口，里面怎么实现是不需要调用者关注的。本人觉得做好“高内聚、低耦合”就能得到一份好维护，复用性强的代码。 做好程序架构的设计之后，就可以开始做语言的选型，从划分的各个模块入手开始做代码的编写。在做语言的选型问题的时候，要考虑与外部对接的难易度，例如与数据库的对接，与外部接口的对接等等，有的语言例如python对这些有很好的支持，但是C++就需要仔细考虑怎么对接的问题。","tags":[{"name":"程序设计","slug":"程序设计","permalink":"https://www.delta1037.cn/tags/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/"},{"name":"系统","slug":"系统","permalink":"https://www.delta1037.cn/tags/%E7%B3%BB%E7%BB%9F/"}]},{"title":"考研感想","date":"2021-12-27T16:00:00.000Z","path":"2021/Times/考研感想/","text":"22刚考完，趁着脑子清醒做一下总结 一、考试与估分本来准备等佛系出分的，早上看到有人发了专业课的答案，没忍住对了一下，然后就全对了一下答案。下边分享一下做题心理路程： 专业课：130。写上的差不多都对了，大题有两个小问没有写出来，还有一个小问忘记把参数代入计算了，只写了表达式。专业课是华科的824，一共有28个题吧，20个选择填空，写完发现只用了一个小时，五个只有一两问的题，大概用了一个小时（写完选择才用了一个小时啊啊啊，再抬头感觉时间就不够了，有的太难算的直接放弃了），开始最后三道大题剩一个小时，一道二十分钟，奈何慌的一批，疯狂赶进度，最后剩十分钟，没写的就不管了，检查了一遍，封口完事！ 数学：120。选择填空错了两个，有个选择记不清了，大题有个题没写出来，列了个公式，还有个大题的最后计算错了，但是步骤都是对的，其它的好像还行。选择填空一共用了一个小时左右，剩下的全在搞大题了（真是太难算了，刚拿到卷子心里乐开了花，心想这么简单，写着写着就哭了），写完选择填空把答题卡就画了轻轻的一下，想着大题写完再回来检查的（选择太多不确定的了），结果大题写的入迷了，最后十五分钟发现答题卡还没涂，人差点被吓傻了赶紧涂一下（所以最后十分钟就不要继续看题了，把卷子看一下，看看有没有什么需要补充的！） 英语：50。我英语不好，没什么好说的，完型错了一半，阅读+七选五应该错了一个还是两个，翻译能给一分就行，作文加起来给十分就行（写的邀请信狗都不来，大作文套的模板） 政治：50。政治也没啥好说的，我没有背诵的天赋，单选是错了两个左右，多选应该有四五个，所以选择大概能拿四十分，大题都写满了，希望赏给我十分。 综述：保350冲380。 二、考研感想 预谋：三四月份的时候就忽然觉得工作没啥意思，趁着年轻应该多学习。咨询了很多老师，和已经上了研究生的同学，以及一些工作的同学，相互交流了很多意见，工作有工作的好处，读研有读研的好处，各有各的难处，各方权衡下我觉得我想去试一试，因为我没考过研，总觉得差点什么。（之前有一个保研的机会我没有珍惜，这也没什么好后悔的，当时觉得工作很香，工作了一年才了解了工作这件事，工作中也收获了挺多，不算亏！） 辞职：主管来劝我，大概说我是应届生里比较强的（Dian团队出来的哪一个不强，就属我菜了），工作三年也可以拿到一个不亚于研究生的薪资水平，大概是我已经拿了一年的工资有点飘了，好说歹说最后还是辞职了（现在想想确实有点冲动，但是考完研后无论最后有没有考上我都有了更大的收获）。 开始：刚辞职的几天，那个浪啊！租的房子还没到期，每天睡到自然醒，偶尔女朋友过来一起做做饭啥的（做饭是我，刷碗也是我，女朋友参与了吃的部分），买了数学的复习资料，每天看个一两眼，过的挺快活！ 中期：高中的学习方式就是使劲刷题，但是大学和一群优秀的人待久了，又有了别的思路。首先是规划方面，每周我都会做周报，每个周日会安排这周的任务，然后每天完成一项就勾一项（一开始用的有道云笔记软件，后来发现了notion，哎呀妈呀真香），到了周日就对这周的东西做一下总结，看看完成情况（大部分都是完不成的，因为各种各样的原因，总而言之就是我有拖延症（此处应该@钟sir），没完成就完后拖呗，最后拖的实在太多了就削减任务，反正最后很多的题都没写，但是写过的都吃的很透，数学复习全书综合提高我认真刷了两边，最后马马虎虎又看了两遍）。然后就是笔记方面，数一的内容真的是多啊，我记笔记是因为从我二刷复习全书的时候发现前边的都忘了，这第二遍刷完再忘了咋办，果断开始记数学笔记（一刷没有记是因为我对数学还是很有信心的，后来发现忘得一干二净），后来因为发现了notion这个软件，记笔记挺方便的（其实主要是我写字太丑了，我一开始写了纸质的数学笔记，不忍直视。。。），然后开始记数学和专业课的笔记，刚开始记的时候真是太痛苦了，严重拖慢复习进度，一直咬牙坚持着，每周花费大量时间在记笔记上（最后看了一下统计一共得有十几万字了），后来复习完一轮回头看的时候，笔记还是很有用的，能够立马想起来这个地方的知识点都会出什么题（后期就不行了）。最后吧就是适当放松，不要一直紧绷着，该放松得放松。 后期：最后的一段时间我也是慌的一批，感觉啥都不会了（到考场上发现会了也没啥用）。做了最后一段时间的规划，填充的满满当当的（当然，最后大部分没搞完）。每隔一天做一套数学卷子保持手感；我这个专业课也是计算题也得保持手感；每天佛系背政治，刷刷选择题；最后几天发现英语单词忘了一些赶紧去补，每隔一天做一下阅读保持手感（最后几天了，做了20年的题，阅读+七选五错了13个，心态都崩了，还好最后英一阅读没有特别难的点，阅读做的很顺畅）。 总结：无论考没考过都不会再考了，这段考研的日子确实能让人收获很多，爷青结~ 三、资料以下只放我写过的，没写过的不好做出评价。 数学： 复习全书：看了四遍，知识比较系统，每一个知识后都有例题（我第一遍用来看基础知识点和看例题，第二遍不看答案刷了一遍例题并且标注一些难点的题，第三遍就是认真看一下重点标注的题，第四遍是快考试了，看了知识点和重点标注的题） 880：是个习题集就行，刷一遍作为巩固（微积分部分我只写了选择题，线代和概率论差不多都写了） 李艳芳的真题：这个老师出的真题讲解真是太棒了！讲解特别的详细（我是用来写完真题对答案的，我写完真题无论这道题有没有写对都会把答案看一遍，看看答案有没有什么好的思路） 历年真题全精解析：我用来巩固真题用的，看看哪一章都会出什么题（高数认真看了一遍，线代和概率论没来得及看） 一些视频：我的全部都是自学的，没看哪个老师的视频。最后的冲刺阶段在B站上看了李艳芳的高数知识梳理。 专业课： 刺猬哥的复习资料（真题、分类题、知识点）：整体来说挺好的，还有答疑服务（虽然我也没问几次，但是有了一个沟通题目的地方）；真题是熟悉题型用的，最重要；分类题是熟悉知识点用的；知识点那本我没咋看 信号与系统（奥本海姆）：专业课的课本，没啥好说的，我是先看了一遍课本，然后才开始写题的 黄皮书和绿皮书：专业课课本辅导资料，对课后的例题做讲解（今年好像有一个特别难的题是从绿皮书上出的，绿皮书很重要），这两本有重复的题目，对照着勾画一下，重复的题做一遍就行了 英语： 黄皮书：真题和讲解，没啥好说的，挺好用的 唐迟阅读的逻辑：看了一遍确实挺好用，看完之后记得做总结 语法新思维+长难句高分通关：我英语太差了，需要补语法（自知之明） 其它：买了一堆，没怎么写（新东方的资料几乎所有的都买了，除了那两本语法其它的没怎么写） 政治： 肖老的一套：必买，四套卷+八套卷+时政刷个心安，1000题也是必刷的（我有一门没刷完，后期转到小程序刷题了） 刷题软件：都一样的，能刷题就行了，这里因为这个刷题软件侵犯了原著的著作权就不提名字了 四、收尾前边放了大段的文字，下边放几张图 有道云笔记做的周报 notion做的周报 notion做的周报汇总 有道云做的数学计划 notion做的数学计划 notion做的英语阅读笔记 notion做的数学笔记","tags":[{"name":"考研","slug":"考研","permalink":"https://www.delta1037.cn/tags/%E8%80%83%E7%A0%94/"}]},{"title":"Typora图床配置","date":"2021-06-20T16:00:00.000Z","path":"2021/Deploy/Typora图床配置/","text":"Typora图床配置 一、开通阿里云对象存储阿里云对象存储页面 之后购买资源包和新建bucket即可，我所使用的是本地冗余的低频访问存储，因为这个便宜一些，主要是因为我的博客图片量比较少，访问频率不大。 具体阿里云方面的配置参考Typora+PicGo+阿里云OSS实现图片上传功能 二、Typora配置如下图所示 1、在图像-&gt;插入图片时可以选择在插入图片时先将图片拷贝到某一个位置，然后可以根据需要对其进行重命名(有关于此见暂未解决的问题1)，然后右键上传图片即可 2、在图像-&gt;上传服务设定可以设置上传服务，下图中选用PicGo-Core（因为上传图片使用命令行而不是后台常驻进程，减少系统资源消耗），选择完毕之后点击下载或更新可以自动安装；安装完毕之后选择打开配置文件 3、配置文件配置如下所示 text123456789101112131415161718192021&#123; &quot;picBed&quot;: &#123; // 图床的配置 &quot;uploader&quot;: &quot;aliyun&quot;, // 图床类型的选择，这里选择阿里云 &quot;aliyun&quot;: &#123; &quot;accessKeyId&quot;: &quot;xxxxxxxxxx&quot;, // 图床的访问ID &quot;accessKeySecret&quot;: &quot;xxxxxxxxxx&quot;, // 图床的访问密钥，具体设置参考 一、开通阿里云对象存储 &quot;bucket&quot;: &quot;bucket_name&quot;, // bucket名字 &quot;area&quot;: &quot;oss-cn-beijing&quot;, // bucket地区 &quot;path&quot;: &quot;hexo-blog/&quot;, // bucket内部文件夹 &quot;customUrl&quot;: &quot;delta1037.oss-cn-beijing.aliyuncs.com&quot;, // 外网访问bucket域名 &quot;options&quot;: &quot;&quot; &#125; &#125;, // PicGo插件相关配置，后续介绍 &quot;picgoPlugins&quot;: &#123; &quot;picgo-plugin-rename-file&quot;: true &#125;, &quot;picgo-plugin-rename-file&quot;: &#123; &quot;format&quot;: &quot;&#123;localFolder:1&#125;-&#123;origin&#125;&quot; &#125;&#125; 三、PicGo相关插件插件的安装需要系统中安装nodejs；以下安装插件命令的执行在PicGo的配置文件夹中(例如C:\\Users\\delta1037.picgo，在此文件中打开Powershell窗口即可) 3.1 picgo-plugin-rename-fileshell或者Powershell中执行安装命令 text1npm i picgo-plugin-rename-file 相应的配置解释如下 text1234567// PicGo插件相关配置&quot;picgoPlugins&quot;: &#123; &quot;picgo-plugin-rename-file&quot;: true // 控制插件的打开与关闭&#125;,&quot;picgo-plugin-rename-file&quot;: &#123; &quot;format&quot;: &quot;&#123;localFolder:1&#125;-&#123;origin&#125;&quot; // 上传图片时图片的重命名格式&#125; 具体的重命名格式参照github项目主页 暂未解决的问题 1、拷贝到Typora的图片不可以右键重命名（需要先粘贴图片，打开图片位置，重命名，修改Typora中对应的名字步骤，及其繁琐，等待后续Typora更新），相应的issue 2、阿里云设置防盗链之后，Typora上传图片之后无法正常显示","tags":[{"name":"博客搭建","slug":"博客搭建","permalink":"https://www.delta1037.cn/tags/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"},{"name":"Typora","slug":"Typora","permalink":"https://www.delta1037.cn/tags/Typora/"}]},{"title":"租房指南","date":"2021-05-24T16:00:00.000Z","path":"2021/Life/租房指南/","text":"租房指南。关于费用、房东&amp;中介、怎么找房东~ 一、费用问题 付款方式：押一付一、押一付三；交租方式，保留交租凭证 需要另付的费用由哪些：电费（商业用电和民用电：商业用电贵一些，可能由民用电的两倍）、水费、物业费、网费，家电维修费（对维修费用的出具人做出约定） 克扣押金：合同可以注明租期满后指定工作日内，在房屋或者其设施不存在人为损毁的情况下，应退还全部押金 二、房东&amp;中介 合同可以注明租赁房屋所在的位置、间数、面积、质量、设施清单、租赁期限、租金及支付期限与方式等 审查合同主体是否合格，即出租人与承租人是否具备相应的条件。审查租赁的客体是否合格，即出租人的房屋是否为法律、法规允许出租的房屋。审查房屋租赁手续是否完备。房屋产权证明并非是合法出租的充分条件，还应按有关规定办理房屋租赁许可证，租赁合同也要进行租赁登记方可生效。 房东直租&#x2F;中介：房东直租不需要中介费；如果找中介，中介费一般是房租的一半，在签订合同时一次性缴清 公寓公司：蛋壳自如之类的、一般租金较贵，注意除了每个月的租金之外是否还需要其它费用，一般会有打扫卫生的费用（服务费）；注意是否与银行签订贷款（蛋壳） 三、如何找房东直租现在找租房信息平台有很多，但是内容混杂很难分清是否是真实信息，例如： 在某网站上找的中介，一开始说自己不是蛋壳的，后来又承认是蛋壳的，然后一开始说不需要服务费，提出录音之后又改口 看到明显很“高大上”的房子，但是租金很便宜，一般是压价来吸引客户的，但是也可以问一问 在线看照片是看不准的，一定要线下看房 3.1 找房东直租的方法 豆瓣租房小组上有很多发布的房源信息 八爪鱼采集器来爬取数据相当好用 众所周知，一个人是不可能有七八套房的（特别厉害的当我没说），根据每个用户的发布房源数量来手动做数据清洗 单个用户一直发同一套房那就大概率是房东了 Oh以上整理于毕业租房的真实经历，最后找到了一个比较满意的房子，网上的照片拍的效果太差，最后才看的，线下看还行，所以一定要线下看一下","tags":[{"name":"租房","slug":"租房","permalink":"https://www.delta1037.cn/tags/%E7%A7%9F%E6%88%BF/"},{"name":"生活","slug":"生活","permalink":"https://www.delta1037.cn/tags/%E7%94%9F%E6%B4%BB/"}]},{"title":"Terraria服务端搭建","date":"2021-05-19T16:00:00.000Z","path":"2021/Game/Terraria服务端搭建/","text":"Terraria服务端搭建 一、环境准备 Linux x86_64（CentOS 8） 二、搭建2.1 下载官网地址最下方点击PC Dedicated Server（此链接版本为1423版本，当steam启动时更新时，服务端也要做相应的更新）即可下载最新版本的服务端，其中包括Linux&#x2F;Window&#x2F;Mac版本。 2.2 安装将下载到的包上传到服务端 text123456789# 创建存放服务端文件的目录mkdir -p /opt/terraria_server# 解压文件到目录unzip terrraria-server-1423.zip -d /opt/terraria_server# 进入到解压后的Linux对应的目录，并给文件执行权限cd /opt/terraria_server/1423/Linuxchmod +x -R ./ # 注意这里是图方便给改文件夹下所有的文件赋予了可执行权限，也可以单独给需要的文件赋予可执行权限 2.3 配置配置文件 text123# 创建并编辑配置文件## 创建在外层目录不影响更新服务端版本vim /opt/terraria_server/terraria_config 配置内容可填写如下： text12345678910111213141516171819# 启动时选择的地图的路径world=/opt/terraria_server/Worlds/delta1037.wld# 最大连接玩家个数maxplayers=3# 连接密码password=******# 指定端口，默认是7777port=6666# 语言配置language=zh# 当地图不存在时创建新地图的配置## 地图难度difficulty=0## 地图大小 1(小), 2(中), and 3(大).autocreate=3## 地图路径和名字worldpath=/opt/terraria_server/Worldsworldname=delta1037.wld 完整的配置见Terraria官方配置说明 三、启动服务端text12345# 进入到主程序目录cd /opt/terraria_server/1423/Linux# 使用配置文件启动./TerrariaServer.bin.x86_64 -config /opt/terraria_server/terraria_config 参考【0】Linux搭建泰拉瑞亚服务器","tags":[{"name":"Terraria","slug":"Terraria","permalink":"https://www.delta1037.cn/tags/Terraria/"},{"name":"游戏","slug":"游戏","permalink":"https://www.delta1037.cn/tags/%E6%B8%B8%E6%88%8F/"}]},{"title":"tModLoader服务端搭建","date":"2021-05-19T16:00:00.000Z","path":"2021/Game/tModLoader服务端搭建/","text":"tModLoader服务端搭建。 tModLoader是Terraria的Mod版本，服务端发布在github，tModLoader服务端的运行需要Terraria的服务端的支持。 一、环境准备 Linux x86_64（CentOS 8） 二、搭建2.1 下载在tModLoader发布页下载最新版本的发布版本，并在Terraria官网地址最下方点击PC Dedicated Server（此链接版本为1423版本）即可下载最新版本的Terraria服务端。获取到包： terraria-server-1423.zip ： Terraria最新安装包 tModLoader.Linux.v0.11.8.4.zip ： tModLoader最新发布的包 2.2 安装安装服务端： text1234567891011121314# 创建服务端安装位置，并切换到安装位置mkdir -p /opt/t_mod_server/servercd /opt/t_mod_server/server# 将Terraria的服务端的安装包拷贝到安装位置并使用unzip解压unzip terraria-server-1423.zip# 将解压的文件拷贝到当前目录中cp -r 1423/Linux/* ./# 将tModLoader的安装包拷贝到安装位置并使用unzip解压，这个时候tModLoader解压的文件会替换Terraria服务端文件中的部分文件unzip tModLoader.Linux.v0.11.8.4.zip# 给文件赋予可执行权限chmod +x -R ./ # 注意这里是图方便给改文件夹下所有的文件赋予了可执行权限，也可以单独给需要的文件赋予可执行权限 2.3 配置创建配置文件路径、Mod路径和地图路径 text12345678# 创建配置路径mkdir -p /opt/t_mod_server/config# 使用自定义Mod位置和地图位置配置## 创建Mod路径，Mod路径中存放mod和一个表示是否开启Mod的json文件，如果不清楚等下可以由系统创建mkdir -p /opt/t_mod_server/Mods## 创建地图路径mkdir -p /opt/t_mod_server/Worlds 新建并编辑配置文件 text1vim /opt/t_mod_server/config/t_mod_loader_config 配置文件内容如下： text12345678910111213141516171819202122# 最大连接个数maxplayers=3# 指定端口，默认是7777port=6666# 连接密码password=1037forest# Mod路径和地图路径modpath=/opt/t_mod_server/Modsworld=/opt/t_mod_server/Worlds/delta1037.wld# 语言language=zh# 创建新地图参数## 地图难度difficulty=0## 地图大小 1(小), 2(中), and 3(大).autocreate=3## 地图路径和名字worldpath=/opt/terraria_server/Worldsworldname=delta1037.wld 完整的参数见Starting a modded server和Terraria官方配置说明 Mod路径下的内容： text1234567➜ Mods pwd/opt/t_mod_server/Mods➜ Mods lsenabled.json MagicStorage_v0.4.3.5.tmod Split_v0.4.0.13.tmodLocalizer_v1.5.0.19.tmod RecipeBrowser_v0.8.8.2.tmod ThoriumMod_v1.6.4.1.tmod# 注：Mod路径下除了一个enabled.json文件其余全是Mod文件 enabled.json文件内容（该json文件是一个字符串列表，每一个字符串是Mod的名字，如果需要去掉某个Mod需要将对应的字符串删除，即不加载该Mod）： text123456[ &quot;Split&quot;, &quot;RecipeBrowser&quot;, &quot;MagicStorage&quot;, &quot;ThoriumMod&quot;] 注意!!!： 1、Mod路径和地图路径默认位置在/username/.local/share/Terraria/ModLoader，username是当前登录用户的用户名 2、当不知道**enabled.json**的格式是什么样的时候，将需要加载的mod放入到/root/.local/share/Terraria/ModLoader/Mods中，切换到tModLoader主程序文件夹/opt/t_mod_server/server中，不加参数直接启动主程序（启动：./tModLoaderServer.bin.x86_64）,显示输出类似如下： text12345678910Terraria Server v1.3.5.3 - tModLoader v0.11.8.41 1037forest2 testn New Worldd &lt;number&gt;Delete Worldm Mods Menub Mod BrowserChoose World: 输入m可以选择是否加载（enable）mod或者取消（disable）mod 界面如下： text12345678910111213Terraria Server v1.3.5.3 - tModLoader v0.11.8.41 Localizer (enabled)2 Magic Storage (enabled)3 Recipe Browser (enabled)4 Split (enabled)5 Thorium Mod (enabled)e Enable Alld Disable Allr Reload and return to world menuType a number to switch between enabled/disabledType a command: 选择完成之后使用r重载并返回到上一级，这时使用Ctrl + C退出，即可获取到/root/.local/share/Terraria/ModLoader/Mods/enable.json文件，将该文件拷贝到指定的Mod路径下即可使用。 2.4 启动text12345# 进入到主程序目录cd /opt/t_mod_server/server# 使用配置文件启动./tModLoaderServer.bin.x86_64 -config /opt/t_mod_server/config/t_mod_loader_config 参考【0】Starting a modded server 【1】How to create a tModLoader&#x2F;Modded server on Linux","tags":[{"name":"Terraria","slug":"Terraria","permalink":"https://www.delta1037.cn/tags/Terraria/"},{"name":"游戏","slug":"游戏","permalink":"https://www.delta1037.cn/tags/%E6%B8%B8%E6%88%8F/"}]},{"title":"C++ List Shuffle","date":"2021-05-16T16:00:00.000Z","path":"2021/C_C++/C++ListShuffle/","text":"目前C++只提供了可随机访问的容器的shuffle接口，对于List容器该接口不可用，这里提供一个List shuffle函数模板 一、随机访问容器shuffle12345# 生成随机种子unsigned seed = std::chrono::system_clock::now().time_since_epoch().count();# 使用默认的随机引擎来打乱容器中的元素std::shuffle(v.begin(), v.end(), std::default_random_engine(seed)); 二、List shuffle函数模板123456789101112131415template &lt; typename T &gt; void list_shuffle( std::list&lt;T&gt;&amp; lst ) // shuffle contents of a list&#123; // create a vector of (wrapped) references to elements in the list // http://en.cppreference.com/w/cpp/utility/functional/reference_wrapper std::vector&lt; std::reference_wrapper&lt; const T &gt; &gt; vec( lst.begin(), lst.end() ) ; // shuffle (the references in) the vector std::shuffle( vec.begin(), vec.end(), std::mt19937&#123; std::random_device&#123;&#125;() &#125; ) ; // copy the shuffled sequence into a new list std::list&lt;T&gt; shuffled_list &#123; vec.begin(), vec.end() &#125; ; // swap the old list with the shuffled list lst.swap(shuffled_list) ;&#125; 参考【0】 how to shuffle a list?","tags":[{"name":"C/C++","slug":"C-C","permalink":"https://www.delta1037.cn/tags/C-C/"},{"name":"STL","slug":"STL","permalink":"https://www.delta1037.cn/tags/STL/"}]},{"title":"C/C++时间封装","date":"2021-05-16T16:00:00.000Z","path":"2021/C_C++/C-C++时间封装/","text":"以下为封装的获取纳秒，毫秒时间的接口、精确睡眠微秒接口、按照指定频率执行某一个功能的封装和时间转字符串接口。 一、获取时间text1234567891011121314/* 获取NS时间 -9 */static uint64_t getTimeOfNs() &#123; struct timespec tv; clock_gettime(CLOCK_REALTIME, &amp;tv); return tv.tv_sec*1000000000 + tv.tv_nsec;&#125;/* 获取MS时间 -3 */uint64_t get_time_of_ms()&#123; struct timeval tv; gettimeofday(&amp;tv, 0); return tv.tv_sec * (uint64_t)1000 + tv.tv_usec / 1000;&#125; 二、精确睡眠text1234567891011/* 精确睡眠US时间 */static void sleepUS(uint64_t usec)&#123; struct timeval tv; tv.tv_sec = usec / 1000000UL; tv.tv_usec = usec % 1000000UL; errno = 0; select(0, 0, 0, NULL, &amp;tv); if (errno != 0)&#123; // error &#125;&#125; 三、按照指定频率执行text1234567891011121314151617181920int freq_op(int freq)&#123; uint64_t freq_interval_ns = uint64_t(1000000000/freq) uint64_t start_time_ns = getTimeOfNs(); uint64_t do_times_count = 0; while(true) &#123; // do some thing do_times_count++; // 得到从开始到现在的运行总时间；计算睡眠时间 uint64_t run_time_ns = getTimeOfNs() - start_time_ns; uint64_t do_times_should = uint64_t(run_time_ns/freq_interval_ns); if(do_times_count &gt; do_times_should) &#123; // 用到了上面精确睡眠的函数 sleepUS((do_times_count - do_times_should) * freq_interval_ns - - run_time_ns % freq_interval_ns); &#125; &#125;&#125; 四、秒转换为时间字符串text123456789101112131415161718192021222324252627282930313233/* 将时间秒计数转换成 dd:hh:mm:ss的格式 */void scaleDownTime(uint64_t s_time, std::string &amp;time)&#123; char buffer[128]; int d = 0; int h = 0; int m = 0; int s = 0; if(s_time &gt;= 3600 * 24)&#123; d = s_time / (3600 * 24); s_time = s_time % (3600 * 24); &#125; if(s_time &gt;= 3600)&#123; h = s_time / 3600; s_time = s_time % 3600; &#125; if(s_time &gt;= 60)&#123; m = s_time / 60; s_time = s_time % 60; &#125; s = s_time; if(d &gt; 0)&#123; int size = snprintf(buffer, 128, &quot;%dd %02d:%02d:%02d&quot;, d, h, m, s); buffer[size] = &#x27;\\0&#x27;; &#125;else&#123; int size = snprintf(buffer, 128, &quot;%02d:%02d:%02d&quot;, h, m, s); buffer[size] = &#x27;\\0&#x27;; &#125; time = std::string(buffer);&#125;","tags":[{"name":"C/C++","slug":"C-C","permalink":"https://www.delta1037.cn/tags/C-C/"},{"name":"封装","slug":"封装","permalink":"https://www.delta1037.cn/tags/%E5%B0%81%E8%A3%85/"}]},{"title":"动态库文件的装载","date":"2021-05-16T16:00:00.000Z","path":"2021/C_C++/动态库文件的装载/","text":"动态库状态过程的细节，待整理 动态符号表（.dynsym）是一个符号集，保存动态链接相关的符号，这些符号对于运行时的动态对象是可见的。在动态链接过程中，如果发现未定义的动态符号，链接器会把动态符号加入到动态符号表。但是我们的插件是显示地运行时链接的（为了减少与主程序的耦合），不可能在编译过程中就动态链接到对应的插件库，所以只能主动导出插件中使用的未定义的符号（注册与反注册符号）到动态符号表中，所以在编译主程序时，使用-Wl,-E（-Wl,–export-dynamic）链接器参数将主程序中所有的符号导出到动态符号表中。这样在使用dlopen打开插件动态库时，插件动态库中相关的注册和反注册接口符号在主程序的动态符号表中就有了定义，于是就可以正常运行了。使用readelf –dyn-syms + 可执行文件或动态库可以查看可执行文件或者动态库中的动态符号表。本例中动态库中动态符号表部分内容如下：Symbol table ‘.dynsym’ contains 22 entries: Num: Value Size Type Bind Vis Ndx Name 1: 0000000000000000 0 NOTYPE GLOBAL DEFAULT UND _Z19unregister_ioengineP1 2: 0000000000000000 0 FUNC GLOBAL DEFAULT UND &#x70;&#114;&#105;&#x6e;&#116;&#102;&#x40;&#x47;&#76;&#x49;&#66;&#x43;&#x5f;&#50;&#46;&#50;&#x2e;&#53; (2) 11: 0000000000000000 0 NOTYPE GLOBAL DEFAULT UND _Z17register_ioengineP11I 13: 0000000000000000 0 FUNC GLOBAL DEFAULT UND &#112;&#116;&#104;&#x72;&#x65;&#x61;&#100;&#95;&#x73;&#101;&#x6c;&#102;&#x40;&#x47;&#76;&#73;&#x42;&#x43;&#95;&#x32;&#46;&#50;&#46;&#53; (3) 14: 0000000000000000 0 FUNC GLOBAL DEFAULT UND &#x70;&#x72;&#x65;&#97;&#100;&#54;&#x34;&#64;&#71;&#76;&#x49;&#x42;&#67;&#x5f;&#x32;&#x2e;&#x32;&#46;&#x35; (3) 15: 0000000000000000 0 FUNC GLOBAL DEFAULT UND &#112;&#x77;&#x72;&#105;&#x74;&#101;&#x36;&#52;&#64;&#71;&#76;&#73;&#66;&#x43;&#x5f;&#x32;&#46;&#x32;&#x2e;&#53; (3) 16: 0000000000202080 80 OBJECT GLOBAL DEFAULT 24 ioengine从中可以看出注册和反注册接口、以及调用glic库中的符号的是未定义（UND）状态，需要在加载时确定这些符号的位置，glic库相关的符号在加载glic库时完成确定，注册与反注册则需要在主程序中确定位置，所以主程序的动态符号表必须有这两个符号的定义。主程序在未加-Wl,-E参数编译时，动态符号表内容如下：Symbol table ‘.dynsym’ contains 87 entries: Num: Value Size Type Bind Vis Ndx Name 0: 0000000000000000 0 NOTYPE LOCAL DEFAULT UND 1: 0000000000000000 0 FUNC GLOBAL DEFAULT UND &#x5f;&#90;&#x4e;&#83;&#x73;&#x61;&#x53;&#69;&#x50;&#x4b;&#99;&#x40;&#x47;&#76;&#73;&#66;&#x43;&#88;&#x58;&#x5f;&#51;&#46;&#52; (2) 2: 0000000000000000 0 FUNC GLOBAL DEFAULT UND &#x5f;&#x5a;&#x4e;&#83;&#115;&#x43;&#x31;&#x45;&#118;&#64;&#71;&#76;&#73;&#66;&#x43;&#88;&#x58;&#x5f;&#x33;&#46;&#52; (2) 3: 0000000000000000 0 FUNC GLOBAL DEFAULT UND &#112;&#114;&#105;&#110;&#116;&#102;&#x40;&#71;&#76;&#73;&#x42;&#x43;&#95;&#x32;&#x2e;&#50;&#46;&#x35; (3) 4: 0000000000000000 0 FUNC GLOBAL DEFAULT UND &#x5f;&#90;&#x53;&#116;&#50;&#x31;&#95;&#95;&#x74;&#x68;&#x72;&#x6f;&#x77;&#x5f;&#x72;&#x75;&#x6e;&#116;&#105;&#109;&#x65;&#x5f;&#x65;&#x72;&#x72;&#x40;&#71;&#76;&#x49;&#x42;&#67;&#88;&#88;&#95;&#51;&#46;&#x34; (2) 5: 0000000000000000 0 FUNC GLOBAL DEFAULT UND &#115;&#110;&#x70;&#x72;&#x69;&#x6e;&#x74;&#x66;&#64;&#x47;&#x4c;&#x49;&#x42;&#x43;&#x5f;&#x32;&#46;&#x32;&#46;&#53; (3)其中只包含一些调用其它动态库的动态符号内容，像glibc库这些第三方库中的符号。 主程序在添加-Wl,-E参数编译时，动态符号表内容过多，添加grep过滤（readelf –dyn-syms main_prj | grep register）可得：240: 0000000000410dd5 218 FUNC GLOBAL DEFAULT 14 _Z17register_ioengineP11I 596: 0000000000410eaf 211 FUNC GLOBAL DEFAULT 14 _Z19unregister_ioengineP1可以看出在使用了-Wl,-E参数后，动态符号表中多出了一些主程序中内部函数的符号，包含插件注册与反注册接口的符号（符号修饰名与插件中的修饰名一致）。 参考：.dynsym：动态符号表：保存动态链接相关的导入导出的符号，不包括模块内部符号.dynsym默认会导出使用其它动态链接库的符号主程序在编译时默认只会导出未定义的符号（将来从动态库中加载）和动态库中定义了并且被使用的符号（定义了函数定义，并有实现和调用）。不会导出有定义但是没有使用的符号。所以当插件需要向主程序注册时，主程序中需要有注册函数符号，才能被插件调用。gcc编译使用-Wl,-E参数可以导出所有符号。主程序加载动态库时，动态符号表会进行合并合并到GOT表显式运行时链接查看动态符号表：readelf –dyn-syms plugin_test待补充的内容：动态表是怎么链接到一起的，动态库加载的时候做了什么？动态链接过程中如果发现未定义的动态符号，链接器会把动态符号加入动态符号表（所以第一个例子中，程序输出正常），但是fun符号因为是在dlopen中（dlopen发生在运行过程中）调用的，不会加入到动态符号表，所以导致找不到符号。-E’–export-dynamic’当创建一个动态连接的可执行程序时, 把所有的符号加到动态符号表中.动态符号表是一个符号集,这些符号对于运行时的动态对象是可见的.如果你不使用这个选项,动态符号表中就会只含有那些连接进来的动态对象中用到的符号 如果你使用’dlopen’来载入动态对象,它需要引用程序中的符号,那你可能需要在连接程序时用到这个选项.你也可以使用版本脚本来控制哪些符号应当被加到动态符号表中.","tags":[{"name":"C/C++","slug":"C-C","permalink":"https://www.delta1037.cn/tags/C-C/"},{"name":"编译","slug":"编译","permalink":"https://www.delta1037.cn/tags/%E7%BC%96%E8%AF%91/"}]},{"title":"pg_repack Window编译安装","date":"2021-05-16T16:00:00.000Z","path":"2021/Deploy/pg_repackWindow编译安装/","text":"在Window上编译安装pg_repack （在线清理表空间插件） pg_repack Window编译安装一、编译准备1.1 pg_repack下载pg_repack下载位置：https://pgxn.org/dist/pg_repack&#x2F;1.4.6&#x2F; 目前最新版本为4.6版本 1.2 postgres版本选择编译时需要在编译机器上安装postgre，官网可以下载到的版本是9.6.21，经测试9.6.21可以使用 二、编译pg_repack注：已经做完以下所有配置和修改的代码打包为pg_repack-1.4.6_modify.zip，使用vs2013打开解压之后其中的msvc文件夹下的pg_repack.sln即可编译。 2.1使用vs2013打开pg_repackpg_repack-1.4.6.zip解压得到pg_repack-1.4.6目录，进入pg_repack-1.4.6\\msvc可以看到2010的sln文件，经测试vs2013版本也可以正常编译，使用vs2013打开pg_repack.sln并升级，可以看到bin和lib两个项目 2.2添加并选择pg_repack 64位编译配置鼠标右键点击解决方案pg_repack，选择配置属性-&gt;配置，可以看到bin和lib两个项目都是32位平台下的配置，如下图所示： 我们需要x64位平台配置，点击右上角配置管理器，点击如下图红框所标示的下拉按钮位置，并选择新建 新平台选择x64，并选择从Win32复制，如下图 新建完成之后返回到配置属性-&gt;配置，选择刚刚新建的x64平台，选择完成如下图： 2.3禁用将警告视为错误bin和lib两个项目都要禁用将警告视为错误，以下以bin项目为例，lib项目同理。 bin项目禁用将警告视为错误：选中bin项目，点击鼠标右键，选择配置属性-&gt;C&#x2F;C++-&gt;常规，将警告视为错误选择否，如下图： lib项目进行同样的操作。 2.4注册PostgreSQL的目录bin和lib两个项目都要注册PostgreSQL的包含目录和库目录，以下以bin项目为例，lib项目同理。 bin项目添加包含目录：选中bin项目，点击鼠标右键，选择配置属性-&gt;VC++目录，选择如下图所示的下拉位置并点击编辑 添加PostgreSQL的头文件目录（根据实际PostgreSQL安装目录决定）： C:\\Program Files\\PostgreSQL\\9.6\\include C:\\Program Files\\PostgreSQL\\9.6\\include\\internal C:\\Program Files\\PostgreSQL\\9.6\\include\\server C:\\Program Files\\PostgreSQL\\9.6\\include\\server\\port\\win32 C:\\Program Files\\PostgreSQL\\9.6\\include\\server\\port\\win32_msvc 添加完成后如下图所示： bin项目添加库目录：选中bin项目，点击鼠标右键，选择配置属性-&gt;VC++目录，选择库目录位置，如下图， 添加PostgreSQL的库文件目录（根据实际PostgreSQL安装目录决定）： C:\\Program Files\\PostgreSQL\\9.6\\bin C:\\Program Files\\PostgreSQL\\9.6\\lib 添加完成后如下图所示： lib项目同样的操作，注册PostgreSQL的包含目录和库目录。 2.5删除lib项目不存在的源文件lib项目src路径下有一个不存在的文件pgut-be.c，选中并delete即可。删除之后如下图 2.6 bin项目修改链接库选中bin项目，点击鼠标右键，选择配置属性-&gt;链接器-&gt;输入，选择附加依赖项并展开选择编辑 1、libintl-8.lib修改为libintl.lib 2、添加postgres.lib 修改完成之后如下图所示 2.7打入版本号bin和lib两个项目在编译时无法打入版本号，所以对源代码repack.c和pg_repack.c文件进行了修改，修改之后如下 bin项目为例，点击鼠标右键，选择配置属性-&gt;C&#x2F;C++-&gt;命令行，在其它选项框中填入&#x2F;D “WIN_BUILD”，如下图： lib项目需要做同样的配置 2.8编译项目分别选中bin和lib两个项目（不分先后），鼠标右键选择生成。 生成的文件在pg_repack-1.4.6\\msvc\\x64\\Release相对路径下，有pg_repack.dll和pg_repack.exe两个文件 三、插件文件汇总注：已经做完编译和修改的文件在压缩包中可以看到 3.1 pg_repack二进制文件上边编译好的pg_repack.dll和pg_repack.exe两个文件 3.2 pg_repack扩展安装辅助文件在pg_repack-1.4.6\\lib相对路径下有pg_repack.sql.in和pg_repack.control.in两个文件，分别拷贝为pg_repack.sql和pg_repack.control 打开pg_repack.sql文件，将REPACK_VERSION替换为版本号1.4.6 修改之后为 打开pg_repack.control文件 将REPACK_VERSION替换为版本号1.4.6；替换module_pathname的值为实际的插件安装DLL文件的路径（插件安装在后续介绍） 修改之后 四、插件安装4.1放入插件相关文件以下描述使用相对路径，均为pStor中PostgreSQL的路径 1、pg_repack–1.4.6.sql和pg_repack.control放入到PostgreSQL\\share\\extension\\中 2、pg_repack.dll和pg_repack.exe放入到PostgreSQL\\bin\\中 注意pg_repack.control中module_pathname的值与pg_repack.dll路径位置一致 4.2登录到数据库并添加插件1、登录到想要使用插件的数据库（cmd中PostgreSQL\\bin\\路径下运行，注：使用管理员用户，否则权限不够无法添加） psql.exe -h hostname -p port -d database_name -U super_user 2、 安装插件（在登录之后的提示命令中执行）， 执行命令：create extension pg_repack; 使用\\dx列出插件看是否安装成功： 注：卸载插件命令（drop extension pg_repack;） 3、 检查是否安装成功（在cmd中PostgreSQL\\bin\\路径下运行，应该输出pg_repack版本号） pg_repack –version","tags":[{"name":"软件","slug":"软件","permalink":"https://www.delta1037.cn/tags/%E8%BD%AF%E4%BB%B6/"},{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"https://www.delta1037.cn/tags/PostgreSQL/"}]},{"title":"IP字符串数字互转","date":"2021-05-16T16:00:00.000Z","path":"2021/Linux/IP字符串数字互转/","text":"封装的IP字符串与数字互转接口 一、字符串转数字text123456789101112131415161718192021222324252627282930313233343536/* @func: IP字符串形式转换成数字形式，支持IPV6 @note: IP字符串中包含&#x27;:&#x27;则认为是IPV6 IPV4返回值保存到 ip_num_low , IPV6返回值保存到 ip_num_high+ip_num_low*/struct IPNum&#123; int is_ipv6; uint64_t ip_num_low; uint64_t ip_num_high; IPNum() &#123; is_ipv6 = 0; ip_num_low = 0; ip_num_high = 0; &#125;&#125;;int ip2num(const std::string &amp;ip_str, IPNum &amp;ip_num)&#123; if(ip_str.find(&#x27;:&#x27;) != std::string::npos) &#123; struct in6_addr ipv6&#123;&#125;; inet_pton(AF_INET6, ip_str.c_str(), &amp;ipv6); ip_num.ip_num_low = ipv6.s6_addr32[2]; ip_num.ip_num_low = ipv6.s6_addr32[3] | (ip_num.ip_num_low &lt;&lt; 32); ip_num.ip_num_high = ipv6.s6_addr32[0]; ip_num.ip_num_high = ipv6.s6_addr32[1] | (ip_num.ip_num_high &lt;&lt; 32); ip_num.is_ipv6 = 1; &#125; else &#123; ip_num.ip_num_low = inet_addr(ip_str.c_str()); &#125; return 0;&#125; 二、数字转字符串待续。。。","tags":[{"name":"封装","slug":"封装","permalink":"https://www.delta1037.cn/tags/%E5%B0%81%E8%A3%85/"},{"name":"IP","slug":"IP","permalink":"https://www.delta1037.cn/tags/IP/"}]},{"title":"Linux 后台执行","date":"2021-05-16T16:00:00.000Z","path":"2021/Linux/Linux后台执行/","text":"Linux 后台执行程序 以下例子来源于网络，位置记不清了，后续补上 text123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;int start_bg()&#123; pid_t pid; // 1.转变为后台进程 if ((pid = fork() ) != 0 ) exit( 0); // 2.离开原先的进程组 setsid(); // 3.禁止再次打开控制终端 if ((pid = fork()) != 0) &#123; exit(0); &#125; // 4.关闭打开的文件描述符，避免浪费系统资源 rlimit rlim; if(getrlimit(RLIMIT_NOFILE,&amp;rlim) == 0) &#123; for(int fd=3; fd&lt;=(int)rlim.rlim_cur; fd++) &#123; close(fd); &#125; &#125; // 5.改变当前的工作目录，避免卸载不了文件系统 if (chdir(&quot;/&quot;) == -1) exit(1); // 6.重设文件掩码，防止某些属性被父进程屏蔽 umask(0); setpgrp(); // 7.重定向标准输入，输出，错误流，因为守护进程没有控制终端 if ((fd = open(&quot;/dev/null&quot;, O_RDWR)) == -1) &#123; exit(1); &#125; dup2(fd, STDIN_FILENO); dup2(fd, STDOUT_FILENO); dup2(fd, STDERR_FILENO); close(fd); // 8.屏蔽信号 signal( SIGINT, SIG_IGN); signal( SIGHUP, SIG_IGN); signal( SIGQUIT, SIG_IGN); signal( SIGPIPE, SIG_IGN); signal( SIGTTOU, SIG_IGN); signal( SIGTTIN, SIG_IGN); signal( SIGCHLD, SIG_IGN); signal( SIGTERM, SIG_IGN); struct sigaction sig; sig.sa_handler = SIG_IGN; sig.sa_flags = 0; sigemptyset( &amp;sig.sa_mask); sigaction( SIGHUP,&amp;sig,NULL); return 0;&#125;","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.delta1037.cn/tags/Linux/"},{"name":"C/C++","slug":"C-C","permalink":"https://www.delta1037.cn/tags/C-C/"}]},{"title":"块设备层中IO事件统计","date":"2021-05-16T16:00:00.000Z","path":"2021/Linux/块设备层中IO事件统计/","text":"块设备层中IO事件统计 一、可统计的内容1、IO合并的比例（传入的IO请求&#x2F;合并后传入设备驱动的请求），合并后块大小统计2、块设备层中IO各个阶段的时间统计（生成IO请求时间、IO调度时间和驱动和硬件上消耗的时间等，分析IO性能瓶颈） 二、统计方法blktrace + blkparse + btt 1、开启监测 text12$ blktrace -d /dev/sda# 其中-d指定监测的设备，运行时无终端输出，使用Ctrl+C终止 2、整理结果blktrace在执行的目录中生成sdc.blktrace.X文件，x代表CPU id，此文件无法直接读取，使用blkparse解析这些文件 text12$ blkparse -i sdc# 解析文件，-i指定了输入文件 输出及其解释： 每一个IO的输出格式 text123456789108,32 1 1201902 31.648378780 7 M W 35726288 + 8 [kworker/u49:0]# 第一个字段：8,32 这个字段是设备号 major device ID和minor device ID。# 第二个字段：1 表示CPU# 第三个字段：1201902 序列号# 第四个字段：31.648378780 Time Stamp是时间偏移# 第五个字段：PID 本次IO对应的进程ID# 第六个字段：Event，这个字段非常重要，反映了IO进行到了那一步# 第七个字段：R表示 Read， W是Write，D表示block，B表示Barrier Operation# 第八个字段：35726288 + 8，表示的是起始block number 和 number of blocks，即我们常说的Offset 和 Size# 第九个字段： 进程名 合计格式 text1234567891011Total (sdc):Reads Queued: 0, 0KiB Writes Queued: 1,392K, 5,570MiBRead Dispatches: 0, 0KiB Write Dispatches: 10,869, 5,564MiBReads Requeued: 0 Writes Requeued: 0Reads Completed: 0, 0KiB Writes Completed: 10,869, 5,564MiBRead Merges: 0, 0KiB Write Merges: 1,381K, 5,527MiBPC Reads Queued: 0, 0KiB PC Writes Queued: 0, 0KiBPC Read Disp.: 15, 0KiB PC Write Disp.: 0, 0KiBPC Reads Req.: 0 PC Writes Req.: 0PC Reads Compl.: 7 PC Writes Compl.: 0IO unplugs: 743 Timer unplugs: 0 blkparse的结果不是很清晰，可以使用btt进行进一步的分析先将blktrace生成的文件整合到一个文件中： text1$ blkparse -O -i sdc -d sdc.blktrace.bin 使用btt进行进一步的分析： text1$ btt -A -i sdc.blktrace.bin 输出和解释： text12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667一、IO请求到写入设备各个阶段的时间统计==================== All Devices ====================ALL MIN AVG MAX N--------------- ------------- ------------- ------------- -----------• Q2Q 0.000000808 0.000022550 0.169176199 5017599• Q2G 0.000000606 0.002694758 0.169166444 39199• S2G 0.070385850 0.086264639 0.169165248 1224• G2I 0.000146627 0.001615914 0.006145786 39199• Q2M 0.000000149 0.000000254 0.000217874 4978400• I2D 0.227251891 0.313646256 0.464198624 39103• M2D 0.230494332 0.315166061 0.464387299 4966208• D2C 0.056031007 0.095095120 0.210527104 5001087• Q2C 0.338179300 0.410294069 0.596850606 5001087其中各个阶段说明：• Q2Q — time between requests sent to the block layer• Q2G — time from a block I/O is queued to the time it gets a request allocated for it• G2I — time from a request is allocated to the time it is Inserted into the device&#x27;s queue• Q2M — time from a block I/O is queued to the time it gets merged with an existing request• I2D — time from a request is inserted into the device&#x27;s queue to the time it is actually issued to the device• M2D — time from a block I/O is merged with an exiting request until the request is issued to the device• D2C — service time of the request by the device• Q2C — total time spent in the block layer for a request问题：Q2I + I2D + D2C = Q2C，实际测出来的并不相等，资料中的结果也是二、IO请求到写入设备各个阶段的占比==================== Device Overhead ====================DEV | Q2G G2I Q2M I2D D2C---------- | --------- --------- --------- --------- ---------( 8, 32) | 0.0051% 0.0031% 0.0001% 0.5977% 23.1773%---------- | --------- --------- --------- --------- ---------Overall | 0.0051% 0.0031% 0.0001% 0.5977% 23.1773%当I2D很大的时候可以试试其它的IO调度策略三、IO合并的比例，Q表示传入的IO请求数量，D表示合并后发出的请求数量,Ratio表示合并的比例，BLKxxx表示合并后的块的大小最大值、最小值和平均值==================== Device Merge Information ====================DEV | #Q #D Ratio | BLKmin BLKavg BLKmax Total---------- | -------- -------- ------- | -------- -------- -------- --------( 8, 32) | 5017600 39198 128.0 | 1024 1024 1024 40138752四、IO调度相关，当一个IO 进入Q状态时，调度器中此时有多少IO处于D状态==================== Active Requests At Q Information ====================DEV | Avg Reqs @ Q---------- | -------------( 8, 32) | 14.9五、每一个进程的时间段统计==================== Per Process ====================Q2C MIN AVG MAX N--------------- ------------- ------------- ------------- -----------kworker 0.339407380 0.414291058 0.595046589 1374335六、Q2D统计直方图数据==================== Q2D Histogram ====================DEV | &lt;.005 &lt;.010 &lt;.025 &lt;.050 &lt;.075 &lt;.100 &lt;.250 &lt;.500 &lt; 1.0 &gt;=1.0--------- | ===== ===== ===== ===== ===== ===== ===== ===== ===== =====( 8, 32) | 0.0 0.0 0.0 0.0 0.0 0.0 0.0 100.0 0.0 0.0========== | ===== ===== ===== ===== ===== ===== ===== ===== ===== =====AVG | 0.0 0.0 0.0 0.0 0.0 0.0 0.0 100.0 0.0 0.0七、设备驱动或者设备具有IO的时间，与iostat的util类似==================== I/O Active Period Information ====================DEV | # Live Avg. Act Avg. !Act % Live---------- | ---------- ------------- ------------- ------( 8, 32) | 1 0.000000000 0.000000000 100.00---------- | ---------- ------------- ------------- ------Total Sys | 1 0.000000000 0.000000000 100.00 参考文档[0] btt[1] 切换调度器-Linux[2] 切换调度器-Redhat[3] 单队列的移除","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.delta1037.cn/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://www.delta1037.cn/tags/Shell/"},{"name":"IO","slug":"IO","permalink":"https://www.delta1037.cn/tags/IO/"}]},{"title":"系统信息收集脚本","date":"2021-05-16T16:00:00.000Z","path":"2021/Linux/系统信息收集脚本/","text":"使用top、iostat、vmstat 、dstat、blktrace、pidstat监控系统状态信息 执行方式： text12345# 开启统计./script_name start [output_filename_prefix]# 关闭统计./script_name stop 脚本内容： text123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171######## 性能数据收集脚本 ######### 开始/停止SWITCH=$&#123;1&#125;# 输出文件前缀OUTPUT_PREFIX=$&#123;2&#125;CURRENT_TIME=`date &quot;+%Y%m%d_%H%M%S&quot;`SCRIPT_ABS_PATH=$(cd `dirname $0`; pwd)# 临时存储进程pidSTAT_PID_FILE=$&#123;SCRIPT_ABS_PATH&#125;/.stat_perf_pidARG_IOSTAT_DISK=/dev/sdcBLKTRACE_SWITCH=1PIDSTAT_PROCESS_NAME=&quot;&quot;function program_exists() &#123; local ret=&#x27;0&#x27; command -v $1 &gt;/dev/null 2&gt;&amp;1 || &#123; local ret=&#x27;1&#x27;; &#125; # 不存在返回0 if [ &quot;$ret&quot; -ne 0 ]; then return 0 fi return 1&#125;# iostat 信息收集function iostat_info() &#123; iostat_info_filename=$&#123;SCRIPT_ABS_PATH&#125;/$&#123;OUTPUT_PREFIX&#125;_iostat_$&#123;CURRENT_TIME&#125;.log # 清空文件 echo &quot;&quot; &gt; $&#123;iostat_info_filename&#125; # 收集数据添加时间戳并写入文件 IOSTAT_ARGS=&quot;-x 3&quot; if [ $&#123;ARG_IOSTAT_DISK&#125; ];then IOSTAT_ARGS=&quot;$&#123;IOSTAT_ARGS&#125; -d $&#123;ARG_IOSTAT_DISK&#125;&quot; fi iostat $&#123;IOSTAT_ARGS&#125; | stdbuf -oL awk &#x27;&#123;print strftime(&quot;[%Y-%m-%d %H:%M:%S]&quot;),$0&#125;&#x27; &gt;&gt; $&#123;iostat_info_filename&#125;&#125;function top_info() &#123; top_info_filename=$&#123;SCRIPT_ABS_PATH&#125;/$&#123;OUTPUT_PREFIX&#125;_top_$&#123;CURRENT_TIME&#125;.log # 清空文件 echo &quot;&quot; &gt; $&#123;top_info_filename&#125; # 收集数据并写入文件 5 s 一次,top取前30行数据 while : ; do sleep 5 top -b -n 1 | stdbuf -oL awk &#x27;BEGIN&#123; i=0 &#125; &#123; if(i++&lt;30) print strftime(&quot;[%Y-%m-%d %H:%M:%S]&quot;),$0&#125;&#x27; &gt;&gt; $&#123;top_info_filename&#125; done&#125;# vmstat 信息收集function vmstat_info() &#123; vmstat_info_filename=$&#123;SCRIPT_ABS_PATH&#125;/$&#123;OUTPUT_PREFIX&#125;_vmstat_$&#123;CURRENT_TIME&#125;.log # 清空文件 echo &quot;&quot; &gt; $&#123;vmstat_info_filename&#125; # 收集数据并写入文件 vmstat -w 3 | stdbuf -oL awk &#x27;&#123;print strftime(&quot;[%Y-%m-%d %H:%M:%S]&quot;),$0&#125;&#x27; &gt;&gt; $&#123;vmstat_info_filename&#125;&#125;# dstat 信息收集function dstat_info() &#123; dstat_info_filename=$&#123;SCRIPT_ABS_PATH&#125;/$&#123;OUTPUT_PREFIX&#125;_dstat_$&#123;CURRENT_TIME&#125;.log # 清空文件 echo &quot;&quot; &gt; $&#123;dstat_info_filename&#125; # 收集数据并写入文件 dstat | stdbuf -oL awk &#x27;&#123;print strftime(&quot;[%Y-%m-%d %H:%M:%S]&quot;),$0&#125;&#x27; &gt;&gt; $&#123;dstat_info_filename&#125;&#125;# blktrace 设备层 IO信息收集function blktrace_info() &#123; # blktrace 会输出多个文件，所以创建文件夹 blktrace_info_dir=$&#123;SCRIPT_ABS_PATH&#125;/$(basename $&#123;ARG_IOSTAT_DISK&#125;)_blktrace_$&#123;OUTPUT_PREFIX&#125;_$&#123;CURRENT_TIME&#125; mkdir -p $&#123;blktrace_info_dir&#125; # 执行blktrace 等待Ctrl+C退出 cd $&#123;blktrace_info_dir&#125; # echo &quot;blktrace dir $&#123;blktrace_info_dir&#125; cmd:blktrace -d $&#123;ARG_IOSTAT_DISK&#125;&quot; blktrace -d $&#123;ARG_IOSTAT_DISK&#125;&#125;function pidstat_info() &#123; pidstat_info_filename=$&#123;SCRIPT_ABS_PATH&#125;/$&#123;OUTPUT_PREFIX&#125;_pidstat_$&#123;CURRENT_TIME&#125;.log # 清空文件 echo &quot;&quot; &gt; $&#123;pidstat_info_filename&#125; # 收集数据并写入文件 pidstat -G $&#123;PIDSTAT_PROCESS_NAME&#125; -u 1 | stdbuf -oL awk &#x27;&#123;print strftime(&quot;[%Y-%m-%d %H:%M:%S]&quot;),$0&#125;&#x27; &gt;&gt; $&#123;pidstat_info_filename&#125;&#125;# 输出文件前缀if [ -z &quot;$&#123;OUTPUT_PREFIX&#125;&quot; ];then OUTPUT_PREFIX=&quot;default&quot;fi# 开始或停止性能监测脚本if [ &quot;$&#123;SWITCH&#125;&quot; = &quot;start&quot; ];then if [ -e $&#123;STAT_PID_FILE&#125; ];then echo &quot;请勿重复运行,若想开启多个监测,将脚本拷贝到新的目录执行&quot; exit -1 fi echo &quot;start stat perf&quot; iostat_info &amp; iostat_pid=$! echo &quot;iostat_pid=&quot;$iostat_pid vmstat_info &amp; vmstat_pid=$! echo &quot;vmstat_pid=&quot;$vmstat_pid top_info &amp; top_pid=$! echo &quot;top_pid=&quot;$top_pid # 如果dstat存在则开启dstat统计 dstat_pid=&quot;&quot; program_exists dstat dstat_exist=$? if [ $&#123;dstat_exist&#125; -eq 1 ];then dstat_info &amp; dstat_pid=$! echo &quot;dstat_pid=&quot;$dstat_pid fi blktrace_pid=&quot;&quot; if [ $&#123;BLKTRACE_SWITCH&#125; -eq 1 ];then # blktrace 一定要指定磁盘 if [ $&#123;ARG_IOSTAT_DISK&#125; ];then blktrace_info &amp; blktrace_pid=$! echo &quot;blktrace_pid=&quot;$blktrace_pid else echo &quot;blktrace need specific device&quot; fi fi pidstat_pid=&quot;&quot; if [ $&#123;PIDSTAT_PROCESS_NAME&#125; ];then pidstat_info &amp; pidstat_pid=$! echo &quot;pidstat_pid=&quot;$pidstat_pid fi echo &quot;iostat_pid:$&#123;iostat_pid&#125; vmstat_pid:$&#123;vmstat_pid&#125; top_pid:$&#123;top_pid&#125; dstat_pid:$&#123;dstat_pid&#125; blktrace_pid:$&#123;blktrace_pid&#125; pidstat_pid:$&#123;pidstat_pid&#125;&quot; &gt; $&#123;STAT_PID_FILE&#125; echo &quot;start stat perf success&quot;elif [ &quot;$&#123;SWITCH&#125;&quot; = &quot;stop&quot; ];then echo &quot;stop stat perf&quot; # 判断pid文件是否存在 if [ -e $&#123;STAT_PID_FILE&#125; ];then for pidname_pid in `cat $&#123;STAT_PID_FILE&#125;` do pid=$&#123;pidname_pid#*:&#125; pidname=$&#123;pidname_pid%:*&#125; echo &quot;stop pid:$&#123;pid&#125; pidname:$&#123;pidname&#125;&quot; if [ -z $&#123;pid&#125; ];then # 如果这种情况不过滤掉，空的pid值会kill掉整个系统的进程 continue fi pstree -p $&#123;pid&#125; if [ $&#123;pidname&#125; = &quot;blktrace_pid&quot; ];then pstree -p $&#123;pid&#125; | awk -F&quot;[()]&quot; &#x27;&#123;for(i=0;i&lt;=NF;i++)if($i~/([0-9])$/)print $i&#125;&#x27; | xargs kill -2 2&gt;/dev/null else pstree -p $&#123;pid&#125; | awk -F&quot;[()]&quot; &#x27;&#123;for(i=0;i&lt;=NF;i++)if($i~/([0-9])$/)print $i&#125;&#x27; | xargs kill -9 2&gt;/dev/null fi done rm -f $&#123;STAT_PID_FILE&#125; fi echo &quot;stop stat perf success&quot;else echo &quot;sh stat_perf.sh [start|stop] [output_file_prefix] &amp;&quot;fi","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.delta1037.cn/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://www.delta1037.cn/tags/Shell/"}]},{"title":"深入理解Linux内核-绪论","date":"2021-03-19T16:00:00.000Z","path":"2021/Linux/深入理解Linux内核-绪论/","text":"深入理解Linux内核-绪论 一、Linux与类Unix内核的比较 大部分Unix是单块结构的内核，不支持按需装载和卸载模块 Unix内核被组织成一组内核线程；Linux以十分有限的方式使用内核线程周期地执行几个内核函数 Unix内核地轻量级线程（LWP，lightweight process）基于内核线程；Linux把轻量级进程当作基本地执上下文 二、操作系统基本概念2.1 多用户系统多用户系统是一台能并发和独立地执行分别属于两个或者多个用户地若干应用程序地计算机 多用户系统的特点： 核实用户身份的认证机制 防止有错误的用户程序妨碍其它应用程序再系统中运行的保护机制 防止有恶意用户程序干涉或者窥视其它用户的活动的保护机制 限制分配给每个用户的资源数的记账机制 2.2 用户和组在多用户系统中，每个用户都有私有空间。所有的用户用唯一的数字标识，这个数字叫用户标识符（User ID，UID）；为了能和其他用户选择性地共享资料，每个用户是一个或者多个用户组的成员，由唯一的用户组标识符标识（User Group ID）。每一个文件恰好与一个组相对应，例如可以设置文件的拥有者有文件的读写权限，同组的用户具有可读权限，从而实现了文件与其它用户的共享。 2.3 进程定义：程序执行的一个实例，或者一个运行程序的上下文 2.4 内核体系结构大多数Unix内核是单块结构：每一个内核层都集成到整个内核程序中，并代表当前进程在内核态下运行。微内核操作系统只需要内核有一个很小的函数集，运行在微内核之上的几个系统进程实现从前操作系统级实现的功能（内存分配、设备驱动程序和系统调用处理程序） 2.5 文件类型 普通文件 目录 符号链接 面向块的设备文件 面向字符的设备文件 管道和命名管道 套接字 2.6 文件描述符与索引节点索引节点至少提供以下属性： 文件类型 与文件相关的硬链接个数 以字节为单位的文件长度 设备标识符 在文件系统中标识文件的索引节点号 文件拥有者的UID 文件的用户组ID 几个时间戳，表示索引节点状态改变的时间、最后访问时间和最后修改时间 访问权限和文件模式 2.7 访问权限和文件模式文件潜在的用户： 文件的拥有者 同组用户，不包括拥有者 剩下的所有用户 有三种类型的访问权限：读、写和执行，每组用户都有三种权限，所以文件权限的组合就用9种不同的二进制来标记。还有三种附加的标记，即suid（Set User ID），sgid（Set Group ID）和sticky定义文件的模式。 当附加的标记应用到可执行文件时有如下含义： suid：进程执行一个文件时通常保持进程拥有者的UID。然而如果设置了可执行文件的suid标志位，进程就获得 了该文件拥有者的UID。 sgid：进程执行一个文件时通常保持进程组的用户组ID。然而如果设置了可执行文件的sgid标志位，进程就获得 了该文件用户组的ID。 sticky：设置了sticky的可执行文件相当于向内核发出了一个请求，当程序结束以后，依然将它保留在内存。 2.8 文件操作的系统调用 打开文件：open() 访问打开的文件：lseek()&#x2F;read()&#x2F;write() 关闭文件：close() 更名文件：rename() 删除文件：unlink() 参考【0】 《深入理解LINUX内核》","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.delta1037.cn/tags/Linux/"},{"name":"Kernel","slug":"Kernel","permalink":"https://www.delta1037.cn/tags/Kernel/"}]},{"title":"C/C++插件式设计","date":"2021-03-11T16:00:00.000Z","path":"2021/C_C++/C-C++插件式设计/","text":"Fio中的插件式设计分析，抽取出来一份模板。 一、设计来源并不是我设计的哈哈哈哈~ 最近看fio的源代码，学习了一波fio中关于IO引擎的插件式设计，对重要的一些部分做了摘要。以下是我的总结，其中有一些是我的猜测，有待验证 名词解释： 名词 解释 主程序 调用插件的程序 插件 可以被方便地替换地部分 二、插件与主程序的结构关联主程序如果想使用插件中的函数，则需要知道插件中对应函数的地址，所以我们可以定义一个结构体集合，用来保存插件提供函数的地址，和其它相关内容。在使用插件时我们只要找到了该结构体的位置，就相当于找到了插件中提供的函数的位置。例如 text12345678910struct PluginStruct &#123; char *plugin_name; int plugin_version; int (*init)(struct thread_data *); int (*uninit)(struct thread_data *); int (*io_write)(struct thread_data *, struct io_unit*); int (*io_read)(struct thread_data *, struct io_unit*);&#125;; 在本例中，我们准备做一个读写文件的插件，插件一使用write/read方式读写；插件二使用pwrite/pread方式读写。如上述结构体中：init和uninit是插件的初始化和反初始化，io_write和io_read是对读写接口的封装。 插件可能是由多线程来调用的，为了表明这一点，插件接口的参数中使用结构体struct thread_data来表示每个线程的私有数据（fio中也是用的thread_data）。 插件中也可能想保存私有数据，但是由于不知道有多少线程会使用该插件，所以只能将数据保存到结构体struct thread_data中plugin_data，然后在插件中做类型转换，结构体struct thread_data只是作为私有数据的plugin_data承载作用，私有数据plugin_data在init和uninit中分别申请空间和释放空间，对于外部来说可以做到‘神不知，鬼不觉’。 为了能够做到基本的数据读写，结构体struct thread_data和struct io_unit定义如下 text1234567891011121314151617181920212223242526/* 文件属性，用于保存每个线程操作的文件信息 */struct FileAttr &#123; char *file_name; int fd;&#125;;/* 线程数据，保存一个线程用到的所有数据 */struct thread_data &#123; /* some thread private data */ int thread_id; pthread_t thread_handle; struct PluginStruct *plugin_struct; // 通过该变量访问插件中的函数地址 void *plugin_private_data; struct FileAttr *file_attr; // 保存该线程用到的文件信息 void *plugin_dll_handle; // 共享库句柄&#125;;/* io操作单元，一次IO操作必要的信息 */struct io_unit &#123; void *buffer; // 缓冲区地址 uint64_t size; // 读写大小 uint64_t offset;// 读写偏移&#125;; 以上的结构体均定义在主程序头文件中，插件只是使用这些结构体类型，或访问内存中的值，或定义变量。 完整的插件需要包含的主程序头文件plugin.h定义如下 text1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// plugin.h// 插件在加载和关闭时，自动调用的构造函数和析构函数 标识？#define plugin_init __attribute__((constructor))#define plugin_exit __attribute__((destructor))/* 文件属性，用于保存每个线程操作的文件信息 */struct FileAttr &#123; char *file_name; int fd;&#125;;/* 线程数据，保存一个线程用到的所有数据 */struct thread_data &#123; /* some thread private data */ int thread_id; pthread_t thread_handle; struct PluginStruct *plugin_struct; // 通过该变量访问插件中的函数地址 void *plugin_private_data; struct FileAttr *file_attr; // 保存该线程用到的文件信息 void *plugin_dll_handle; // 共享库句柄&#125;;/* io操作单元，一次IO操作必要的信息 */struct io_unit &#123; void *buffer; // 缓冲区地址 uint64_t size; // 读写大小 uint64_t offset;// 读写偏移&#125;;struct PluginStruct &#123; char *plugin_name; int plugin_version; int (*init)(struct thread_data *); int (*uninit)(struct thread_data *); int (*io_write)(struct thread_data *, struct io_unit*); int (*io_read)(struct thread_data *, struct io_unit*);&#125;;// 插件向主程序注册和反注册接口extern void plugin_register(struct PluginStruct *);extern void plugin_unregister(struct PluginStruct *); 三、插件向主程序注册&#x2F;主程序主动加载插件fio中IO引擎的注册包含了两种，（猜测是为了防止其中一种失败，然后采用另一种方式）。 主程序主动加载插件方式是主程序通过dlopen()、dlsym()和dlclose()系列函数完成插件中struct PluginStruct结构体变量的加载，从而获取到插件中相应函数的地址；插件向主程序注册方式是主程序在加载插件动态库时，自动调用某些”构造函数”，而在构造函数中调用主程序的注册函数可以完成插件的注册。 插件程序定义如下： text12345678910111213141516171819202122232425262728293031323334353637383940414243444546// plugin_1.c/* 包含定义插件必须的头文件 */#include &quot;plugin.h&quot;// 插件私有变量定义struct plugin_private_data &#123; // some private data int write_call_times; int read_call_times;&#125;static int plugin_1_init(struct thread_data *td)&#123;&#125;static int plugin_1_uninit(struct thread_data *td)&#123;&#125;static int plugin_1_io_read(struct thread_data *td, struct io_unit *io_u)&#123;&#125;static int plugin_1_io_write(struct thread_data *td, struct io_unit *io_u)&#123;&#125;// 注册所有本插件的相关函数到插件结构体中struct PluginStruct plugin = &#123; .plugin_name = &quot;plugin_1&quot;, .plugin_version = 1, .init = plugin_1_uninit, .uninit = plugin_1_uninit, .io_write = plugin_1_io_write, .io_read = plugin_1_io_read,&#125;;// 插件动态库在加载时会自动调用该函数，因为plugin_init的原因static void plugin_init plugin_1_auto_register()&#123; plugin_register(&amp;plugin);&#125;// 插件动态库在关闭时会自动调用该函数static void plugin_exit plugin_1_auto_unregister()&#123; plugin_unregister(&amp;plugin);&#125; 3.1 主程序主动加载插件主程序通过dlopen()、dlsym()和dlclose()系列函数完成插件中plugin变量的加载，从而完成插件的注册，这种方式的前提是插件中一定定义了plugin变量，否则无法完成插件的加载。 主动加载示例如下： text123456789101112131415// plugin.cstatic PluginStruct* load_plugin(struct thread_data *td, char *plugin_dll_path)&#123; struct PluginStruct *plugin; void *dll_handle = dlopen(plugin_dll_path, RTLD_LAZY); if (!dll_handle) &#123; return NULL; &#125; plugin = dlsym(dll_handle, plugin_dll_path); // 这是啥？ if (!plugin)&#123; plugin = dlsym(dll_handle, &quot;plugin&quot;); &#125; return plugin;&#125; 3.2 插件向主程序注册插件中需要定义的代码如下： text12345678910// plugin_1.c// 插件动态库在加载时会自动调用该函数，因为plugin_init的原因static void plugin_init plugin_1_auto_register()&#123; plugin_register(&amp;plugin);&#125;// 插件动态库在关闭时会自动调用该函数static void plugin_exit plugin_1_auto_unregister()&#123; plugin_unregister(&amp;plugin);&#125;","tags":[{"name":"C/C++","slug":"C-C","permalink":"https://www.delta1037.cn/tags/C-C/"},{"name":"程序设计","slug":"程序设计","permalink":"https://www.delta1037.cn/tags/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/"}]},{"title":"C/C++调用外部程序","date":"2021-02-03T16:00:00.000Z","path":"2021/C_C++/C-C++调用外部程序/","text":"C&#x2F;C++中调用外部程序的接口：exec系列函数、system、popen 一、exec库函数基于系统调用execve()，提供了一系列冠以exec来命名的上层库函数，虽然接口方式各异，但功能一致。 1.1 执行新程序：execve()系统调用execve()可以将新的程序加载到调用者进程的内存空间。这一操作过程中，进程的栈、数据以及堆段会被新的程序相应部件替换。一般由fork()生成的子进程对execve()的调用最常见。 execve()系统调用定义如下： text1234#include &lt;unistd.h&gt;int execve(const char *pathname, char *const argv[], char *const envp[]);/* 成功不返回，失败返回-1 */ execve()系统调用参数说明： pathname是准备载入当前进程空间的新程序的路径名。pathname可以是绝对路径，也可以是相对调用进程当前工作目录（current working directory）的相对路径 argv指定了传递给新进程的命令行参数。argv是由字符串指针组成的列表，并且以NULL值结尾。其中argv[0]的值对应于命令名，通常来说与pathname中的basename（路径的最后部分）值相同。 envp指定了新程序的环境列表。对应于新程序的environ数组，也是由字符串指针组成的列表，格式为name=value，并且以NULL值结尾。 调用execve()之后,因为同一进程依然存在，所以进程ID不变。 1.2 exec()库函数基于系统调用，库函数提供了多种API选择，这些API都构建于execve()之上，只是在为新程序指定程序名，参数列表以及环境变量的方式上有所不同。 exec()库函数API如下： text12345678#include &lt;unistd.h&gt;int execle(const char *pathname, const char * arg, ... /*, (char*)NULL, char *const envp[] */);int execlp(const char *filename, const char * arg, ... /*, (char*)NULL */);int execvp(const char *filename, char *const argv[]);int execv(const char *pathname, char *const argv[]);int execl(const char *pathname, const char * arg, ... /*, (char*)NULL */);/* 成功不返回，失败返回-1 */ exec()库函数之间的差异总结 函数 对程序文件的描述（-,p） 对参数的描述（v,l） 环境变量来源（e,-） execve() 路径名 数组 envp参数 execle() 路径名 列表 envp参数 execlp() 文件名+PATH 列表 调用者的environ execvp() 文件名+PATH 数据 调用者的environ execv() 路径名 数组 调用者的environ execl() 路径名 列表 调用者的environ fexecve()执行由文件描述符指定的程序。有些应用程序需要打开某个文件，通过执行校验和之后再运行该程序，这一场景就比较适合使用fexecve()，该接口定义如下： text12345#define _GNU_SOURCE#include &lt;unistd.h&gt;int fexecve(int fd, char *const argv[], char *const envp[]);/* 成功不返回，失败返回-1 */ 1.3 解释器脚本解释器(interpreter)是能够读取并执行文本格式命令的程序。（相形之下，编译器是将源代码译为可在真实或者虚拟机上执行的机器语言）解释器通常可以从被称为脚本的文件中读取和执行命令。 UNIX内核运行解释器脚本的方式与二进制程序无异，前提是：1、必须赋予脚本可执行权限；2、文件的起始行必须执行运行脚本的解释器路径名，格式如下： text12345#! interpreter# 其中# 1、#!必须置于改行起始处，这两个字符可以与解释器的路径名使用空格分割# 2、在解释解释器路径名时不会使用环境变量PATH，所以解释器路径一般使用绝对路径# 3、解释器路径名后可以跟随可选参数，二者以空格分隔，但是可选参数中不应包含空格（Linux系统不会将对可选参数中的中的空格做特殊解释，从参数起始到行尾视为一个单词，并且要求脚本的#!起始行不超过127个字节，包括换行符） 当调用execve()来运行脚本时，execve()如果检测到传入的文件以两字节序列开始，就会析取该行剩余的部分（路径名和参数）。然后按照如下格式执行解释器程序： text1interpreter-path [optional-arg] script-path arg interpreter-path(解释器路径)和optional-arg(可选参数)都取自脚本的#!行，script-path时传递给execve()的路径名，arg是通过argv传递给execve()的参数列表（argv[0]排除在外）。 二、执行shell命令：system程序可以通过调用system()函数来执行任意的shell命令，函数定义如下： text12345678#include &lt;stdlib.h&gt;int system(const char*command);# 返回值定义如下# 1、当command命令为NULL指针时，如果shell可用则system()返回非0值，如果不可用则返回0# 2、如果无法创建子进程或者无法获取其终止状态，system返回-1# 3、如果子进程不能执行shell，则system返回值与子shell调用_exit(127)终止时一样# 4、如果所有的系统调用都成功，system返回执行command的子shell的终止状态。shell的终止状态是执行最后一条命令时的退出状态；如果命令被信号所杀，大多数shell会以128+n的值退出，其中n为信号编号 函数system()创建一个子进程来运行shell，并以之执行命令command。所以使用system()函数运行命令至少会创建两个进程，一个用于运行shell，另一个或者多个用于运行shell所执行的命令（如果对效率或者速度有要求，最好直接调用fork()和exec()来执行既定程序）。 三、通过管道与shell命令通信popen管道的一个常见的用途是执行shell命令并读取或向其发送一些输入。popen()和pclose()简化了这个任务，函数定义如下： text123456#include &lt;stdio.h&gt;FILE *popen(const char *command, const char *mode);/* 成功时返回文件流指针，失败时返回NULL并设置errno */int pclose(FILE *stream);/* 成功时返回子进程结束状态，失败返回-1 */ popen()函数创建了一个管道，然后创建了一个子进程来执行shell，而shell又创建了一个子进程来执行command字符串。其中mode是一个字符串，它确定调用进程是从管道中读取数据（mode是r）或者是写入到管道中（mode是w），由于管道是单向的，所以无法在执行的command中进行双向通信。 与使用pipe()创建的管道一样，当从管道中读取数据时，调用进程在command关闭管道的写入端之后会看到文件结束；当向管道写入数据时，如果command已经关闭了管道的读取端，那么调用进程会收到SIGPIPE并的到EPIPE错误。 当IO结束之后可以使用pclose()函数关闭管道并等待子进程中的shell终止（不应该使用fclose()函数，因为它不会等待子进程）。pclose()在成功时会返回子进程中shell的终止状态（即shell命令执行最后一条命令的终止状态，除非是被信号杀死的）。与system()一样，如果无法执行shell，pclose()会返回一个值就像是子进程中的shell调用_exit(127)来终止一样。如果发生了其它错误，那么pclose()返回-1。 参考文献【0】Linux&#x2F;UNIX系统编程手册","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.delta1037.cn/tags/Linux/"},{"name":"C/C++","slug":"C-C","permalink":"https://www.delta1037.cn/tags/C-C/"}]},{"title":"计算机系统","date":"2021-01-30T16:00:00.000Z","path":"2021/OS/计算机系统/","text":"深入理解计算机系统中关于系统的摘要 计算机系统一、硬件组织1.1 总线总线被设计成传送定长的字节块，也就是字（word）。现在大多数机器要么是4个字节（32位），要么是8个字节（64位）。 1.2 I&#x2F;O设备I&#x2F;O设备是是系统与外部的联系通道。基本的I&#x2F;O设备包括：作为用户输入的鼠标和键盘、作为用户输出的显示器和用于长期存储数据和程序的磁盘驱动器（磁盘）。 每一个I&#x2F;O设备都通过一个控制器或适配器与I&#x2F;O总线相连。控制器是IO设备本身或者系统的主印制电路板（主板）上的芯片组。适配器是插在主板插槽上的卡。 1.3 主存主存是一个临时存储设备。在处理器执行程序时，用来存放程序和程序处理的数据。从物理上来讲，主存是一组动态随机存取存储器（DRAM）组成的；从逻辑上来说，存储器是一个线性的字节数组，每个字节有唯一的地址。 1.4 处理器中央处理单元（CPU），简称处理器，是解释（执行）存储在主存中指令的引擎。处理器的核心是一个大小为一个字的存储设备（或寄存器），称为程序计数器（PC）。 从系统通电开始，直到系统断电，处理器一直在不断地执行程序计数器指向的指令，再更新计数器，使之指向下一条指令。 二、操作系统操作系统的两个基本功能：（1）防止硬件被失控的应用程序滥用；（2）向应用程序提供简单一致的机制来控制复杂而又通常不同的低级硬件设备。 2.1 进程进程是操作系统对一个正在运行的程序的一种抽象。在一个系统上可以同时运行多个进程，每个进程像是独占地使用硬件。 一个CPU看上去在并发地执行多个进程，这是通过进程间的切换实现的。操作系统实现这种交错执行的机制称为上下文切换，操作系统保持跟踪进程运行所需的所有的状态信息，这些状态信息就是上下文。 2.2 线程在现代操作系统中，一个进程实际上是可以由多个称为线程的执行单元组成，每个线程运行在进程的上下文中，并共享同样的代码和全局数据。 2.3 虚拟内存虚拟内存是一个抽象概念，为每一个进程提供了一个假象——每个进程在独占地使用主存。每个进程看到地内存都是一致地，称为虚拟地址空间。 Linux进程地虚拟地址空间是由大量准确定义地区域组成的。从低地址到高地址主要有： 只读的代码和数据、读&#x2F;写数据：对所有的进程来说，代码是从一个固定的地址开始的。代码区和数据区是直接按照可执行目标文件的内容初始化的。 运行时堆：堆可以在运行时进行动态地扩展和收缩 共享库：大约在地址空间的中间部分。 用户栈：编译器用它来实现函数调用。每调用一个函数，栈就会增长；从一个函数返回时，栈会收缩。 内核虚拟内存：为内核保留，不允许应用程序读写这个区域的内容或者直接调用内核代码定义的函数。相反，必须调用内核来执行这些操作。 2.4 文件文件就是字节序列。每一个IO设备甚至是网络，都可以看成是文件。系统中的所有输入输出都是通过一组Unix I&#x2F;O的系统函数调用读写文件来实现的。 三、计算机系统中的抽象 文件是对I&#x2F;O设备的抽象 虚拟内存是是对程序存储器的抽象（主存和磁盘的抽象） 进程是对一个正在运行的程序的抽象（处理器、主存和I&#x2F;O设备的抽象） 参考资料【0】深入理解计算机系统","tags":[{"name":"系统","slug":"系统","permalink":"https://www.delta1037.cn/tags/%E7%B3%BB%E7%BB%9F/"}]},{"title":"圣诞树彩灯曲线方程","date":"2020-12-18T16:00:00.000Z","path":"2020/Math/圣诞树彩灯曲线方程/","text":"马上就要圣诞节了，圣诞树上会绕一圈彩灯，以表对圣诞节的敬意，淦！讨论一下理想状态下圣诞树彩灯曲线方程。 对于一个圣诞树，绕的一圈的彩灯的曲线是什么样的呢？侧面看起来是什么样的？如果彩灯曲线上彩灯分布式均匀的，那么彩灯的位置该怎么计算？ 本文假设圣诞树是一个圆锥体，彩灯从顶端开始等梯度绕线，并绕了整数圈，如下图所示： 本文主要固定值： H：圆锥体高 W：圆锥体底面直径 A：圆锥顶点 O：圆锥底面圆心 M：绕线与底面的交点 Q：绕线的圈数 T：彩灯的间隔距离 一、建立三维的彩灯曲线方程以圆锥的底面圆心O为基准，在底面上建立极坐标系；以从圆锥顶点A到圆锥底面圆心O方向为$Z$轴；建立坐标系，如下图所示 绕线的圈数是Q，所以绕线的总角度是 $2{\\pi}Q$，由于绕线是均匀的，所以$Z$轴方向的$h$和极坐标平面上的曲线半径$l$都是均匀变化的，所以曲线方程如下： $$f(\\theta, l, h)\\begin{cases}\\theta&#x3D;\\theta , &amp;0 \\le \\theta \\le 2{\\pi}Q \\l &#x3D; { {W\\theta}\\over{4{\\pi}Q} }, \\h &#x3D; { {H\\theta}\\over{2{\\pi}Q} },\\end{cases}$$ 其中： 曲线半径最大是$W\\over2$，在$\\theta \\in[0, 2{\\pi}Q]$的范围内均匀变化所以$l &#x3D; { { W\\over2 }\\over{2{\\pi}Q} }\\theta &#x3D; { {W\\theta}\\over{4{\\pi}Q} }$ 圆锥高为$H$，在$\\theta \\in[0, 2{\\pi}Q]$的范围内均匀变化所以$l &#x3D; { { H }\\over{2{\\pi}Q} }\\theta &#x3D; { {H\\theta}\\over{2{\\pi}Q} }$ 二、俯视图的彩灯曲线圣诞树上彩灯从树的俯视图方向看如下： 为什么俯视图（像）是螺旋线呢？俯视图去掉了三维视图中高的特征，所以可以在俯视图上建立极坐标系，如下如所示： 从三维坐标系中抽出极坐标平面相关的变量，由于三维坐标系中的曲线方程$f(\\theta, l, h)$组成的方程中与极坐标平面相关的变量$\\theta,l$与$h$没有关系，所以俯视图彩灯曲线方程如下： $$l &#x3D; f(\\theta) &#x3D; { {W\\theta}\\over{4{\\pi}Q} } \\ \\ \\ \\ \\ \\ \\ 0 \\le \\theta \\le 2{\\pi}Q \\$$ 其中： $l$是随$\\theta$均匀变化的，所以俯视图是平面上的螺旋线。 三、主视图的彩灯曲线圣诞树上的彩灯从树的主视图方向看如下： 主视图为什么长这个样子呢？主视图上关于三维坐标系中的$h$相关的特征是没有损失的，那么关于螺旋线在主视图上的投影是什么样的呢？ 我们可以在俯视图的螺旋线上看（如下图所示），我们对于螺旋线的任何一个位置，向极坐标的起始位置作垂线（起始位置是与主视图方向平行的），也就是在$\\theta$处，我们在主视图方向看到的偏离圆锥中轴线方向的长度是$l*cos(\\theta)$。 我们在主视图上建立如下坐标系： 所以根据以上的分析，在$h$方向是随$\\theta$均匀变化的，在$w$方向，坐标长度是$l*cos(\\theta)$，但是在主视图的坐标系中不存在$\\theta$变量，所以我们使用h变量来替换掉$\\theta$，根据彩灯的三维曲线方程，我们知道$h &#x3D; { {H\\theta}\\over{2{\\pi}Q} }$，所以$\\theta$使用$h$来表示则是$\\theta &#x3D; { {2{\\pi}Qh}\\over{H} }$，$l$使用$\\theta$替换可得$l &#x3D; { {W\\theta}\\over{4{\\pi}Q} }$。所以在$w$方向，$w &#x3D; l\\ cos(\\theta) &#x3D; { {W\\theta}\\over{4{\\pi}Q} } \\ cos(\\theta) &#x3D; {Wh\\over2H}\\ cos({ {2{\\pi}Qh}\\over{H} })$ 。所以主视图上的方程如下： $$w &#x3D; f(h) &#x3D; {Wh\\over2H}\\ cos({ {2{\\pi}Qh}\\over{H} }) \\ \\ \\ \\ \\ \\ \\ 0 \\le h \\le H \\$$ 其中： $w$的核心为$h \\ cos(h)$，该函数是一次函数$h$和三角函数$cos(h)$的乘积，即使用一次函数$h$对三角函数$cos(h)$的范围进行了限制。 四、主视图上彩灯位置方程俯视图上来看彩灯的间隔距离是不相等的（由于俯视图上将曲线等梯度下降这一特性抹掉了，彩灯实际的距离应该是$\\sqrt{ 彩灯间隔对应梯度^2 + 俯视图彩灯间隔^2 }$，联想到小时候见到的一个三角形纸片卷在铅笔上从而类似盘山公路，将螺旋线展开可能也是一个直角三角形，将盘山公路这一想法对应到螺旋线中，从三维方程中可知，$h &#x3D; { {H \\theta}\\over{2{\\pi}Q} } $，即$h$是随着$\\theta$线性变化的，即盘上公路展开的图形的高是随着$\\theta$线性变化的；盘山公路展开的图形对应的底边是$l\\Delta \\theta$的和式，由于$l &#x3D; { {W\\theta}\\over{4{\\pi}Q} }$，所以底边对应增量$d{v} &#x3D; { {W\\theta}\\over{4{\\pi}Q} } d*{\\theta}$，求积分得$V &#x3D; { {W\\theta^{2} }\\over{8{\\pi}Q} } $，所以展开图形的底边不是随着$\\theta$线性变化的，所以螺旋线展开不是一个直角三角形，其中斜边向下弯曲，因为斜率随着$\\theta$的增大而减小） 但我们为了简化计算，认为螺旋线的展开是一个三角形，并且从$\\theta$的范围得出底边的总长度是${\\pi wQ}\\over{2}$。 为了计算彩灯间隔T对应的$\\Delta h$，有了$\\Delta h$才能计算每一个彩灯相对于上一个$h$位置的$w$值。 假设彩灯在俯视图上的间隔是T，假设间隔T对应的角度变化量为$\\Delta \\theta$，所以T和$\\Delta \\theta$的对应关系是 $$T &#x3D; l\\Delta \\theta &#x3D; { {W\\theta}\\over{4{\\pi}Q} } \\Delta \\theta$$ 代入$\\theta &#x3D; { {2{\\pi}Qh}\\over{H} }$可得 $$\\Delta \\theta &#x3D; { 4{ {\\pi}QT}\\over{W\\theta} } &#x3D; { 2HT \\over { Wh } }$$ 由$\\theta &#x3D; { {2{\\pi}Qh}\\over{H} }$可得 $$\\Delta \\theta &#x3D; { {2{\\pi}Q\\Delta h}\\over{H} }$$ 联立方程(5)(6)消去$\\Delta \\theta$可得 $$\\Delta h &#x3D; { TH^2 \\over {\\pi WQh} }$$ 所以每一次彩灯的变化量与当前的h值有关（假设当前为$h$，则下一次位置是$h + \\Delta h$，以此自以为是的将方程7进行修正，将$h$值取为当前$h$和下一次位置$h + \\Delta h$的平均值$h + { \\Delta h \\over 2 }$，从而得到如下方程） $$\\Delta h &#x3D; { TH^2 \\over {\\pi WQ(h + {\\Delta h\\over2}) } }$$ 从而得到一元二次方程 $${\\pi WQ \\over 2}·\\Delta h^2 + {\\pi WQh}·\\Delta h - TH^2 &#x3D; 0$$ 由$x_1,x_2 &#x3D; {-b \\pm \\sqrt{b^2-4ac} \\over 2 }$得 $$\\Delta h_1 &#x3D; -h + { \\sqrt{ h^2 + {2TH^2\\over{ \\pi WQ } } } }\\\\Delta h_2 &#x3D; -h - { \\sqrt{ h^2 + {2TH^2\\over{ \\pi WQ } } } } （负值舍去）$$ JS语言代码示例 text1234567891011121314var h_start = 0.001;var h_max = 300;for(double h = h_start; h &lt; h_max;)&#123; // 计算灯位置的x坐标和y坐标 var light_x = h; var light_y = (W*h)/(2*H) * Math.sin(2*Math.PI*Q*h/H) // 更新h的值 var equation_A = Math.PI * W * Q / 2; var equation_B = Math.PI * W * Q * h; var equation_C = -(T * H * H); h = Math.sqrt(equation_B * equation_B - 4 * equation_A * equation_C) / (2 * equation_A);&#125; 渲染出来的图： 备注： 如果想固定彩灯的总数$N$，需要求得彩灯间隔T的值，俯视图上的线的总长度是${\\pi wQ}\\over{2}$，所以该长度除以$N$得$T &#x3D; { {\\pi wQ}\\over{2N} } $ 。","tags":[{"name":"Math","slug":"Math","permalink":"https://www.delta1037.cn/tags/Math/"}]},{"title":"布隆过滤器","date":"2020-12-10T16:00:00.000Z","path":"2020/Math/布隆过滤器/","text":"布隆过滤器 一、简介布隆过滤器是由伯顿·布隆于1970年提出的。布隆过滤器实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器用于判断一个元素是否在一个集合中，它只有插入元素和查询元素是否存在两种操作。 哈希表也有与布隆过滤器同样的功能，但是布隆过滤器只需要哈希表的$1&#x2F;8$到$1&#x2F;4$的大小就可以解决相同的问题，但是布隆过滤器可能存在误识别的问题，后续给出误识别的概率计算。 二、应用 建立初始环境：假设存储一亿个电子邮件地址，建立16亿个比特位，即一个两亿字节的向量，将16亿个比特位清零。 插入元素：对于要插入的每一个电子邮件地址，使用8个不同的随机数生成器（$F_1$，$F_2$，…，$F_8$），生成8个信息指纹（$f_1$，$f_2$，…，$f_8$），再使用一个随机数产成器G将8个信息指纹映射到1-16亿中的八个自然数（$g_1$，$g_2$，…，$g_8$）。在16亿个比特位中将这8个自然数位置的比特位置为1。 查询元素：对于一个需要查询的邮件地址，使用相同的八个随机数生成器和随机数产生器得到八个自然数（$t_1$，$t_2$，…，$t_8$），如果在16亿个比特位向量中对应的比特值为1，则判断为元素存在。 问题：有极小的概率误判元素存在，因为有可能某个邮件地址在布隆过滤器中的对应的8个位置恰巧被设置为1。 三、误识别概率计算假设布隆过滤器有m个比特位，已经插入了n个元素，每个元素使用k个散列函数。 在布隆过滤器中插入一个新的元素时，元素的第一个散列函数会将布隆过滤器中的某一位设置为1，因此某一位被设置为1的概率是${ {1}\\over{m} }$（因为一共有m个比特位，每一个比特位被设置为1的概率是相同的，都是${ {1}\\over{m} }$），某一位没有被设置为1的概率是$1-{ {1}\\over{m} }$。 对于布隆过滤器中的一个特定的位置，插入一个元素，k个散列函数都没有将它置为1的概率是$(1-{ {1}\\over{m} })^k$。插入第二个元素，该位置仍然没有被设置为1的概率是$(1-{ {1}\\over{m} })^{2k}$。如果插入了n个元素，该位置仍然没有被置为1的概率是$(1-{ {1}\\over{m} })^{nk}$。反过来，该位置被置为1的概率是$1-(1-{ {1}\\over{m} })^{nk}$。 假定n个元素都已经插入到了布隆过滤器中，新来一个不在集合（即n个元素组成的集合）中的元素，新元素的第一个散列函数正好命中一个被置为1的位置的概率是上述计算的概率是$1-(1-{ {1}\\over{m} })^{nk}$，如果新元素被误识别为在集合中，那么k个散列函数都命中了被置为1的位置，其概率为 $$(1-(1-{ {1}\\over{m} })^{nk})^k \\approx (1-e^{ {-nk}\\over{m} })^k$$ 化简后为 $$p &#x3D; (1-e^{ {-ln({ {m}\\over{n} }ln2)n}\\over{m} })^{ln({ {m}\\over{n} }ln2)}$$ 如果n值比较大，可以近似为 $$(1-e^{ {-k(n+0.5)}\\over{m-1} })^k \\approx (1-e^{ {-kn}\\over{m} })^k$$ 误识别率参考表，来源于Bloom Filters - the math m**&#x2F;**n k k&#x3D;1 k&#x3D;2 k&#x3D;3 k&#x3D;4 k&#x3D;5 k&#x3D;6 k&#x3D;7 k&#x3D;8 2 1.39 0.393 0.400 3 2.08 0.283 0.237 0.253 4 2.77 0.221 0.155 0.147 0.160 5 3.46 0.181 0.109 0.092 0.092 0.101 6 4.16 0.154 0.0804 0.0609 0.0561 0.0578 0.0638 7 4.85 0.133 0.0618 0.0423 0.0359 0.0347 0.0364 8 5.55 0.118 0.0489 0.0306 0.024 0.0217 0.0216 0.0229 9 6.24 0.105 0.0397 0.0228 0.0166 0.0141 0.0133 0.0135 0.0145 10 6.93 0.0952 0.0329 0.0174 0.0118 0.00943 0.00844 0.00819 0.00846 11 7.62 0.0869 0.0276 0.0136 0.00864 0.0065 0.00552 0.00513 0.00509 12 8.32 0.08 0.0236 0.0108 0.00646 0.00459 0.00371 0.00329 0.00314 13 9.01 0.074 0.0203 0.00875 0.00492 0.00332 0.00255 0.00217 0.00199 14 9.7 0.0689 0.0177 0.00718 0.00381 0.00244 0.00179 0.00146 0.00129 15 10.4 0.0645 0.0156 0.00596 0.003 0.00183 0.00128 0.001 0.000852 16 11.1 0.0606 0.0138 0.005 0.00239 0.00139 0.000935 0.000702 0.000574 17 11.8 0.0571 0.0123 0.00423 0.00193 0.00107 0.000692 0.000499 0.000394 18 12.5 0.054 0.0111 0.00362 0.00158 0.000839 0.000519 0.00036 0.000275 19 13.2 0.0513 0.00998 0.00312 0.0013 0.000663 0.000394 0.000264 0.000194 20 13.9 0.0488 0.00906 0.0027 0.00108 0.00053 0.000303 0.000196 0.00014 21 14.6 0.0465 0.00825 0.00236 0.000905 0.000427 0.000236 0.000147 0.000101 22 15.2 0.0444 0.00755 0.00207 0.000764 0.000347 0.000185 0.000112 7.46e-05 23 15.9 0.0425 0.00694 0.00183 0.000649 0.000285 0.000147 8.56e-05 5.55e-05 24 16.6 0.0408 0.00639 0.00162 0.000555 0.000235 0.000117 6.63e-05 4.17e-05 25 17.3 0.0392 0.00591 0.00145 0.000478 0.000196 9.44e-05 5.18e-05 3.16e-05 26 18 0.0377 0.00548 0.00129 0.000413 0.000164 7.66e-05 4.08e-05 2.42e-05 27 18.7 0.0364 0.0051 0.00116 0.000359 0.000138 6.26e-05 3.24e-05 1.87e-05 28 19.4 0.0351 0.00475 0.00105 0.000314 0.000117 5.15e-05 2.59e-05 1.46e-05 29 20.1 0.0339 0.00444 0.000949 0.000276 9.96e-05 4.26e-05 2.09e-05 1.14e-05 30 20.8 0.0328 0.00416 0.000862 0.000243 8.53e-05 3.55e-05 1.69e-05 9.01e-06 31 21.5 0.0317 0.0039 0.000785 0.000215 7.33e-05 2.97e-05 1.38e-05 7.16e-06 32 22.2 0.0308 0.00367 0.000717 0.000191 6.33e-05 2.5e-05 1.13e-05 5.73e-06 m**&#x2F;**n k k&#x3D;9 k&#x3D;10 k&#x3D;11 k&#x3D;12 k&#x3D;13 k&#x3D;14 k&#x3D;15 k&#x3D;16 11 7.62 0.00531 12 8.32 0.00317 0.00334 13 9.01 0.00194 0.00198 0.0021 14 9.7 0.00121 0.0012 0.00124 15 10.4 0.000775 0.000744 0.000747 0.000778 16 11.1 0.000505 0.00047 0.000459 0.000466 0.000488 17 11.8 0.000335 0.000302 0.000287 0.000284 0.000291 18 12.5 0.000226 0.000198 0.000183 0.000176 0.000176 0.000182 19 13.2 0.000155 0.000132 0.000118 0.000111 0.000109 0.00011 0.000114 20 13.9 0.000108 8.89e-05 7.77e-05 7.12e-05 6.79e-05 6.71e-05 6.84e-05 21 14.6 7.59e-05 6.09e-05 5.18e-05 4.63e-05 4.31e-05 4.17e-05 4.16e-05 4.27e-05 22 15.2 5.42e-05 4.23e-05 3.5e-05 3.05e-05 2.78e-05 2.63e-05 2.57e-05 2.59e-05 23 15.9 3.92e-05 2.97e-05 2.4e-05 2.04e-05 1.81e-05 1.68e-05 1.61e-05 1.59e-05 24 16.6 2.86e-05 2.11e-05 1.66e-05 1.38e-05 1.2e-05 1.08e-05 1.02e-05 9.87e-06 25 17.3 2.11e-05 1.52e-05 1.16e-05 9.42e-06 8.01e-06 7.1e-06 6.54e-06 6.22e-06 26 18 1.57e-05 1.1e-05 8.23e-06 6.52e-06 5.42e-06 4.7e-06 4.24e-06 3.96e-06 27 18.7 1.18e-05 8.07e-06 5.89e-06 4.56e-06 3.7e-06 3.15e-06 2.79e-06 2.55e-06 28 19.4 8.96e-06 5.97e-06 4.25e-06 3.22e-06 2.56e-06 2.13e-06 1.85e-06 1.66e-06 29 20.1 6.85e-06 4.45e-06 3.1e-06 2.29e-06 1.79e-06 1.46e-06 1.24e-06 1.09e-06 30 20.8 5.28e-06 3.35e-06 2.28e-06 1.65e-06 1.26e-06 1.01e-06 8.39e-06 7.26e-06 31 21.5 4.1e-06 2.54e-06 1.69e-06 1.2e-06 8.93e-07 7e-07 5.73e-07 4.87e-07 32 22.2 3.2e-06 1.94e-06 1.26e-06 8.74e-07 6.4e-07 4.92e-07 3.95e-07 3.3e-07 m**&#x2F;**n k k&#x3D;17 k&#x3D;18 k&#x3D;19 k&#x3D;20 k&#x3D;21 k&#x3D;22 k&#x3D;23 k&#x3D;24 22 15.2 2.67e-05 23 15.9 1.61e-05 24 16.6 9.84e-06 1e-05 25 17.3 6.08e-06 6.11e-06 6.27e-06 26 18 3.81e-06 3.76e-06 3.8e-06 3.92e-06 27 18.7 2.41e-06 2.34e-06 2.33e-06 2.37e-06 28 19.4 1.54e-06 1.47e-06 1.44e-06 1.44e-06 1.48e-06 29 20.1 9.96e-07 9.35e-07 9.01e-07 8.89e-07 8.96e-07 9.21e-07 30 20.8 6.5e-07 6e-07 5.69e-07 5.54e-07 5.5e-07 5.58e-07 31 21.5 4.29e-07 3.89e-07 3.63e-07 3.48e-07 3.41e-07 3.41e-07 3.48e-07 32 22.2 2.85e-07 2.55e-07 2.34e-07 2.21e-07 2.13e-07 2.1e-07 2.12e-07 2.17e-07 四、参考【0】数学之美 （第三版） 【1】markdown中公式编辑教程 【2】Bloom Filters - the math","tags":[{"name":"Math","slug":"Math","permalink":"https://www.delta1037.cn/tags/Math/"}]},{"title":"经济学十大原理","date":"2020-12-08T16:00:00.000Z","path":"2020/Economics/经济学十大原理/","text":"经济学十大原理 一、十大原理分类1.1 人们如何做出决策原理一：人们面临权衡取舍为了得到一件喜爱的东西，我们通常不得不放弃另一件喜爱的东西。做出决策就是要求我们在一个目标与另一个目标之间进行权衡取舍。 人们只有了解面临的选择，才有可能做出良好的决策。 原理二：某种东西的成本是为了得到它所放弃的东西一种东西的机会成本是为了得到这种东西所放弃的东西 原理三：理性人考虑边际量理性人通常比较边际收益与边际成本来做决策。当且仅当一种行为的边际收益大于边际成本时，一个理性的决策者才会采取这种行为。 原理四：人们会对激励做出反应激励是引起一个人做出某种行为的东西（例如惩罚或奖励的预期）。由于理性人会通过比较成本与收益做出决策，所以他们会对激励做出反应 1.2 人们如何互相影响原理五：贸易可以使每个人的情况都变得更好贸易可以使得每个人做自己擅长的活动。通过与其他人贸易，人们可以以较低的成本获得各种各样的物品与服务。 原理六：市场通常是组织经济活动的一种 好方法市场经济：许多家庭和企业在物品与服务市场上互相交易时，通过他们的分散决策配置资源的经济。 家庭和企业在市场上互相交易，他们仿佛被一只“看不见的手”所指引，并导致了合意的市场结果。 原理七：政府优势可以改善市场的结果看不见的手是强有力的，但并不是无所不能的。政府干预经济并改变人们自己选择的资源配置的原因有两类：促进效率或促进平等。也就是说，大多数政策目标是要么把经济蛋糕做大，要么改变这个蛋糕的分割方式。 1.3 整体经济如何运行原理八：一国的生活水平取决于它生产物品与服务能力生活水平的差别可以归结于生产率的差别，即每一单位劳动投入所生产的物品与服务数量的差别。 原理九：当政府发行了过多的货币时，物价上升通货膨胀是物价总水平的上升。大多数严重或者持续的通货膨胀情况下，罪魁祸首是货币的增长。 原理十：社会面临通货膨胀与失业之间的短期权衡取舍长期中，物价水平的上升主要是货币量增加的结果 货币注入的短期效应： 经济中货币的增加刺激了社会的整体支出水平，从而增加了对物品和服务的需求 需求的增加随着时间的推移，会引起企业提高物价，但同时，它也鼓励企业雇佣更多的工人，并生产更多的物品与服务 雇佣更多的工人意味着更少的失业 二、参考文献【0】经济学原理 微观经济学分册","tags":[{"name":"经济学","slug":"经济学","permalink":"https://www.delta1037.cn/tags/%E7%BB%8F%E6%B5%8E%E5%AD%A6/"}]},{"title":"fcntl","date":"2020-12-03T16:00:00.000Z","path":"2020/Linux/fcntl/","text":"fcntl针对描述符提供控制，可以用来改变已打开文件的性质 一、函数定义函数接口定义： text12345678#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;int fcntl(int fd, int cmd);// 针对cmd的值，可以使用第三个参数arg/lockint fcntl(int fd, int cmd, long arg);int fcntl(int fd, int cmd, struct flock *lock); 函数参数结构定义： text123456789struct flcok &#123; short int l_type; /* 锁类型：F_RDLCK, F_WRLCK, F_UNLCK */ short int l_whence; /* 锁定开始位置：SEEK_SET, SEEK_CUR, SEEK_END */ off_t l_start; /* 锁定开始计算位置：relative starting offset in bytes */ off_t l_len; /* 锁定长度：#bytes; 0 means EOF */ pid_t l_pid; /* PID returned by F_GETLK */&#125;;// 注：开始位置是由l_whence和l_start共同指定的// l_whence指定了l_start开始计算的位置 函数参数解释： fd是要改变的描述符（已打开的文件等） cmd：操作指定，包含如下几种 F_DUPFD：复制一个现有的描述符 F_GETFD&#x2F;F_SETFD：获得／设置文件描述符标记 F_GETFL&#x2F;F_SETFL：获得／设置文件状态标记 F_GETOWN&#x2F;F_SETOWN：获得／设置异步I&#x2F;O所有权 F_GETLK、F_SETLK/F_SETLKW：获得／设置记录锁 arg&#x2F;lock：针对cmd的值，需要的第三个参数 二、应用场景2.1 记录上锁记录上锁使用如下接口： text1234#include &lt;fcntl.h&gt;int fcntl(int fd, int cmd, ... /* struct flock *lock */);/* 成功返回值取决于cmd，失败返回-1 */ 记录上锁使用cmd的类型：F_GETLK、F_SETLK/F_SETLKW F_GETLK： F_SETLK： F_SETLKW： 三、参考文献【0】Unix网络编程","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.delta1037.cn/tags/Linux/"},{"name":"C/C++","slug":"C-C","permalink":"https://www.delta1037.cn/tags/C-C/"}]},{"title":"ioctl","date":"2020-12-03T16:00:00.000Z","path":"2020/Linux/ioctl/","text":"ioctl()系统调用为执行文件和设备操作提供了一种多用途机制 一、接口定义ioctl接口定义： text123#include &lt;sys/ioctl.h&gt;int ioctl(int fd, int request, ... /* argp */) 接口参数说明： fd：某个设备或者文件已经打开的文件描述符 request：将在fd上执行的控制操作（具体设备的头文件定义了可以传递给request参数的常量） argp：argp的值的类型是由request的参数值确定的，类型如下： 不需要该参数（哈哈哈没想到吧） 指向整数或者结构的指针 二、应用场景三、参考文献【0】Linux&#x2F;UNIX系统编程手册","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.delta1037.cn/tags/Linux/"},{"name":"C/C++","slug":"C-C","permalink":"https://www.delta1037.cn/tags/C-C/"}]},{"title":"Linux C语言实现按键即时识别","date":"2020-12-02T16:00:00.000Z","path":"2020/Linux/LinuxC语言实现按键即时识别/","text":"top中的源代码，慢慢理解。。。不需要按ENTER键，按下即可识别 一、代码片段部分摘自top源代码，部分来源于网络博客 text123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384#include &lt;sys/time.h&gt;#include &lt;stdio.h&gt;#include &lt;termios.h&gt;/* The original and new terminal attributes */static struct termios Savedtty, Rawtty;// 设置终端相关属性static void initKeyboard()&#123; tcgetattr(0,&amp;Savedtty); Rawtty = Savedtty; Rawtty.c_lflag &amp;= ~ICANON; // 设置不以规范模式工作，读请求直接从队列读取字符，至少接到MIN字节或者两个字节之间超时值TIME到期时，read才返回 Rawtty.c_lflag &amp;= ~ECHO; // 关闭输入字符回显到终端设备 // Rawtty.c_lflag &amp;= ~ISIG; // 判断输入字符是否要产生终端信号的特殊字符 Rawtty.c_cc[VMIN] = 1; // 至少接到MIN字节 Rawtty.c_cc[VTIME] = 0; // 两个字节之间超时值TIME tcsetattr(0, TCSANOW, &amp;Rawtty);&#125;// 恢复终端属性static void closeKeyboard()&#123; tcsetattr(0, TCSANOW, &amp;Savedtty);&#125;// 读取字符static int chin (int ech, char *buf, unsigned cnt)&#123; int rc; fflush(stdout); if (!ech) rc = read(STDIN_FILENO, buf, cnt); else &#123; tcsetattr(STDIN_FILENO, TCSAFLUSH, &amp;Savedtty); rc = read(STDIN_FILENO, buf, cnt); tcsetattr(STDIN_FILENO, TCSAFLUSH, &amp;Rawtty); &#125; // may be the beginning of a lengthy escape sequence tcflush(STDIN_FILENO, TCIFLUSH); return rc; // note: we do NOT produce a vaid &#x27;string&#x27;&#125;// 判断读取字符的有效性static char kbhit()&#123; long file_flags; int rc; char c; fd_set fs; FD_ZERO(&amp;fs); FD_SET(STDIN_FILENO, &amp;fs); file_flags = fcntl(STDIN_FILENO, F_GETFL); if(file_flags==-1) file_flags=0; fcntl(STDIN_FILENO, F_SETFL, O_NONBLOCK|file_flags); // check 1st, in case tv zeroed (by sig handler) before it got set rc = chin(0, &amp;c, 1); if (rc &lt;= 0) &#123; // EOF is pretty much a &quot;can&#x27;t happen&quot; except for a kernel bug. // We should quickly die via SIGHUP, and thus not spin here. // if (rc == 0) end_pgm(0); /* EOF from terminal */ fcntl(STDIN_FILENO, F_SETFL, file_flags); select(1, &amp;fs, NULL, NULL, NULL); fcntl(STDIN_FILENO, F_SETFL, O_NONBLOCK|file_flags); &#125; if (chin(0, &amp;c, 1) &gt; 0) &#123; fcntl(STDIN_FILENO, F_SETFL, file_flags); return c; &#125; else &#123; fcntl(STDIN_FILENO, F_SETFL, file_flags); &#125; kbhit();&#125;## useinitKeyboard();while(true)&#123; char input = kbhit(); if( input == &#x27;q&#x27;)&#123; // do something break; &#125;&#125;closeKeyboard(); 二、相关知识2.1 终端相关text123456789101112131415#include &lt;termios.h&gt;// 终端属性结构体struct termios&#123; tcflag_t c_iflag; // 输入标志 tcflag_t c_oflag; // 输出标志 tcflag_t c_cflag; // 控制标志 tcflag_t c_lflag; // 本地标志 cc_t c_cc[NCCS]; // 控制字符&#125;;// 获取终端的属性tcgetattr(int fd, struct termios* tty_struct);// 设置终端属性tcsetattr(int fd, int opt, const struct termios* tty_struct); tcsetattr的opt参数指定新设置的终端属性什么时候起作用 TCSANOW：更改立即发生 TCSADRAIN：发送了所有的输出后更改才发生 TCSAFLUSH：发送了所有的输出后更改才发生。更进一步，更改发生时未读入的所有输入都会被丢弃 标志详细见APUE 2.2 select函数允许进程指示内核等待多个事件中的任何一个发生，并且只有一个或者多个事件或者超时之后才唤醒它 text12345#include &lt;sys/select.h&gt;#include &lt;sys/time.h&gt;int select(int maxfdp, fd_set *readset, fd_set *writeset, fd_set *exceptset, const struct timeval *timeout);// return：返回就绪的描述符的数目，超时返回0，出错返回-1 若timeout为空指针，则永远等下去 若timeout中秒数和微妙数设置为0，检查描述符之后立即返回 若timeout中秒数和微妙数设置不为0，在有描述符就绪时返回，但是不超过timeout指定的时间 2.3 fcntl函数text123456int fcntl(int fd, int cmd);int fcntl(int fd, int cmd, long arg);int fcntl(int fd, int cmd, struct flock *lock);//fcntl()针对(文件)描述符提供控制.参数fd是被参数cmd操作(如下面的描述)的描述符。针对cmd的值,fcntl能够接受第三个参数（arg） fcntl函数功能： 复制一个现有的描述符（cmd&#x3D;F_DUPFD） 获得／设置文件描述符标记(cmd&#x3D;F_GETFD或F_SETFD) 获得／设置文件状态标记(cmd&#x3D;F_GETFL或F_SETFL) .获得／设置异步I&#x2F;O所有权(cmd&#x3D;F_GETOWN或F_SETOWN) 获得／设置记录锁(cmd&#x3D;F_GETLK,F_SETLK或F_SETLKW) 三、参考文献【1】top相关源码","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.delta1037.cn/tags/Linux/"},{"name":"C/C++","slug":"C-C","permalink":"https://www.delta1037.cn/tags/C-C/"}]},{"title":"Linux终端动态刷新","date":"2020-12-02T16:00:00.000Z","path":"2020/Linux/Linux终端动态刷新/","text":"Linux终端动态刷新 一、代码片段text123456789101112void CStat::runtimePrintBuf(std::vector&lt;std::string&gt; &amp;buf)&#123; static int last_print_lines = 0; for(int i = 0; i &lt; last_print_lines; ++i)&#123; printf(&quot;\\033[1A&quot;); //先回到上一行 printf(&quot;\\033[K&quot;); //清除该行 &#125; last_print_lines = buf.size(); for(const std::string &amp;it : buf)&#123; printf(&quot;%s\\n&quot;, it.c_str()); &#125;&#125; 二、相关知识2.1 终端颜色字符text12345678910111213141516171819# 字体颜色控制echo -e &quot;\\033[30m 黑色字 \\033[0m&quot;echo -e &quot;\\033[31m 红色字 \\033[0m&quot;echo -e &quot;\\033[32m 绿色字 \\033[0m&quot;echo -e &quot;\\033[33m 黄色字 \\033[0m&quot;echo -e &quot;\\033[34m 蓝色字 \\033[0m&quot;echo -e &quot;\\033[35m 紫色字 \\033[0m&quot;echo -e &quot;\\033[36m 天蓝字 \\033[0m&quot;echo -e &quot;\\033[37m 白色字 \\033[0m&quot;# 字体背景颜色和字体颜色echo -e &quot;\\033[40;37m 黑底白字 \\033[0m&quot;echo -e &quot;\\033[41;37m 红底白字 \\033[0m&quot;echo -e &quot;\\033[42;37m 绿底白字 \\033[0m&quot;echo -e &quot;\\033[43;37m 黄底白字 \\033[0m&quot;echo -e &quot;\\033[44;37m 蓝底白字 \\033[0m&quot;echo -e &quot;\\033[45;37m 紫底白字 \\033[0m&quot;echo -e &quot;\\033[46;37m 天蓝底白字 \\033[0m&quot;echo -e &quot;\\033[47;30m 白底黑字 \\033[0m&quot; 2.2 终端控制字符text12345678910111213141516171819\\33[0m 关闭所有属性\\33[1m 设置高亮度\\33[4m 下划线\\33[5m 闪烁\\33[7m 反显\\33[8m 消隐\\33[30m — \\33[37m 设置前景色\\33[40m — \\33[47m 设置背景色\\33[nA 光标上移n行\\33[nB 光标下移n行\\33[nC 光标右移n行\\33[nD 光标左移n行\\33[y;xH设置光标位置\\33[2J 清屏\\33[K 清除从光标到行尾的内容\\33[s 保存光标位置\\33[u 恢复光标位置\\33[?25l 隐藏光标\\33[?25h 显示光标 在C语言中使用终端控制字符，如上代码片段所示 text12printf(&quot;\\033[1A&quot;); //先回到上一行printf(&quot;\\033[K&quot;); //清除该行 三、参考【0】shell脚本中echo显示内容带颜色","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.delta1037.cn/tags/Linux/"},{"name":"C/C++","slug":"C-C","permalink":"https://www.delta1037.cn/tags/C-C/"}]},{"title":"Shell脚本基础","date":"2020-12-02T16:00:00.000Z","path":"2020/Linux/Shell脚本基础/","text":"Shell脚本基础 一、变量text1234567891011# 使用变量，建议方式$&#123;var&#125;# 在变量名var后是空格时才可用如下方式$var# 设定只读变量declare -r var_namereadonly var_name# 删除变量uset var_name 1.1 字符串变量text123456789101112# 字符串的定义var_string=&quot;hello world&quot;# 字符串的长度计算$&#123;#var_string&#125;# 字符串拼接var_string_new=&quot;$&#123;var_string&#125; new string&quot;######## 字符串操作 ######### 根据起始和截取长度截取字符串$&#123;string_var:start_index:length&#125; 1.2 变量赋值text1234567891011# 除了显式赋值，也可以将命令的结果存入到变量，如下就是将`ls /etc`的结果存到到了file_arrayfile_array=$( ls /etc )# 也可以使用` 命令 `方式file_array=` ls /etc `# 应用:循环访问文件for file in $( ls /etc )do # do somethingdone 1.3 数组变量text12345678910111213141516# 数组的定义array_var=(val0 val1 val2)# 单独定义每个元素array_var[0]=val0array_var[1]=val1# 获取所有元素$&#123;array_var[@]&#125;# 获取数组的长度/元素个数$&#123;#array_var[@]&#125;$&#123;#array_var[*]&#125;# 获取单个元素长度$&#123;#array_var[n]&#125; 二、运算符2.1 算数运算符 +、-、*、/，% 借助expr进行计算，例如expr $var1 + $var2 = 赋值 == 数字比较相等返回true，[ $var1 == $var2 ] != 数字比较不相等返回true，[ $var1 != $var2 ] 2.2 关系运算符关系运算符只用于比较数字之间的关系，不支持字符串，除非字符串的值是数字 eq 数字相等返回true，[ $var1 -eq $var2 ] &#x3D;&gt; == ne 数字不相等返回true，[ $var1 -nq $var2 ] &#x3D;&gt; != gt 左边大于右边返回true，[ $var1 -gt $var2 ] &#x3D;&gt; &gt; lt 左边小于右边返回true，[ $var1 -lt $var2 ] &#x3D;&gt; &lt; ge 左边大于等于右边返回true，[ $var1 -ge $var2 ] &#x3D;&gt; &gt;= le 左边小于等于右边返回true，[ $var1 -le $var2 ] &#x3D;&gt; &lt;= 2.3 布尔运算符设var1=10，var2=20 ! 非运算，表达式为false，返回true，[ ! false ]返回true o 或运算，有一个表达式为true就为true，[ $var1 -lt 20 -o $var1 -gt 100 ]返回true a 与运算，所有表达式为true才是true，[ $var1 -lt 20 -a $var1 -gt 100 ]返回false 2.4 逻辑运算符 &amp;&amp; ：逻辑的AND || ：逻辑的OR text1234# 注意需要两个嵌套的中括号if [[ $&#123;var1&#125; == 0 &amp;&amp; $&#123;var2&#125; == 0 ]];then // do somethingfi 2.5 字符串运算符设var1=&quot;abc&quot;，var2=&quot;efg&quot; = 检测字符串相等返回true，[ $var1 = $var2 ]返回false != 检测字符串不相等返回true，[ $var1 != $var2 ]返回true z 检测字符串长度为0返回true，[ -z $var1 ]返回false n 检测字符串长度不为0返回true，[ -n $var1 ]返回true $ 检测字符串不为空返回true，[ $var1 ]返回true text12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152########## 字符串为空和字符串长度的运算测试 ###########!/bin/bashvar1=var2=&quot;&quot;if [ -z $var1 ];then echo &quot;var1 字符串长度为0&quot;else echo &quot;var1 字符串长度不为0&quot;fiif [ -z $var2 ];then echo &quot;var2 字符串长度为0&quot;else echo &quot;var2 字符串长度不为0&quot;fiif [ -z $no_exits ];then echo &quot;no_exits 字符串长度为0&quot;else echo &quot;no_exits 字符串长度不为0&quot;fiif [ $var1 ];then echo &quot;var1 字符串不为空&quot;else echo &quot;var1 字符串为空&quot;fiif [ $var2 ];then echo &quot;var2 字符串不为空&quot;else echo &quot;var2 字符串为空&quot;fiif [ $no_exits ];then echo &quot;no_exits 字符串不为空&quot;else echo &quot;no_exits 字符串为空&quot;fi########## 输出 ##########var1 字符串长度为0var2 字符串长度为0no_exits 字符串长度为0var1 字符串为空var2 字符串为空no_exits 字符串为空########## 结论 ##########字符串长度和字符串是否为空的运算*好像*是一致的，他们有没有区别呢？ 2.6 文件测试运算符使用方法： file_name operator e 文件是否存在 r 文件可读检测 w 文件可写检测 x 文件可执行检测 d 目录检测 f 普通文件检测（既不是目录，也不是设备文件） b 块设备检测 c 字符设备检测 p 有名管道检测 s 文件大小是否为0 S 文件是否是socket连接 L 文件是否存在并且是一个符号链接 g 文件SGID位检测 u 文件SUID位检测 k 文件粘滞位（Sticky Bit）检测 三、参考文章【1】Shell 教程","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.delta1037.cn/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://www.delta1037.cn/tags/Shell/"}]},{"title":"Linux获取时间","date":"2020-11-19T16:00:00.000Z","path":"2020/Linux/Linux获取时间/","text":"Linux获取时间 一、获取时间1.1 获取秒、微秒Linux中获取微秒级时间的系统调用gettimeofday()，但是返回值的准确性依赖于系统的架构。 text123#include &lt;sys/time.h&gt;/* 在tz指向的缓冲区中返回日历时间；Linux不支持tz参数，设置为NULL */int gettimeofday(struct timeval *tv, struct timezone *tz); 其中timeval结构体定义如下 text1234struct timeval &#123; time_t tv_sec; /* 从1970年1月1日00:00:00以来的秒数(long) */ suseconds_t tv_usec; /* 附加的微秒(long int) */&#125; time()系统调用返回自Epoch( 1970年1月1日00:00:00 )以来的秒数，如果p_time参数不为空，则会将返回值置于p_time指向的位置。 text12#include &lt;time.h&gt;time_t time(time_t *p_time); 二、时间转换2.1 time_t和可打印的格式ctime()提供了一种简单的将时间转成字符串格式的转换方式。 text1234#include &lt;time.h&gt;char *ctime(const time_t *p_time); // 返回的字符串包括终止空字符和换行符// output eg : Wed Jun 8 14:22:34 2012// 返回的字符串是静态分配的，下次调用会覆盖 注：在SUSv3规定，调用ctime()、gmtime()、localTime()或asctime()中的任一个函数，都可能覆盖其它函数的返回 2.2 time_t和分解的格式gmtime()可以把日历时间转换成一个对应UTC的分解的时间；localTime()考虑时区和夏令时的设置，返回对应系统本地时间的分解时间 text1234567#include &lt;time.h&gt;struct tm *gmtime(const time_t *p_time);struct tm *localTime(const time_t *p_time);// 可重入版本struct tm *gmtime_r(const time_t *p_time);struct tm *localTime_r(const time_t *p_time); text123456789101112// 分解时间结构体struct tm &#123; int tm_sec; /* seconds [0,61] */ int tm_min; /* minutes [0,59] */ int tm_hour; /* hour [0,23] */ int tm_mday; /* day of month [1,31] */ int tm_mon; /* month of year [0,11] */ int tm_year; /* years since 1900 */ int tm_wday; /* day of week [0,6] (Sunday = 0) */ int tm_yday; /* day of year [0,365] */ int tm_isdst; /* daylight savings flag */&#125;; 2.3 分解的格式与可打印格式asctime()将分解的格式转换成可打印的格式，指向由静态分配的字符串 text12345#include &lt;time.h&gt;char *asctime(const struct tm *timeptr);// 可重入版本char *asctime_r(const struct tm *timeptr); strftime()在将分解的时间转换成可打印的格式时提供更为精确的控制。 text12345#include &lt;time.h&gt;size_t strftime(char *out_str, size_t max_size, const char *format, const struct tm *timeptr);// strftime不会自动添加换行符// out_str会按照format做格式化 format参数定义： 说明符 描述 实例 %a 星期几的缩写 Tue %A 星期几的全称 Tuesday %b 月份名称的缩写 Feb %B 月份全称 February %c 日期和时间 Tue Feb 1 21:39:46 2011 %d 一月中的一天（两位数字，01-31） 01 %D 美国日期的格式（同%m%d%y） 02&#x2F;01&#x2F;2011 %e 一月中的一天（两个字符） 1 %F ISO格式的日期（%Y-%m-%d） 2011-02-01 %H 24 小时格式的小时（两位数，00-23） 21 %I 12 小时格式的小时（两位数，01-12） 09 %j 一年中的第几天（三位数，001-366） 032 %m 十进制数表示的月份（两位，01-12） 08 %M 分（两位，00-59） 55 %p AM 或 PM 名称 PM %P 上午&#x2F;下午（GNU扩展） pm %R 24小时制的时间（%H:%M） 21:39 %S 秒（00-61） 46 %T 时间（%H:%M:%S） 21:39:46 %u 星期几编号（1-7） 2 %U 一年中的第几周，以第一个星期日作为第一周的第一天（00-53） 05 %w 十进制数表示的星期几，星期日表示为 0（0-6） 2 %W 一年中的第几周，以第一个星期一作为第一周的第一天（00-53） 05 %x 日期表示法（本地化） 02&#x2F;01&#x2F;2011 %X 时间表示法（本地化） 21:39:46 %y 两位数字年份，最后两个数字（00-99） 11 %Y 四位数字年份 2011 %Z 时区的名称或缩写 CET %% 一个 % 符号 % strptime()是strftime()的逆向函数，将包含日期的字符串转换成分解的时间 text1234#define _XOPNE_SOURCE#include &lt;time.h&gt;char *strptime(const char *str, const char *format, struct tm *time_ptr); 转换图下图来自Linux&#x2F;Unix系统编程手册","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.delta1037.cn/tags/Linux/"},{"name":"C/C++","slug":"C-C","permalink":"https://www.delta1037.cn/tags/C-C/"}]},{"title":"C++ 类型转换","date":"2020-04-24T16:00:00.000Z","path":"2020/C_C++/C++类型转换/","text":"C++中的const_cast、static_cast、dynamic_cast和reinterpret_cast C++类型转换典型的C类型转换如下所示 text12Typename_1 var_type_1;Typename_0 var_type_0 = (Typename_0)var_type_1; 在C语言中，不管什么类型的转换都可以使用上述的形式；C++也支持上述类型的强制类型转换，但是这种转换可能会带来一些隐患，所以C++提供了四个在不同场合的强制类型转换函数：const_cast, static_cast, dynamic_cast, reinterpret_cast 一、const_castconst_cast用于修改指针或者引用，将指针或引用的常量形式转为非常量的形式，并且仍然指向原来的对象 SUM： 修改指针或者引用 常量转为非常量 Code： text1234567891011121314151617# 正常的使用方法int test_func()&#123; int num = 6; const int *p_const_num = &amp;num; int *p_num = const_cast&lt;int*&gt;p_const_num; *p_num = 8; return 0;&#125;# 未定义的使用方法int test_func()&#123; const char *p_const_str = &quot;ABCD&quot;; char *p_str = const_cast&lt;char*&gt;p_const_str; return 0;&#125; 二、static_caststatic_cast与C语言风格的强制转换效果一样 SUM： 常用于： 类层次结构中基类（父类）和派生类（子类）之间指针或引用的转换。注意：进行上行转换（把派生类的指针或引用转换成基类表示）是安全的；进行下行转换（把基类指针或引用转换成派生类表示）时，由于没有动态类型检查，所以是不安全的。 基本数据类型之间的转换，如把int转换成char，把int转换成enum。安全性需要开发者来维护 注： 没有运行时检查，与C风格一样都存在安全隐患 static_cast不能转换掉原有类型的const、volatile、或者 __unaligned属性。(前两种可以使用const_cast 来去除) c++ 的任何的隐式转换都是使用 static_cast 来实现 Code： text1234567891011121314151617class Base&#123; // base class&#125;;class Sub : public Base&#123; // sub class&#125;;// 继承类向基类的转换，编译通过并且是安全的Sub sub;Base *base_ptr = static_cast&lt;Base*&gt;sub;// 基类向继承类的转换，编译通过但是是不安全的Base base;Sub *sub_ptr = static_case&lt;Sub*&gt;base; 三、dynamic_castdynamic_cast将基类指针（或引用）转换成继承类指针（或引用），dynamic_cast会根据基类指针是否真正指向继承类指针做相应处理。 text1234567891011121314151617181920212223242526272829303132333435363738394041424344class Base&#123;public: virtual void print()&#123; cout &lt;&lt; &quot;base class print&quot; &lt;&lt; endl; &#125;&#125;;class Sub : public Base &#123;public: void print() override&#123; cout &lt;&lt; &quot;sub class print&quot; &lt;&lt; endl; &#125;&#125;;int main() &#123; Sub *sub_ptr = new Sub(); sub_ptr-&gt;print(); // 如果基类没有虚函数，使用dynamic_cast会报错 Base *base_ptr = dynamic_cast&lt;Base*&gt;(sub_ptr); if(base_ptr)&#123; base_ptr-&gt;print(); &#125;else&#123; cout &lt;&lt; &quot;base ptr is NULL&quot; &lt;&lt; endl; &#125; delete sub_ptr; base_ptr = new Base(); base_ptr-&gt;print(); sub_ptr = dynamic_cast&lt;Sub*&gt;(base_ptr); if(sub_ptr)&#123; sub_ptr-&gt;print(); &#125;else&#123; cout &lt;&lt; &quot;sub ptr is NULL&quot; &lt;&lt; endl; &#125; delete base_ptr; return 0;&#125;/* Win10上的Clion输出如下: sub class print sub class print base class print sub ptr is NULL*/ 从上边的运行结果可以看出： 从子类到基类的指针dynamic_cast转换没有问题 从基类到子类的转换虽然编译没有报错，但是转换的sub_ptr是一个空指针，说明dynamic_cast在程序运行时对类型进行了检查（RTTI，运行期类型检查，Runtime type information） 这个检查主要来自虚函数，虚函数时dynamic_cast转换能够进行的前提条件。当一个类有一个虚函数，那么编译器会构造出来一个虚函数表来指示这些虚函数的地址，如果该类被继承并且子类实现了一个同名并具有相同的函数签名的方法重写了基类的方法，那么虚函数表中会将该函数指向新的地址。此时多态性体现：使用激烈的指针或引用指向子类的对象，调用该方法时会顺着虚函数表找到对应子类的方法。 四、reinterpret_castreinterpret_cast是强制类型转换符用来处理无关类型转换的，通常为操作数的位模式提供较底层的重新解释。 主要应用在： 任意指针之间的转换 引用之间的转换 指针和足够大的int类型之间的转换 整数到指针的转换 text123456789101112int main() &#123; int *num_ptr = new int(2333); uint64_t ptr_num = reinterpret_cast&lt;uint64_t&gt;(num_ptr); cout &lt;&lt; &quot;ptr addr :&quot; &lt;&lt; hex &lt;&lt; num_ptr &lt;&lt; endl &lt;&lt; &quot;num val :&quot; &lt;&lt; hex &lt;&lt; ptr_num &lt;&lt; endl; return 0;&#125;/*64位机器上的测试和输出 ptr addr :0x80004adc0 num val :80004adc0*/ 参考【0】c++ 四种强制类型转换介绍 【1】C++虚函数表剖析 【2】dynamic_cast","tags":[{"name":"C/C++","slug":"C-C","permalink":"https://www.delta1037.cn/tags/C-C/"}]},{"title":"MySQL使用MariaDB Audit Plugin实现审计功能","date":"2019-10-19T16:00:00.000Z","path":"2019/Deploy/MySQL使用MariaDBAuditPlugin实现审计功能/","text":"MySQL使用MariaDB Audit Plugin实现审计功能。 一、安装MariaDB Audit Plugin1.1 准备MariaDB安装环境为了不对使用mysql的主机造成影响，建议使用另一台与mysql主机系统一致的主机来安装MariaDB，然后不用执行下面的卸载操作 text123sudo apt-get autoremove --purge mysql-\\*sudo rm -rf /var/lib/mysql*sudo rm -rf /etc/mysql/ 1.2 安装MariaDBtext1sudo apt-get install mariadb-server 安装完成之后在&#x2F;usr&#x2F;lib&#x2F;mysql&#x2F;plugin目录中有server_audit.so插件，将该插件拷贝出来备用（拷贝到mysql主机的&#x2F;usr&#x2F;lib&#x2F;mysql&#x2F;plugin目录中） 1.3 MySQL环境恢复如果是在mysql的主机上进行安装MariaDB操作，使用如下命令将MariaDB卸载，并重新安装mysql text12345sudo apt-get remove --purge mariadb-\\*sudo rm -rf /etc/mysql/sudo rm -rf /var/lib/mysql*sudo apt-get remove --purge mysql-\\*sudo apt-get install mysql-server mysql-client 1.4 添加MySQL配置修改&#x2F;etc&#x2F;mysql&#x2F;my.cnf文件，在文件末尾添加如下内容 text12345[mysqld]log_output=FILEserver_audit_file_path=/var/log/mysql/audit.logserver_audit_events = &#x27;QUERY_DCL,QUERY_DML_NO_SELECT,QUERY_DML,QUERY_DDL,TABLE,QUERY,CONNECT&#x27;server_audit_logging=1 重新启动MySQL text1service mysql restart 二、Mysql审计日志分析2.1 server_audit_events变量过滤功能使用mysql -uroot -p登陆数据库，执行如下命令修改变量为如下 text1set global server_audit_events=&#x27;QUERY_DDL&#x27;; 执行如下SQL语句 text12345create database test2;use test2;create table table1 (col1 VARCHAR(20));insert into table1 values (&quot;lili&quot;);select * from table1; text1220191019 20:56:50,delta-mysql,root,localhost,16,1300,QUERY,test,&#x27;create database test2&#x27;,020191019 20:57:29,delta-mysql,root,localhost,16,1306,QUERY,test2,&#x27;create table table1 (col1 VARCHAR(20))&#x27;,0 由上图可见只有create类型的日志被记录下来，insert和select类型的操作日志并没有被记录下来，并且操作类型字段显示为QUERY类型 使用mysql -uroot -p登陆数据库，执行如下命令修改变量为如下 text1set global server_audit_events=&#x27;QUERY_DDL,QUERY_DML&#x27;; text12345create database test3;use test3;create table table2 (col1 VARCHAR(20));insert into table2 values (&quot;lili&quot;);select * from table2; 前两行是上面的日志，后面的是新产生的日志 text12345678910111220191019 20:56:50,delta-mysql,root,localhost,16,1300,QUERY,test,&#x27;create database test2&#x27;,020191019 20:57:29,delta-mysql,root,localhost,16,1306,QUERY,test2,&#x27;create table table1 (col1 VARCHAR(20))&#x27;,020191019 21:45:18,delta-mysql,root,localhost,16,1312,QUERY,test2,&#x27;create table table2 (col1 VARCHAR(20))&#x27;,020191019 21:45:33,delta-mysql,root,localhost,16,1313,QUERY,test2,&#x27;insert into table2 values (&quot;lili&quot;)&#x27;,020191019 21:45:56,delta-mysql,root,localhost,16,1314,QUERY,test2,&#x27;select * from table2&#x27;,020191019 21:47:52,delta-mysql,root,localhost,16,1316,QUERY,test2,&#x27;create databse test3&#x27;,106420191019 21:47:58,delta-mysql,root,localhost,16,1317,QUERY,test2,&#x27;create database test3&#x27;,020191019 21:48:08,delta-mysql,root,localhost,16,1318,QUERY,test2,&#x27;SELECT DATABASE()&#x27;,020191019 21:48:15,delta-mysql,root,localhost,16,1320,QUERY,test2,&#x27;SELECT DATABASE()&#x27;,020191019 21:48:31,delta-mysql,root,localhost,16,1324,QUERY,test3,&#x27;create table table2 (col1 VARCHAR(20))&#x27;,020191019 21:48:31,delta-mysql,root,localhost,16,1325,QUERY,test3,&#x27;insert into table2 values (&quot;lili&quot;)&#x27;,020191019 21:48:31,delta-mysql,root,localhost,16,1326,QUERY,test3,&#x27;select * from table2&#x27;,0 由上可见，create，select和insert类型的日志均被记录下来，并且操作类型字段均为QUERY类型，并不是QUERY_DDL和QUERY_DML类型 根据官方文档显示，QUERY_DDL操作类型指的是进行CREATE等操作时才产生QUERY_DDL操作类型的日志，QUERY_DML操作类型是进行SELECT等操作时才产生QUERY_DML操作类型的日志。 综上所述，server_audit_events确实对操作日志起到了过滤作用，但是实际日志中操作类型字段只有QUERY。说明QUERY_DDL确实起到了日志类型过滤作用，实际操作类型字段仍为QUERY。 2.2TABLE Event分析按照官方文档显示，执行查询操作时会显示操作类型为READ的TABLE事件日志 text12345620170817 16:04:33,ip-172-30-0-38,root,localhost,29,913,READ,company,employees,20170817 16:04:33,ip-172-30-0-38,root,localhost,29,913,READ,company,employees_salaries,20170817 16:04:33,ip-172-30-0-38,root,localhost,29,913,READ,company,ref_job_titles,20170817 16:04:33,ip-172-30-0-38,root,localhost,29,913,READ,company,org_departments,20170817 16:04:33,ip-172-30-0-38,root,localhost,29,913,QUERY,company,&#x27;SELECT * FROM employee_pay WHERE title LIKE \\&#x27;%Executive%\\&#x27; OR title LIKE \\&#x27;%Manager%\\&#x27;&#x27;,0 下面是在MySQL中执行查询操作产生的audit日志，由最后一条可以看出，并没有READ类型的操作日志。 text1220191020 10:48:09,delta-mysql,root,localhost,3,31,QUERY,wordpress,&#x27;SELECT * FROM wp_options WHERE option_name LIKE \\&#x27;%Executive%\\&#x27; OR title LIKE \\&#x27;%Manager%\\&#x27;&#x27;,105420191020 10:48:19,delta-mysql,root,localhost,3,32,QUERY,wordpress,&#x27;SELECT * FROM wp_options WHERE option_name LIKE \\&#x27;%Executive%\\&#x27; OR option_name LIKE \\&#x27;%Manager%\\&#x27;&#x27;,0 通过查询资料，TABLE事件只支持MariaDB 5.5.31 以及更新的版本，MySQL Server不提供MariaDB Audit Plugin需要的信息来追踪TABLE事件。 三、参考资料MariaDB Audit Plugin 官方文档MYSQL-MARIADB AUDIT PLUGIN INSTALLATION AND CONFIGURATION","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.delta1037.cn/tags/MySQL/"},{"name":"软件","slug":"软件","permalink":"https://www.delta1037.cn/tags/%E8%BD%AF%E4%BB%B6/"}]},{"title":"CentOS 6安装GitLab服务端","date":"2019-10-17T16:00:00.000Z","path":"2019/Deploy/CentOS6安装GitLab服务端/","text":"CentOS 6安装GitLab服务端 一、配置基础环境text1234yum install openssh-serveryum install postfixservice postfix startchkconfig postfix on 二、下载安装gitlabgitlab安装包下载地址：centos 6系统的下载地址:https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el6centos 7系统的下载地址:https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7安装： text1rpm -i gitlab-ce-9.5.9-ce.0.el6.x86_64.rpm 三、配置gitlab修改gitlab配置文件指定服务器ip和自定义端口，将external_url后面的值修改为http://ip:port（例如http://192.168.7.89:8010，如果不指定端口则是默认的端口80） text1vim /etc/gitlab/gitlab.rb 如果服务端开启了防火墙，则需要开放相应的端口 text1iptables -I INPUT -p tcp --dport 8010 -j ACCEPT 按照新的配置文件重新配置gitlab，并重新启动 text12gitlab-ctl reconfiguregitlab-ctl restart 查看gitlab运行状态 text1234567891011121314151617gitlab-ctl status# 得到如下输出run: gitaly: (pid 10798) 24009s; run: log: (pid 4490) 24327srun: gitlab-monitor: (pid 10820) 24009s; run: log: (pid 5099) 24297srun: gitlab-workhorse: (pid 10824) 24008s; run: log: (pid 4654) 24321srun: logrotate: (pid 24622) 2407s; run: log: (pid 4894) 24309srun: nginx: (pid 10887) 24007s; run: log: (pid 4803) 24315srun: node-exporter: (pid 10896) 24007s; run: log: (pid 5007) 24303srun: postgres-exporter: (pid 10908) 24006s; run: log: (pid 5383) 24279srun: postgresql: (pid 10918) 24006s; run: log: (pid 3780) 24391srun: prometheus: (pid 10926) 24005s; run: log: (pid 5271) 24285srun: redis: (pid 10943) 24005s; run: log: (pid 3615) 24398srun: redis-exporter: (pid 10947) 24005s; run: log: (pid 5181) 24291srun: sidekiq: (pid 10959) 24004s; run: log: (pid 4393) 24333srun: unicorn: (pid 10987) 24003s; run: log: (pid 4292) 24339s bug0:&#96;GLIBC_2.14’ not found如果出现报错&#x2F;lib64&#x2F;libc.so.6: version &#96;GLIBC_2.14’ not found，则需要升级glibc text1234567891011121314# 下载安装包wget http://ftp.gnu.org/gnu/glibc/glibc-2.14.tar.gztar zxvf glibc-2.14.tar.gzcd glibc-2.14mkdir buildcd build# 编译安装../configure --prefix=/opt/glibc-2.14make -j4make install# 设置链接库目录export LD_LIBRARY_PATH=/opt/glibc-2.14/lib","tags":[{"name":"GitLab","slug":"GitLab","permalink":"https://www.delta1037.cn/tags/GitLab/"},{"name":"软件","slug":"软件","permalink":"https://www.delta1037.cn/tags/%E8%BD%AF%E4%BB%B6/"}]},{"title":"Install Oracle Database 9i on CentOS 5 (i386)","date":"2019-10-13T16:00:00.000Z","path":"2019/Deploy/InstallOracleDatabase9ionCentOS5(i386)/","text":"Oracle Database 9i的官方安装环境为RHEL3，RHEL4。由于项目需要，需要同时安装Oracle Database 9i和日志采集工具rsyslog，rsyslog仅支持RHEL&#x2F;CENTOS 5及其以上的版本，最终在CentOS 5 (i386)版本上安装成功。 一、软件下载： Oracle9i Database Release 2 Enterprise&#x2F;Standard Edition for Intel Linux（ship_9204_linux_disk）：迅雷 百度网盘提取码：ve9y 补丁： compat-libcwait-2.1-1.i386.rpm compat-oracle-rhel4-1.0-5.i386.rpm j2re-1_3_1_19-linux-i586.bin 二、开始安装1、关闭SELinuxtext12gedit /etc/selinux/configset SELINUX=disabled 2、 安装JREtext123chmod +x j2re-1_3_1_19-linux-i586.bin./j2re-1_3_1_19-linux-i586.binmv jre1.3.1_19 /usr/local/ 3、安装缺少的依赖text1234567891011121314151617181920# 检查依赖缺失rpm -q compat-db compat-gcc-34 compat-gcc-34-c++ \\ compat-libgcc-296 compat-libstdc++-296 compat-libstdc++-33 \\ gcc gcc-c++ glibc glibc-common glibc-devel glibc-headers libgcc make libXp# 使用yum安装依赖yum install compat-db*yum install compat-gcc*yum install gcc*yum install compat-libgcc*yum install compat-libstdc++*yum install gnome-libs*yum install libaio*yum install openmotif*yum install xorg-x11-deprecated-libs*yum install glibc-devel*# 安装补丁rpm -Uvh compat-libcwait-2.1-1.i386.rpmrpm -Uvh compat-oracle-rhel4-1.0-5.i386.rpm --nodeps 4、配置环境text123456cd /usr/libln -s libstdc++-3-libc6.2-2-2.10.0.so libstdc++-libc6.1-1.so.2ln -s libgdbm.so.2.0.0 libdb.so.2cd /usr/binln -s gcc34 gcc32 5、添加oracle组和用户text1234groupadd oinstall #添加oinstall组groupadd dba # 添加dba组useradd -g oinstall -G dba oracle #新建用户并添加到组passwd oracle #按照输出设置密码 6、建立安装目录text123456cd /optmkdir oracle # 创建oracle目录chown –R oracle.oinstall oracle #修改oracle目录权限cd oraclemkdir 920 # 创建9i安装目录 7、 配置环境变量和系统设置以oracle用户登陆，打开&#x2F;u01&#x2F;oracle&#x2F;.bash_profile，在文件末尾追加如下内容 text1234567891011121314ORACLE_BASE=/opt/oracle; export ORACLE_BASEORACLE_HOME=$ORACLE_BASE/920; export ORACLE_HOMEORACLE_SID=orcl; export ORACLE_SIDLD_LIBRARY_PATH=$ORACLE_HOME/lib; export LD_LIBRARY_PATHORACLE_OEM_JAVARUNTIME=/usr/local/jre1.3.1_19; export ORACLE_OEM_JAVARUNTIMEPATH=$PATH:$ORACLE_HOME/bin; export PATHif [ $USER = &quot;oracle&quot; ]; then if [ $SHELL = &quot;/bin/ksh&quot; ]; then ulimit -p 16384 ulimit -n 65536 else ulimit -u 16384 -n 65536 fifi 以root用户登陆，打开&#x2F;etc&#x2F;sysctl.conf，在文件末尾追加如下内容，并执行sysctl -p生效 text12345678kernel.shmmni = 4096kernel.sem = 250 32000 100 128fs.file-max = 65536net.ipv4.ip_local_port_range = 1024 65000net.core.rmem_default=262144net.core.wmem_default=262144net.core.rmem_max=262144net.core.wmem_max=262144 打开&#x2F;etc&#x2F;security&#x2F;limits.conf，在文件末尾追加如下内容 text1234oracle soft nofile 65536oracle hard nofile 65536oracle soft nproc 16384oracle hard nproc 16384 8、文件准备a）从网上下载oracle Database 9i有三个文件 text123ship_9204_linux_disk1.cpio.gzship_9204_linux_disk2.cpio.gzship_9204_linux_disk3.cpio.gz b）对压缩文件解压 text123gunzip ship_9204_linux_disk1.cpio.gzgunzip ship_9204_linux_disk2.cpio.gzgunzip ship_9204_linux_disk3.cpio.gz c）使用如下命令解压得到Disk1、Disk2和Disk3文件夹 text123cpio -idmv &lt; ship_9204_linux_disk1.cpiocpio -idmv &lt; ship_9204_linux_disk2.cpiocpio -idmv &lt; ship_9204_linux_disk3.cpio 9、 开始安装进入Disk1目录，执行.&#x2F; runInstaller开始图形界面的安装程序，选择自己喜欢的版本进行安装，一路next就可以 备注：1、终端界面可能出现Inside isCluster, bCluster bfr return is : false，不影响后续使用2、在最后的configuration阶段会发生错误如下 此时退出安装程序，进行如下操作 text1234567cd $ORACLE_HOMErm JREln -s $ORACLE_BASE/jre/1.3.1 JREcd JRE/binln -s java jrecd i386/native_threads/ln -s java jre 然后再执行.&#x2F; runInstaller走一遍安装流程即可 三、使用1、建立数据库进入&#x2F;u01&#x2F;oracle&#x2F;product&#x2F;bin目录，运行dbca命令，进入建立数据库的图形界面，根据界面提示进行操作 2、使用过程中可能会遇到的问题a）startup 出现LRM-00109: could not open parameter file …： text12cd /opt/oracle /admin/sxf/pfile #sxf是dbca新建的数据库名cp init.ora.* /opt/oracle/920/dbs/initmyoracle.ora b）startup出现ORA-01990: error opening password file ‘&#x2F;opt&#x2F;oracle&#x2F;920&#x2F;dbs&#x2F;orapw’ text12cd /opt/oracle/920/binorapwd file=/opt/oracle/920/dbs/orapw passwd=sxf123 entries=1024 四、个人经验1、以CentOS 5（x86_64）无法完成amd64_db_9204_Disk1.cpio.gz的安装2、以CentOS 4（x86_64）可以完成amd64_db_9204_Disk1.cpio.gz的安装 五、参考文献1、Installing Oracle 9i on RHEL5. (x86)","tags":[{"name":"软件","slug":"软件","permalink":"https://www.delta1037.cn/tags/%E8%BD%AF%E4%BB%B6/"},{"name":"部署","slug":"部署","permalink":"https://www.delta1037.cn/tags/%E9%83%A8%E7%BD%B2/"}]},{"title":"Linux启动过程分析","date":"2019-10-13T16:00:00.000Z","path":"2019/Linux/Linux启动过程分析/","text":"Linux启动过程分析 第一阶段-BIOS计算机通电后，首先会区读取ROM芯片中的开机程序（基本输入输出系统&#x2F;BIOS） 1.1 硬件自检BIOS程序首先检查计算机硬件是否满足运行的基本条件–硬件自检（POST） CMOS：存储硬件的各项参数。 1.2 启动顺序硬件自检完成后，BIOS把控制权交给下一阶段的启动程序。 这时，BIOS需要知道下一阶段的启动程序在哪个设备，也就是BIOS需要有一个外部存储设备排序，排在前边的设备就是优先转交控制权的设备。这个排序叫启动顺序。 第二阶段-主引导记录BIOS把控制权交给排在第一位的存储设备。 计算机读取此设备的第一个扇区（最前边的512个字节，叫做主引导记录&lt;Master boot record，缩写为**MBR**&gt;），如果这个扇区最后两个字节是0x55和0xAA，表明设备可以启动；如果不是，表明设备不能启动，控制权交给启动顺序中的下一个 设备。 2.1 主引导记录结构 范围&#x2F;字节 作用 1-446 调用操作系统的机器码 447-510 分区表：将磁盘分为若干个区 511-512 主引导记录签名 2.2 分区表考虑到每个区可以安装不同的操作系统，主引导记录必须知道将控制权交给哪个区。 分区表长度有64个字节，里面分为四项（所以一个硬盘最多有四个一级分区，又叫主分区），每一项16个字节 主分区16个字节组成： 范围&#x2F;字节 作用 1-1 如果为0x80，就表示该分区是激活分区，控制权要交给这个分区。四个分区里面只能有一个是激活的 2-4 主分区第一个扇区的物理位置（柱面、磁头、扇区号） 5-5 主分区类型 6-8 主分区最后一个扇区的物理位置 9-12 该主分区第一个扇区的逻辑地址 13-16 主分区的扇区总数 第三阶段-硬盘启动这时，计算机的控制权就交给了硬盘的某个分区了 3.1 情况A：卷引导记录计算机会读取激活分区的第一个扇区，叫做卷引导记录（Volume boot record，VBR） 卷引导记录告诉计算机，操作系统在这个分区的位置。然后计算机就会加载操作系统了。 3.2 情况B：扩展分区和逻辑分区随着硬盘越来越大，四个分区已经不够了，需要更多分区。于是规定有一个分区可以定义为扩展分区（里面又分了好多个区，叫逻辑分区）。 计算机首先读取扩展分区的第一个扇区，叫扩展引导记录（EBR）。它里面包含一张64字节的分区表，但是最多只有两项（也就是两个逻辑分区，包括它自身的分区表和下一个分区的分区表）。从里面找到第二个逻辑分区的位置，直到找到一个分区里面只包含它自己的分区表为止。 3.3 情况C：启动管理器在这种情况下，计算机读取主引导记录前446个字节的机器码之后，不把控制权交给某一个分区，而是运行启动管理器（boot loader），由用户选择启动哪一个操作系统。 Linux环境中，最流行的启动管理器是Grub。 第四阶段-操作系统控制权交给操作系统之后，操作系统的内核首先载入内存。 所有进程的祖先叫进程0，idle进程，或者由于历史的原因叫做swapper进程。 start_kernel()函数初始化内核需要的所有数据结构，激活终端，创建另一个叫做进程1的内核线程（一般叫做init进程），创建init进程之后，进程0执行cpu_idle()函数，该函数本质上是在开中断的情况下重复之星hlt汇编指令。当 没有其他进程处于TASK_RUNNING才选择执行进程0。 多处理器系统中每个CPU都有一个进程0，计算机启动之后首先启动一个CPU，禁用其他CPU，swapper进程进程初始化内核数据结构，通过copy_process()函数创建另外的swapper进程。 进程0创建的内核线程执行init()函数，init()依次完成内核初始化。init()调用execve()系统调用装入可执行程序init，结果init内核线程变成了一个普通进程。 以Linux系统为例，首先载入&#x2F;boot目录下面的kernel。内核加载成功后（如上），第一个运行的程序是&#x2F;sbin&#x2F;init，它根据配置文件产生init进程，pid进程编号为1，其它进程都是它的后代。 然后init进程加载系统的各个模块，比如窗口和网络程序，直到&#x2F;bin&#x2F;login程序，跳出登录页面。 参考 计算机是如何启动的 深入理解Linux内核","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.delta1037.cn/tags/Linux/"},{"name":"Kernel","slug":"Kernel","permalink":"https://www.delta1037.cn/tags/Kernel/"},{"name":"小系统","slug":"小系统","permalink":"https://www.delta1037.cn/tags/%E5%B0%8F%E7%B3%BB%E7%BB%9F/"}]},{"title":"点石成金，挥刀琢玉——“双创老太”刘玉那些事儿","date":"2019-08-20T16:00:00.000Z","path":"2019/DianGroup/点石成金，挥刀琢玉——“双创老太-刘玉那些事儿/","text":"点石成金，挥刀琢玉——“双创老太”刘玉那些事儿 高调、爱折腾、不走寻常路、犀利、“毒舌”、超级大忙人，她是被贴满标签的华中大教授——刘玉老师。而其中最响亮，最广为人知的标签，一定非“双创老太”莫属。今天，让我们走近这神秘的刘玉教授，说一说，她的那些事儿—— 她是谁—— 湖北省创业红娘众创空间 负责人 武汉创业红娘公益服务中心 理事长 华中科技大学 电信学院 教 授 华中科技大学 Dian团队 创始人 她都做过什么—— 扶弟子创新 曾指导本科生获全国挑战杯特等奖，Dian团队育人模式获国家教学成果二等奖，教育部大学生创新性实验计划的“源头”之一，央视小崔说事栏目曾以“点亮未来”专题报道，曾应邀到全国高校、中学、企事业等逾百家单位作创新创业报告，引起强烈反响。曾获评“全国师德先进个人”和湖北省“五一劳动奖章”、湖北省教育系统“三育人”奖、 宝钢优秀教师特等奖的提名奖、两次获华中科技大学教学质量优秀一等奖。 在她严格要求和精心培养下，Dian团队出站队员500多人在社会上总体表现优异，近7年涌现出50余家创业公司，其中贝贝网和贝店已成为独角兽，释码大华、ping++、悦然心动等创业公司业绩斐然，4人荣登福布斯中国30位“30岁以下创业者”榜单。 帮他人创业 2015年3月，刘玉创办“武汉市洪山区创业红娘公益服务中心”，义务为优秀创业项目与投资机构牵线搭桥，创业项目的甄选范围从华中科技大学在校生拓宽至全社会，不分地域、不分年龄、不分学校、不分学历。至今，经刘玉老师推荐的创业项目已超过500个，融资成交率13.2%，促成投资总额2.57亿元。 她的那些事儿—— 刘玉:创客点睛手——《长江日报》 创新潜能在实践中尽情释放——《中国教育报》网络版 人民网专访“创业红娘”刘玉：如何做到人靠谱、事落实、有情怀 刘玉：被“强推转身”的创业红娘——《中国青年报》 全国布撒“姻缘线”的“创业红娘” ——武汉首个创业服务公益机构实录——《长江日报》 武汉女教授入选“中国好人” 免费孵出50多家公司——荆楚网 华科Dian团队15年走出10余家“过亿”企业——人民网 崔永元“说事”设“圈套” 女教授均“化险为夷”——中国政协新闻网 “点”下种子——访谈华中科技大学“点团队”创始人刘玉教授——《大学生》 华科创客点睛手刘玉讲述：张小龙在武汉首提微信产品观——荆楚网 刘延东寄语Dian团队———在实践中释放创新潜能 华中科大教授刘玉：人才标准固化扼杀大学生创新热情——《中国青年报》 华中科技大学刘玉教授：未来工程师“点”亮江城","tags":[{"name":"Dian","slug":"Dian","permalink":"https://www.delta1037.cn/tags/Dian/"}]},{"title":"编译总结","date":"2019-08-02T16:00:00.000Z","path":"2019/C_C++/编译总结/","text":"C&#x2F;C++编译流程梳理 一、系统环境 CPU：Intel(R) Core(TM) i5-5200U CPU @ 2.20GHz 操作系统：Ubuntu 18.04.2 LTS 内核版本：Linux version 4.18.0-25-generic GNU GCC版本：gcc version 7.4.0 (Ubuntu 7.4.0-1ubuntu1~18.04.1) C standard revision：C11 GNU Compiled BY GMP version： 6.1.2 MPFR version ：4.0.1 MPC version ： 1.1.0 isl version ： isl-0.19-GMP GNU 汇编器版本：2.30 (x86_64-linux-gnu) using BFD version (GNU Binutils for Ubuntu) 2.30 链接器版本： collect2 version：7.4.0 gcc一般是collect2,而不是ld，collect2 是ld链接器的一个封装，最终还是调用ld来完成链接工作 collect2通过第一次链接程序查看链接器输出文件来查找具有特定名称表明是构造函数的符号，如果找得到则会创建一个新的临时‘.c’文件包含这些符号，然后编译这个文件并第二次链接程序.The program collect2 works by linking the program once and looking through the linker output file for symbols with particular names indicating they are constructor functions. If it finds any, it creates a new temporary ‘.c’ file containing a table of them, compiles it, and links the program a second time including that file.） GNU ld (GNU Binutils for Ubuntu)：2.30 二、GCC编译过程2.1 GCC编译过程 预处理 删除所有的#define，展开所有的宏定义 处理所有的条件预编译指令&lt;#if,#endif,#ifdef,#ifndef,#elif,#else&gt; 处理#include预编译指令，将包含的文件插入到include的位置（递归进行） 删除所有的注释 添加行号和文件名标识（调试时使用） 保留所有的#pragma编译器指令（编译器需要使用这些指令） text1234567# 单独产生预处理后的文件（本模块假设hello.c是源代码程序,hello.i是hello.c预处理后的文件,hello.s是hello.c编译后的文件，hello.o是hello.c汇编后的文件，hello是hello.c最终的可执行程序）# 使用gcc命令产生预处理文件$ gcc -E hello.c -o hello.i# 使用cpp命令产生预处理文件$ cpp hello.c &gt; hello.i 编译：将预处理完的文件进行一系列的词法分析、语法分析、语义分析、中间代码生成、目标代码生成与优化之后产生相应的汇编代码文件 词法分析：扫描器运行类似于有限状态机的算法将代码的字符序列分割成一系列的记号 语法分析：语法分析器对扫描器产生的记号进行语法分析，从而产生语法树（以表达式为节点的树） 语义分析：语义分析器确定语句的意义（比如两个指针做乘法是没有意义的），编译器只能分析静态语义（在编译时能够确定的语义，通常包括声明和类型的匹配，类型的转换；与之相对的动态语义是在运行时才能确定的语义，例如将0作为除数是一个运行期语义错误） text12345678# 编译预处理后的文件产生汇编代码文件$ gcc -S hello.i -o hello.s# 编译源文件产生汇编代码文件$ gcc -S hello.c -o hello.s# 现在的gcc编译器将预处理和编译两个步骤合成了一个步骤，使用一个叫cc1的程序来完成这个过程$ /usr/lib/gcc/x86_64-linux-gnu/7/cc1 hello.c -o hello.s 汇编：将汇编代码转变成机器可以执行的指令（根据汇编指令和机器指令的对照表一一翻译） text12345678# 使用as处理汇编文件产生目标文件$ as hello.s -o hello.o# 使用gcc处理汇编文件产生目标文件$ gcc -c hello.s -o hello.o# 使用gcc处理源文件产生目标文件$ gcc -c hello.c -o hello.o 链接：将目标文件链接到一起形成可执行文件,主要包括地址和空间分配，符号决议，和重定位等步骤 符号决议：也叫做符号绑定、名称绑定、名称决议等等。从细节上来讲，决议更倾向于静态链接，绑定更倾向与动态链接 重定位：编译一个文件时不知道一个要调用的函数或者需要操作的一个变量的地址，就会把这些调用函数或者操作变量的指令目标地址搁置，等到最后链接的时候由链接器去将这些指令的目标地址修正，这个地址修正的过程也被叫做重定位，每一个需要修正的地方叫做重定位入口。 2.2 实际编译过程 使用如下样例，包含hello.c和func.c两个源文件（之后也是用这两个文件进行分析） text123456789101112131415161718192021222324252627282930313233343536373839/* hello.c：主测试程序，包括全局静态变量，局部静态变量，全局变量，局部变量，基本的函数调用 */// export varextern int export_func_var;// global varint global_uninit_var;int global_init_var_0 = 0;int global_init_var_1 = 1;// const varconst char *const_string_var = &quot;const string&quot;;// static global varstatic int static_global_uninit_var;static int static_global_init_var_0 = 0;static int static_global_init_var_1 = 1;// func headervoid func_call_test(int num);int main(void)&#123; // local var int local_uninit_var; int local_init_var_0 = 0; int local_init_var_1 = 1; // static local var static int static_local_uninit_var; static int static_local_init_var_0 = 0; static int static_local_init_var_1 = 1; // call func func_call_test(8); // export var op export_func_var = export_func_var * 2; return 0;&#125; text123456/* func.c：包含一个简单的被调用函数和一个全局变量 */int export_func_var = 666;void func_call_test(int num)&#123; int double_num = num * 2;&#125; 使用gcc -v hello.c func.c编译生成可执行文件a.out，产生如下输出（简化版本） text1234567891011121314[delta@delta: code ]$ gcc -v func.c hello.c# 对func.c的预处理和编译过程/usr/lib/gcc/x86_64-linux-gnu/7/cc1 func.c -o /tmp/ccfC6J5E.s# 对func.c产生的.s文件汇编产生二进制文件as -v --64 -o /tmp/ccF4Bar0.o /tmp/ccfC6J5E.s# 对hello.c的预处理和编译过程/usr/lib/gcc/x86_64-linux-gnu/7/cc1 hello.c -o /tmp/ccfC6J5E.s# 对hello.c产生的.s文件汇编产生二进制文件as -v --64 -o /tmp/cc7UmhQl.o /tmp/ccfC6J5E.s# 链接过程/usr/lib/gcc/x86_64-linux-gnu/7/collect2 -dynamic-linker ld-linux-x86-64.so.2 Scrt1.o crti.o crtbeginS.o /tmp/ccF4Bar0.o /tmp/cc7UmhQl.o crtendS.o crtn.o 三、链接过程解析Q: 目标文件的格式是怎样的？ 多个目标是如何链接到一起的？ 3.1 目标文件3.1.1目标文件类型 Window下的PE（Portable Executable） Linux下的ELF（Executable Linkable Format） 1、PE和ELF格式都是COFF（Common file format）格式的变种2、目标文件与可执行文件的内容和结构类似，所以一般采用相同的格式存储。广义上来可以将目标文件和可执行文件看做是同一种类型的文件，在window下统称它们为PE-COFF文件格式，在Linux下统称它们为ELF文件。3、不止是可执行文件按照可执行文件格式存储，动态链接库（DLL，Dynamic Linking Library）（Window的.dll和Linux的.so）以及静态链接库（Static Linking Library）（Window的.lib和Linux的.a）文件都按照可执行文件的格式存储。（静态链接库稍有不同，它是把很多的目标文件捆绑在一起形成一个文件，再加上一些索引。可以理解为一个包含很多目标文件的文件包） 3.1.2 ELF文件类型 ELF文件类型 说明 实例 可重定位文件（Relocatable File） 包含代码和数据，可以被用来链接成可执行文件或者共享目标文件，静态链接库可以归为这一类 Linux的.o，Window下的.obj 可执行文件（Executable File） 包含可以直接执行的程序，一般没有扩展名 Linux的&#x2F;bin&#x2F;bash文件，Window的.exe 共享目标文件（Shared Object File） 包含代码和数据，链接器可以上映这种文件与其他可重定位文件和共享目标文件进行链接产生新的目标文件；动态链接器可以将几个共享目标文件与可执行文件结合，作为进程映像的一部分来运行 Linux的.so，Window的.dll 核心转储文件（Core Dump File） 进程意外终止时，系统将该进程的地址空间的内容以及终止时的其它信息转储到核心转储文件 Linux下的core dump 3.1.3目标文件结构目标文件中包含编译后的指令代码、数据，还包括了链接时需要的一些信息（符号表，调试信息和字符串等），一般目标文件将这些信息按照不同的属性，以节（Section）的形式存储（有时也称为**段（Segment)**）。如下图所示 3.1.3.1****常见的段 段名 说明 .text&#x2F;.code 代码段，编译后的机器指令 .data 数据段，全局变量和局部静态变量 .bss 未初始化的全局变量和局部静态变量（.bss段只是为未初始化的全局变量和局部静态变量预留位置） .rodata 只读信息段 .rodata1 存放只读数据，字符串常量，全局const变量。与.rodata一样 .comment 编译器版本信息 .debug 调试信息 .dynamic 动态链接信息 .hash 符号哈希表 .line 调试时的行号表，即源代码行号与编译后的指令的对应表 .note 额外的编译器信息。程序的公司名，发布版本号 .strtab String Table，字符串表，用来存储ELF文件中用到的各种字符串 .symtab Symbol Table，符号表 .shstrtab Section String Table，段名表 .plt&#x2F;.got 动态链接的跳转表和全局入口表 .init&#x2F;.fini 程序初始化与终结代码段 3.1.3.2目标文件结构分析 ELF文件头： 使用gcc -c hello.c -o hello.o生成目标文件hello.o，并使用readelf -h hello.o读取目标文件的ELF文件头，可以看出ELF文件头定义了ELF魔数、文件机器字节长度、数据存储方式、版本，运行平台、ABI版本、ELF重定位类型、硬件平台、硬件平台版本、入口地址、程序入口和长度、段表的位置和长度及段的数量等，如下图所示 text1234567891011121314151617181920ELF Header: Magic: 7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00 Class: ELF64 Data: 2&#x27;s complement, little endian Version: 1 (current) OS/ABI: UNIX - System V ABI Version: 0 Type: REL (Relocatable file) Machine: Advanced Micro Devices X86-64 Version: 0x1 Entry point address: 0x0 Start of program headers: 0 (bytes into file) Start of section headers: 1328 (bytes into file) Flags: 0x0 Size of this header: 64 (bytes) Size of program headers: 0 (bytes) Number of program headers: 0 Size of section headers: 64 (bytes) Number of section headers: 15 Section header string table index: 14 ELF文件头结构体定义在&#x2F;usr&#x2F;include&#x2F;elf.h中，目标文件hello.o的文件头中机器字节长度为ELF64，找到64位版本文件头结构体Elf64_Ehdr定义，如下所示 text1234567891011121314151617typedef struct&#123; unsigned char e_ident[EI_NIDENT]; /* Magic number and other info */ Elf64_Half e_type; /* Object file type */ Elf64_Half e_machine; /* Architecture */ Elf64_Word e_version; /* Object file version */ Elf64_Addr e_entry; /* Entry point virtual address */ Elf64_Off e_phoff; /* Program header table file offset */ Elf64_Off e_shoff; /* Section header table file offset */ Elf64_Word e_flags; /* Processor-specific flags */ Elf64_Half e_ehsize; /* ELF header size in bytes */ Elf64_Half e_phentsize; /* Program header table entry size */ Elf64_Half e_phnum; /* Program header table entry count */ Elf64_Half e_shentsize; /* Section header table entry size */ Elf64_Half e_shnum; /* Section header table entry count */ Elf64_Half e_shstrndx; /* Section header string table index */&#125; Elf64_Ehdr; 除结构体中的e_ident对应到readelf输出的从Magic到ABI Version部分，其它都是一一对应关系 e_shstrndx变量表示.shstrtab在段表中的下标 段表 使用gcc -c hello.c -o hello.o生成目标文件hello.o，并使用readelf -S hello.o读取目标文件的段表部分 text1234567891011121314151617181920212223242526272829303132333435363738Section Headers: [Nr] Name Type Address Offset Size EntSize Flags Link Info Align [ 0] NULL 0000000000000000 00000000 0000000000000000 0000000000000000 0 0 0 [ 1] .text PROGBITS 0000000000000000 00000040 0000000000000035 0000000000000000 AX 0 0 1 [ 2] .rela.text RELA 0000000000000000 00000440 0000000000000048 0000000000000018 I 12 1 8 [ 3] .data PROGBITS 0000000000000000 00000078 000000000000000c 0000000000000000 WA 0 0 4 [ 4] .bss NOBITS 0000000000000000 00000084 0000000000000014 0000000000000000 WA 0 0 4 [ 5] .rodata PROGBITS 0000000000000000 00000084 000000000000000d 0000000000000000 A 0 0 1 [ 6] .data.rel.local PROGBITS 0000000000000000 00000098 0000000000000008 0000000000000000 WA 0 0 8 [ 7] .rela.data.rel.lo RELA 0000000000000000 00000488 0000000000000018 0000000000000018 I 12 6 8 [ 8] .comment PROGBITS 0000000000000000 000000a0 000000000000002c 0000000000000001 MS 0 0 1 [ 9] .note.GNU-stack PROGBITS 0000000000000000 000000cc 0000000000000000 0000000000000000 0 0 1 [10] .eh_frame PROGBITS 0000000000000000 000000d0 0000000000000038 0000000000000000 A 0 0 8 [11] .rela.eh_frame RELA 0000000000000000 000004a0 0000000000000018 0000000000000018 I 12 10 8 [12] .symtab SYMTAB 0000000000000000 00000108 0000000000000240 0000000000000018 13 16 8 [13] .strtab STRTAB 0000000000000000 00000348 00000000000000f6 0000000000000000 0 0 1 [14] .shstrtab STRTAB 0000000000000000 000004b8 0000000000000076 0000000000000000 0 0 1Key to Flags: W (write), A (alloc), X (execute), M (merge), S (strings), I (info), L (link order), O (extra OS processing required), G (group), T (TLS), C (compressed), x (unknown), o (OS specific), E (exclude), l (large), p (processor specific) 段表结构体定义在&#x2F;usr&#x2F;include&#x2F;elf.h中，目标文件hello.o的文件头中机器字节长度为ELF64，找到64位版本段表结构体定义Elf64_Shdr（每个Elf64_Shdr对应一个段，Elf64_Shdr又称为**段描述符**），如下所示 text12345678910111213typedef struct&#123; Elf64_Word sh_name; /* Section name (string tbl index) */ Elf64_Word sh_type; /* Section type */ Elf64_Xword sh_flags; /* Section flags */ Elf64_Addr sh_addr; /* Section virtual addr at execution */ Elf64_Off sh_offset; /* Section file offset */ Elf64_Xword sh_size; /* Section size in bytes */ Elf64_Word sh_link; /* Link to another section */ Elf64_Word sh_info; /* Additional section information */ Elf64_Xword sh_addralign; /* Section alignment */ Elf64_Xword sh_entsize; /* Entry size if section holds table */&#125; Elf64_Shdr; Elf64_Shdr部分成员解释 变量名 说明 sh_name 段名是一个字符串，位于一个叫.shstrtab的字符串表中，sh_name是段名字符串在.shstrtab中的偏移 sh_addr 段虚拟地址，如果该段可以加载，sh_addr为该段被加载后在进程地址空间的虚拟地址，否则为0 sh_offset 段偏移，如果该段存在于文件中则表示该段在文件中的偏移，否则无意义 sh_link、sh_info 段链接信息，如果该段的类型是与链接相关的，则该字段有意义 sh_addralign 段地址对齐，sh_addralign表示是地址对齐数量的指数，如果sh_addralign为0或者1则该段没有字节对齐要求 sh_entsize 对于一些段包含了一些固定大小的项，比如符号表，则sh_entsize表示每个项的大小 3. 重定位表：hello.o中包含一个.rela.text的段，类型为RELA，它是一个重定位表。链接器在处理目标文件时必须对文件中的某些部位进行重定位，这些重定位信息都记录在重定位表中。对于每个需要重定位的代码段或者数据段，都会有一个相应的重定位表。 4. 字符串表 - .strtab：字符串表，保存普通的字符串，比如符号的名字 - .shstrtab：段表字符串表，保存段表中用到的字符串，比如段名 结论：ELF文件头中的**e_shstrndx变量表示.shstrtab在段表中的下标，e_shoff**表示段表在文件中的偏移，只有解析ELF文件头，就可以得到段表和段表字符串表的位置，从而解析整个ELF文件 3.1.4 链接的接口——符号3.1.4.1 符号定义 定义：在链接中，目标文件之间相互拼合实际上是目标文件之间对地址的引用，即对函数和变量地址的引用。在链接中，将函数和变量统称为符号（Symbol），函数名或变量名称为符号名（Symbol Name）。 每个目标文件都有一个符号表记录了目标文件中用到的所有符号（每个定义的符号都有一个符号值，对于函数和变量来说，符号值就是它们的地址），常见分类如下 符号类型 说明 定义在本目标文件中的全局符号 可以被其它目标文件引用的符号 在本目标文件中引用的符号，却没有定义在本目标文件中 外部符号（External Symbol） 段名，由编译器产生 它的值就是该段的起始地址 局部符号 只在编译单元内部可见，链接器往往忽略它们 行号信息 目标文件指令与代码行的对应关系，可选 3.1.4.2 符号结构分析 符号表结构：符号表结构体定义在&#x2F;usr&#x2F;include&#x2F;elf.h中，如下所示 text123456789typedef struct&#123; Elf64_Word st_name; /* Symbol name (string tbl index) */ unsigned char st_info; /* Symbol type and binding */ unsigned char st_other; /* Symbol visibility */ Elf64_Section st_shndx; /* Section index */ Elf64_Addr st_value; /* Symbol value */ Elf64_Xword st_size; /* Symbol size */&#125; Elf64_Sym; Elf64_Sym成员解释 变量名 说明 st_name 符号名在字符串表中的下标 st_info 符号类型和绑定信息 st_other 符号可见性 st_shndx 符号所在的段 st_value 符号对应的值 st_size 符号大小 使用gcc -c hello.c -o hello.o生成目标文件hello.o，并使用readelf -s hello.o读取目标文件的符号表部分 text1234567891011121314151617181920212223242526Symbol table &#x27;.symtab&#x27; contains 24 entries: Num: Value Size Type Bind Vis Ndx Name 0: 0000000000000000 0 NOTYPE LOCAL DEFAULT UND 1: 0000000000000000 0 FILE LOCAL DEFAULT ABS hello.c 2: 0000000000000000 0 SECTION LOCAL DEFAULT 1 3: 0000000000000000 0 SECTION LOCAL DEFAULT 3 4: 0000000000000000 0 SECTION LOCAL DEFAULT 4 5: 0000000000000000 0 SECTION LOCAL DEFAULT 5 6: 0000000000000000 0 SECTION LOCAL DEFAULT 6 7: 0000000000000004 4 OBJECT LOCAL DEFAULT 4 static_global_uninit_var 8: 0000000000000008 4 OBJECT LOCAL DEFAULT 4 static_global_init_var_0 9: 0000000000000004 4 OBJECT LOCAL DEFAULT 3 static_global_init_var_1 10: 0000000000000008 4 OBJECT LOCAL DEFAULT 3 static_local_init_var_1.1 11: 000000000000000c 4 OBJECT LOCAL DEFAULT 4 static_local_init_var_0.1 12: 0000000000000010 4 OBJECT LOCAL DEFAULT 4 static_local_uninit_var.1 13: 0000000000000000 0 SECTION LOCAL DEFAULT 9 14: 0000000000000000 0 SECTION LOCAL DEFAULT 10 15: 0000000000000000 0 SECTION LOCAL DEFAULT 8 16: 0000000000000004 4 OBJECT GLOBAL DEFAULT COM global_uninit_var 17: 0000000000000000 4 OBJECT GLOBAL DEFAULT 4 global_init_var_0 18: 0000000000000000 4 OBJECT GLOBAL DEFAULT 3 global_init_var_1 19: 0000000000000000 8 OBJECT GLOBAL DEFAULT 6 const_string_var 20: 0000000000000000 53 FUNC GLOBAL DEFAULT 1 main 21: 0000000000000000 0 NOTYPE GLOBAL DEFAULT UND _GLOBAL_OFFSET_TABLE_ 22: 0000000000000000 0 NOTYPE GLOBAL DEFAULT UND func_call_test 23: 0000000000000000 0 NOTYPE GLOBAL DEFAULT UND export_func_var text1234567注： 1. static_global_uninit_var、static_local_init_var_0和static_local_uninit_var、static_global_init_var_0和global_init_var_0在bss段（因为初始化为0和不初始化是一样的） 2. static_global_init_var_1、static_local_init_var_1和global_init_var_1在data段（初始化的全局变量） 3. static变量的类型均为LOCAL，表明该符号只为该目标文件内部可见；非Static全局变量的类型为GLOBAL，表明该符号外部可见 4. 在hello.c中引用了func_call_test和export_func_var符号，但是没有定义，所以它的Ndx是UND（注：export一个变量但是并未使用则符号表中不会出现这个边浪符号信息；export一个不存在的变量但是并未使用编译不会报错；export一个不存在的变量并使用会报错 &lt;**注意系统环境**&gt; ） 5. 未初始化的全局非静态变量global_uninit_var在COM块中 6. const_string_var在.data.rel.local段中 特殊符号：当使用链接器生成可执行文件时，会定义很多特殊的符号，这些符号并未在程序中定义，但是可以直接声明并引用它们 3.1.4.3 符号修饰与函数签名符号修饰与函数签名：在符号名前或者后面加上_修饰符号，防止与库文件和其它目标文件冲突。现在的linux下的GCC编译器中，默认情况下去掉了加上_这种方式，可以通过参数选项打开 C++符号修饰：C++拥有类，继承，重载和命名空间等这些特性，导致符号管理更为复杂。例如重载的情况：函数名相同但是参数不一样。然后就有了符号修饰和符号改编的机制，使用函数签名（包括函数名，参数类型，所在的类和命名空间等信息）来识别不同的函数 C++符号修饰栗子 text1234567891011121314151617181920212223242526272829303132333435363738394041424344454647class C &#123; public: int func(int); class C2 &#123; public: int func(int); &#125;;&#125;;namespace N &#123; int func(int); class C &#123; public: int func(int); &#125;;&#125;int func(int num)&#123; return num;&#125;float func(float num)&#123; return num;&#125;int C::func(int num)&#123; return num;&#125;int C::C2::func(int num)&#123; return num;&#125;int N::func(int num)&#123; return num;&#125;int N::C::func(int num)&#123; return num;&#125;int main()&#123; int int_res = func(1); float float_var = 1.1; float float_res = func(float_var); C class_C; int_res = class_C.func(1); return 0;&#125; 使用g++ -c hello.cpp -o hello_cpp.o编译产生目标文件hello_cpp.o，使用readelf -a hello_cpp.o查看目标文件中的符号表，如下 text1234567891011121314151617181920Symbol table &#x27;.symtab&#x27; contains 18 entries: Num: Value Size Type Bind Vis Ndx Name 0: 0000000000000000 0 NOTYPE LOCAL DEFAULT UND 1: 0000000000000000 0 FILE LOCAL DEFAULT ABS hello.cpp 2: 0000000000000000 0 SECTION LOCAL DEFAULT 1 3: 0000000000000000 0 SECTION LOCAL DEFAULT 3 4: 0000000000000000 0 SECTION LOCAL DEFAULT 4 5: 0000000000000000 0 SECTION LOCAL DEFAULT 5 6: 0000000000000000 0 SECTION LOCAL DEFAULT 7 7: 0000000000000000 0 SECTION LOCAL DEFAULT 8 8: 0000000000000000 0 SECTION LOCAL DEFAULT 6 9: 0000000000000000 12 FUNC GLOBAL DEFAULT 1 _Z4funci 10: 000000000000000c 16 FUNC GLOBAL DEFAULT 1 _Z4funcf 11: 000000000000001c 16 FUNC GLOBAL DEFAULT 1 _ZN1C4funcEi 12: 000000000000002c 16 FUNC GLOBAL DEFAULT 1 _ZN1C2C24funcEi 13: 000000000000003c 12 FUNC GLOBAL DEFAULT 1 _ZN1N4funcEi 14: 0000000000000048 16 FUNC GLOBAL DEFAULT 1 _ZN1N1C4funcEi 15: 0000000000000058 119 FUNC GLOBAL DEFAULT 1 main 16: 0000000000000000 0 NOTYPE GLOBAL DEFAULT UND _GLOBAL_OFFSET_TABLE_ 17: 0000000000000000 0 NOTYPE GLOBAL DEFAULT UND __stack_chk_fail 可以看出函数签名与修饰后的名称的对应关系 函数签名 修饰后名称（符号名） int func(int) _Z4funci float func(float) _Z4funcf int C::func(int) _ZN1C4funcEi int C::C2::func(int) _ZN1C2C24funcEi int N::func(int) _ZN1N4funcEi int N::C::func(int) _ZN1N1C4funcEi extern “C”：C++编译器会将在extern C大括号内的内部代码当做C语言代码处理，也就是名称修饰机制将不会起作用。当需要兼容C和C++，例如在C++代码中调用C中的memset函数，可以使用C++的宏__cplusplus，C++在编译程序时会默认定义这个宏 text123456789#ifdef __cplusplusextern “C” &#123;#endifvoid *memset(void *, int, size_t);#ifdef __cplusplus&#125;#endif 由于不同的编译器采用不同的名字修饰方法，必然会导致不同编译器产生的目标文件无法正常互相链接，这是导致不同编译器之间不能互操作的原因 3.1.4.4 弱符号与强符号在编程中经常遇到符号重定义的问题，例如hello.c和func.c都定义了一个_global并将它们都初始化，在编译时就会报错。对于C&#x2F;C++来说，编译器默认函数和初始化的全局变量为强符号，未初始化的全局变量为弱符号。 编译器处理符号规则 不允许强符号被多次定义 如果一个符号在一个文件中是强符号，在其它文件中是弱符号，则选择强符号 如果一个符号在所有的文件中都是弱符号，则选择其中占用空间最大的一个（int型和double型会选择double型） 弱引用与强引用：对外部目标文件中的符号引用在目标文件最终被链接成可执行文件时都哟啊被正确决议，如果没有找到该符号的定义，则会报未定义错误，这种被称为强引用；与之对应的弱引用，在处理弱引用时，如果该符号有定义，则链接器将该符号的引用决议；如果该符号未被定义，则链接器也不会报错。 弱符号与弱引用的作用（对库来说很有用） 库中定义的弱符号可以被用户定义的强符号所覆盖，从而使程序可以使用自定义版本的函数 程序可以对某些扩展功能模块的引用定义为弱引用，当扩展模块与程序链接到一起时，功能模块可以正常使用；如果去掉了某些功能模块，则程序也可以正常链接，只是缺少了相应的功能，这使得程序的功能更容易裁剪和组合 3.2 静态链接3.2.1 空间和地址分配链接器在合并多个目标文件的段时，采用相似段合并的方式，并分配地址和空间（虚拟地址空间的分配） 两步链接法： 空间和地址分配：扫描所有的目标文件，获得它们的各个段的长度、属性和位置，并且将输入目标文件中的符号表中所有的符号定义和符号引用收集起来，统一放到一个全局符号表，这一步中，链接器将能够获得所有输入目标文件的段长度，并将它们合并，计算输出文件中各个合并之后的段的长度，建立映射关系。 符号解析与重定位：使用空间和地址分配中收集到的所有信息，读取输入文件中段的数据、重定位信息，并且进行符号解析与重定位、调整代码中的地址等。 当进行了空间和地址分配之后，各个段的虚拟地址也就确定了，由于各个符号在段内的位置是相对的，所以各个符号的地址也就确定了。 3.2.2 符号解析与重定位 使用gcc -c hello.c -o hello.o生成目标文件hello.o，并使用objdump -d hello.o读取目标文件的.text的反汇编结果，如下所示（简略部分内容）；同理使用gcc -c func.c -o func.o生成目标文件func.o。 text12345678910111213141516[delta@rabbit: c_code ]$ objdump -d hello.oDisassembly of section .text:0000000000000000 &lt;main&gt;: 0: 55 push %rbp 1: 48 89 e5 mov %rsp,%rbp 4: 48 83 ec 10 sub $0x10,%rsp 8: c7 45 f8 00 00 00 00 movl $0x0,-0x8(%rbp) f: c7 45 fc 01 00 00 00 movl $0x1,-0x4(%rbp) 16: bf 08 00 00 00 mov $0x8,%edi 1b: e8 00 00 00 00 callq 20 &lt;main+0x20&gt; 20: 8b 05 00 00 00 00 mov 0x0(%rip),%eax # 26 &lt;main+0x26&gt; 26: 01 c0 add %eax,%eax 28: 89 05 00 00 00 00 mov %eax,0x0(%rip) # 2e &lt;main+0x2e&gt; 2e: b8 00 00 00 00 mov $0x0,%eax 33: c9 leaveq 34: c3 retq 分析：由以上结果可以看出，在链接之前，main函数在调用func_call_test函数时，使用的地址是0x00000000，根据反汇编结果就是下一条指令（e8 00 00 00 00之中e8是callq的指令码，00 00 00 00是目的地址相对于下一条指令的偏移量）；在使用export_func_var变量时，编译器就将0x0看做是export_func_var的地址 使用ld hello.o func.o -e main链接两个目标文件，生成可执行文件a.out（并不能执行，因为缺少部分目标文件，但是符号已经被重新定位；e main表示将main函数作为程序入口），使用objdump -d a.out查看a.out的.text段反汇编结果，如下图所示（简略部分内容） text123456789101112131415161718192021222324252627[delta@rabbit: c_code ]$ objdump -d a.outDisassembly of section .text:00000000004000e8 &lt;main&gt;: 4000e8: 55 push %rbp 4000e9: 48 89 e5 mov %rsp,%rbp 4000ec: 48 83 ec 10 sub $0x10,%rsp 4000f0: c7 45 f8 00 00 00 00 movl $0x0,-0x8(%rbp) 4000f7: c7 45 fc 01 00 00 00 movl $0x1,-0x4(%rbp) 4000fe: bf 08 00 00 00 mov $0x8,%edi 400103: e8 15 00 00 00 callq 40011d &lt;func_call_test&gt; 400108: 8b 05 0a 0f 20 00 mov 0x200f0a(%rip),%eax # 601018 &lt;export_func_var&gt; 40010e: 01 c0 add %eax,%eax 400110: 89 05 02 0f 20 00 mov %eax,0x200f02(%rip) # 601018 &lt;export_func_var&gt; 400116: b8 00 00 00 00 mov $0x0,%eax 40011b: c9 leaveq 40011c: c3 retq000000000040011d &lt;func_call_test&gt;: 40011d: 55 push %rbp 40011e: 48 89 e5 mov %rsp,%rbp 400121: 89 7d ec mov %edi,-0x14(%rbp) 400124: 8b 45 ec mov -0x14(%rbp),%eax 400127: 01 c0 add %eax,%eax 400129: 89 45 fc mov %eax,-0x4(%rbp) 40012c: 90 nop 40012d: 5d pop %rbp 40012e: c3 retq 使用nm a.out查看a.out中的符号信息（简略），可以看到export_func_var的地址为0000000000601018 text12[delta@rabbit: c_code ]$ nm a.out0000000000601018 D export_func_var 分析：在链接之后，可以从反汇编中看出main函数的调用func_call_test函数的地方地址已经被修正为func_call_test真正的地址000000000040011d，使用export_func_var变量的地方的地址也修正为export_func_var真正的地址0000000000601018（在nm a.out输出的符号表中）。所以链接器在完成地址空间分配之后就可以确定所有符号的虚拟地址了，链接器就可以根据符号的地址对每个需要重定位的地方进行地址修正。 链接器如何知道哪些地址需要修正呢？有一个重定位表的结构专门保存与重定位相关的信息（比如.text如果有需要重定位的地方，那么就会有一个叫.rela.text的段保存了代码段的重定位信息），使用objdump -r hello.o查看重定位信息如下（简略），可以看到所有需要重定位的地方 text123456[delta@rabbit: c_code ]$ objdump -r hello.oRELOCATION RECORDS FOR [.text]:OFFSET TYPE VALUE000000000000001c R_X86_64_PLT32 func_call_test-0x00000000000000040000000000000022 R_X86_64_PC32 export_func_var-0x0000000000000004000000000000002a R_X86_64_PC32 export_func_var-0x0000000000000004 符号解析：使用nm hello.o可以查看hello.o 中所有的符号信息，如下所示，可以看到export_func_var和func_call_test符号都是未定义状态（U）。所以档链接器扫描完所有的输入目标文件之后，所有的这些未定义的符号都能够在全局符号表中找到，否则就会报符号未定义（undefined reference to）错误。 text12345678910111213141516# 输出hello.o 中所有的符号信息[delta@rabbit: c_code ]$ nm hello.o0000000000000000 D const_string_var U export_func_var U func_call_test0000000000000000 B global_init_var_00000000000000000 D global_init_var_1 U _GLOBAL_OFFSET_TABLE_0000000000000004 C global_uninit_var0000000000000000 T main0000000000000008 b static_global_init_var_00000000000000004 d static_global_init_var_10000000000000004 b static_global_uninit_var000000000000000c b static_local_init_var_0.18090000000000000008 d static_local_init_var_1.18100000000000000010 b static_local_uninit_var.1808 text1234567# 符号未定义错误[delta@rabbit: c_code ]$ ld hello.old: warning: cannot find entry symbol _start; defaulting to 00000000004000e8hello.o: In function `main&#x27;:hello.c:(.text+0x1c): undefined reference to `func_call_test&#x27;hello.c:(.text+0x22): undefined reference to `export_func_var&#x27;hello.c:(.text+0x2a): undefined reference to `export_func_var&#x27; 指令修正方式：（A：保存正在修正位置的值；P：被修正的位置&lt;相对于段开始的偏移量或者虚拟地址&gt;；S：符号的实际地址；L：表示其索引位于重定位条目中的符号的值）以下计算参考 text12345678910111213# hello.o中的重定位信息（简略）[delta@rabbit: c_code ]$ objdump -r hello.oRELOCATION RECORDS FOR [.text]:OFFSET TYPE VALUE000000000000001c R_X86_64_PLT32 func_call_test-0x00000000000000040000000000000022 R_X86_64_PC32 export_func_var-0x0000000000000004000000000000002a R_X86_64_PC32 export_func_var-0x0000000000000004# 解析：# 根据输出符号的重定位类型有R_X86_64_PLT32和R_X86_64_PC32# R_X86_64_PLT32 ： L + A - P（绝对地址修正）# R_X86_64_PC32 ： S + A - P（相对寻址修正）# 其它方式参考：http://www.ucw.cz/~hubicka/papers/abi/node19.html 绝对地址修正：绝对地址修正后的地址为该符号的实际地址，例如调用func_call_test符号的地址被修正成为了绝对地址40011d 相对地址修正：相对地址修正后的地址为符号距离被修正位置的地址差，例如使用export_func_var符号的地址被修正成为了相对地址0x200f0a，mov指令（第一个mov指令）的下一条地址40010e加上这个偏移量0x200f0a就是export_func_var的绝对地址0x601018 COMMON块：根据nm hello.o的输出，如下所示（简略），可以看到global_uninit_var符号的类型为COMMON类型，编译器将未初始化的全局变量作为弱符号处理 text12[delta@rabbit: c_code ]$ nm hello.o0000000000000004 C global_uninit_var 多个符号定义类型情况分析 两个或以上强符号类型不一致：报重定义错误 有一个强符号和多个弱符号：取强符号，若是有弱符号比强符号空间大的情况则编译时会出现warning 两个或者以上弱符号类型不一致：取占用空间最大的弱符号 注：当编译器将一个编译单元编译成目标文件时，如果该编译单元包含弱符号（未初始化或者初始化为0的全局变量是典型），那么该符号所占用的最终空间就是不确定的，所以编译器无法在该阶段为该符号在BSS段分配空间。但是经过链接之后，任何一个符号的大小都确定了，所以它可以在最终输出文件的BSS段为其分配空间。总体来看，未初始化的全局变量是放在BSS段的 3.2.3 静态库链接 定义：静态库可以简单地看做是一组目标文件的集合，即很多目标文件经过压缩打包后形成的一个文件（Linux上常用的C语言静态库libc位于&#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libc.a） 静态链接过程：在链接过程中ld链接器会自动寻找所有需要的符号以及它们所在的目标文件，将这些目标文件从libc.a中“解压”出来，最终将它们链接到一起形成一个可执行文件。使用gcc -v hello.c func.c编译生成可执行文件a.out，可以看到详细的链接过程，产生如下输出（简化版本） text123456789101112131415161718192021222324[delta@delta: code ]$ gcc -v func.c hello.c# 对func.c的预处理和编译过程/usr/lib/gcc/x86_64-linux-gnu/7/cc1 func.c -o /tmp/ccfC6J5E.s# 对func.c产生的.s文件汇编产生二进制文件as -v --64 -o /tmp/ccF4Bar0.o /tmp/ccfC6J5E.s# 对hello.c的预处理和编译过程/usr/lib/gcc/x86_64-linux-gnu/7/cc1 hello.c -o /tmp/ccfC6J5E.s# 对hello.c产生的.s文件汇编产生二进制文件as -v --64 -o /tmp/cc7UmhQl.o /tmp/ccfC6J5E.s# 链接过程/usr/lib/gcc/x86_64-linux-gnu/7/collect2 -dynamic-linker ld-linux-x86-64.so.2 Scrt1.o crti.o crtbeginS.o /tmp/ccF4Bar0.o /tmp/cc7UmhQl.o crtendS.o crtn.o############################################# 实际各个目标文件的位置/usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/Scrt1.o/usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crti.o/usr/lib/gcc/x86_64-linux-gnu/7/crtbeginS.o/tmp/ccF4Bar0.o/tmp/cc7UmhQl.o/usr/lib/gcc/x86_64-linux-gnu/7/crtendS.o/usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crtn.o 可以看到Scrt1.o crti.o crtbeginS.o &#x2F;tmp&#x2F;ccF4Bar0.o &#x2F;tmp&#x2F;cc7UmhQl.o crtendS.o crtn.o被链接入了最终可执行文件 各个文件的解释（来源） 目标文件 说明 crt0.o Older style of the initial runtime code ? Usually not generated anymore with Linux toolchains, but often found in bare metal toolchains. Serves same purpose as crt1.o (see below). crt1.o Newer style of the initial runtime code. Contains the _start symbol which sets up the env with argc&#x2F;argv&#x2F;libc _init&#x2F;libc _fini before jumping to the libc main. glibc calls this file ‘start.S’. crti.o Defines the function prolog; _init in the .init section and _fini in the .fini section. glibc calls this ‘initfini.c’. crtn.o Defines the function epilog. glibc calls this ‘initfini.c’. scrt1.o Used in place of crt1.o when generating PIEs. gcrt1.o Used in place of crt1.o when generating code with profiling information. Compile with -pg. Produces output suitable for the gprof util. Mcrt1.o Like gcrt1.o, but is used with the prof utility. glibc installs this as a dummy file as it’s useless on linux systems. crtbegin.o GCC uses this to find the start of the constructors. crtbeginS.o Used in place of crtbegin.o when generating shared objects&#x2F;PIEs. crtbeginT.o Used in place of crtbegin.o when generating static executables. crtend.o GCC uses this to find the start of the destructors. crtendS.o Used in place of crtend.o when generating shared objects&#x2F;PIEs. 通常链接顺序： text1crt1.o crti.o crtbegin.o [-L paths] [user objects] [gcc libs] [C libs] [gcc libs] crtend.o crtn.o 链接过程控制：链接过程需要考虑很多内容：使用哪些目标文件？使用哪些库文件？是否保留调试信息、输出文件格式等等。 链接器控制链接过程方法： 使用命令行来给链接器指定参数 将链接器指令存放在目标文件里面，编译器通常会使用这种方式向链接器传递指令。 使用链接控制脚本 3.2.4 BFD库简介 定义：由于现代的硬件和软件平台种类繁多，每个平台都有不同的目标文件格式，导致编译器和链接器很难处理不同平台的目标文件。BFD库（Binary File Descriptor library）希望通过统一的接口来处理不同的目标文件格式。 现代GCC（具体来讲是GNU 汇编器GAS）、链接器、调试器和GDB及binutils的其他工具都是通过BFD库来处理目标文件，而不是直接操作目标文件。 3.3 装载与动态链接3.3.1可执行文件的装载 进程的虚拟地址空间：每个程序运行起来之后，它将拥有自己独立的虚拟地址空间，这个虚拟地址空间的大小由计算机的硬件平台决定，具体来说是CPU的位数决定（32位平台下的虚拟空间为4G&lt;2^32&gt;，通过cat /proc/cpuinfo可以看到虚拟地址的位数，如本机为address sizes : 39 bits physical, 48 bits virtual，虚拟地址位数为48位，则虚拟空间为2^48）。 进程只能使用操作系统分配给进程的地址，否则系统会捕获到这些访问并将其关闭（Window：进程因非法操作需要关闭；Linux：Segment Fault段错误） 装载的方式：程序运行时是有局部性原理的，所以可以将程序最常用的部分驻留在内存中，将不常用的数据存放在磁盘里（动态装入的基本原理） 覆盖装入（几乎被淘汰）：覆盖装入的方法吧挖掘内存潜力的任务交给了程序员，程序员在编写程序时将程序分为若干块，然后编写一个辅助代码来管理这些这些模块何时应该驻留内存，何时应该被替换掉（在多个模块的情况下，程序员需要手工将它们之间的依赖关系组织成树状结构） 页映射：页映射不是一下子将指令和数据一下子装入内存，而是将内存和磁盘中的所有数据和指令按照页（Page）为单位划分，之后所有的装载和操作的单位就是页。 操作系统角度来看可执行文件的加载： 创建一个独立的虚拟地址空间：创建映射函数所需要的对应的数据结构 读取可执行文件头，建立虚拟空间和可执行文件的映射关系：程序在发生页错误时，操作系统从物理空间分配出来一个物理页，然后将“缺页”从磁盘读取到内存中，并设置缺页的虚拟页与物理页的映射关系，很明显，操作系统捕获到缺页错误时，它应该知道当前所需要的页在可执行文件的哪一个位置。这就是虚拟空间与可执行文件之间的映射关系（这种映射关系只是保存在操作系统内部的一个数据结构，Linux中将进程虚拟空间中的一个段叫做虚拟内存区域（VMA））。 将CPU的指令寄存器设置成可执行文件的入口地址，启动运行 注：页错误处理： CPU将控制权交给操作系统 操作系统查询装载过程 第二部建立起来的数据结构，找到空白页所在的VMA，计算出相应页面在可执行文件中的便宜，然后在物理内存中分配一个物理页面，将进程中该虚拟地页与分配的物理页之间建立映射关系 把控制权还给进程 3.3.2 动态链接 为什么需要动态链接：1、静态链接方式对于计算机内存和磁盘空间的浪费非常严重；2、静态链接库对程序的更新部署会带来很多麻烦（如果其中一个依赖进行了更新，那么该程序就要重新链接发布） 动态链接：将链接的过程推迟到了运行的时候再进行，通过动态链接器（第二部分GCC编译过程中最后的链接设置了动态链接器参数dynamic-linker ld-linux-x86-64.so.2 ）完成链接工作，通过延迟绑定等来将动态链接损失的性能尽可能的小。 动态地选择加载各种程序模块 加强程序的兼容性：一个程序在不同的平台运行时可以动态地链接到由操作系统提供的动态链接库，这些动态链接库相当于在程序和操作系统之间添加了一个中间层，从而消除程序对不同平台之间依赖的差异性 地址无关代码：共享对象在编译时不能假设自己在进程虚拟空间中的位置。把指令中那些需要修改的部分分离出来与数据部分放在一起，这样指令部分就可以保持不变，而数据部分可以在每个进程中有一个副本，这种方案就是地址无关代码（PIC，Position-Independent Code） 装载时重定位：一旦模块装载地址确定，即目标地址确定，那么系统就对程序中所有的绝对地址进行重定位（静态链接时的重定位叫做链接时重定位；动态链接的重定位叫做装载时重定位 ） 模块中国各种类型地址类型引用方式： 模块内部的函数调用、跳转：采用相对地址调用，不需要重定位 模块内部的数据访问，比如模块中定义的全局变量，静态变量：采用相对地址访问，获取当前的PC值，加上偏移量就能访问变量了 模块外部的数据访问，比如其它模块定义的全局变量：ELF的做法是子啊数据段里面建立一个指向这些变量的指针数组，称为全局偏移表（GOT，Global Offset Table）。GOT是放在数据段的，可以在模块装载时被修改，并且每个进程都可以有独立的副本，互相不影响。 模块外部的函数调用、跳转等：通过GOT中的项进行间接跳转 延迟绑定：当函数第一次被用到才进行绑定（符号查找、重定位等），如果没有用到则不绑定。ELF使用PLT（Procedure Linkage Table）的方式来事先延迟绑定（PLT使解析只会在符号未解析时进行一次）。 动态链接的步骤 动态链接器自举：动态链接器不依赖其它任何共享对象；动态链接器本身所需的全局和静态变量的重定位工作由它本身完成 装载共享对象：将可执行文件和链接器本身的符号都合并到一个全局符号表中（图的遍历过程），当一个符号需要加入到全局符号表时，如果相同的符号已经存在，则忽略后加入的符号 重定位与初始化：重新遍历可执行文件和每个共享对象的重定位表，将它们的GOT&#x2F;PLT中的每个需要重定位的地方进行修正。 四、参考文献[0] 程序员的自我修养 ：链接、装载与库 &#x2F; 俞甲子，石凡，潘爱民著.—北京：电子工业出版社 [1] GNU ONLINE DOC - collect2 https://gcc.gnu.org/onlinedocs/gccint/Collect2.html","tags":[{"name":"C/C++","slug":"C-C","permalink":"https://www.delta1037.cn/tags/C-C/"},{"name":"编译","slug":"编译","permalink":"https://www.delta1037.cn/tags/%E7%BC%96%E8%AF%91/"}]},{"title":"基于NS3的无线链路物理层仿真实验","date":"2019-02-10T16:00:00.000Z","path":"2019/School/基于NS3的无线链路物理层仿真实验/","text":"基于NS3的无线链路物理层仿真实验 一、实验目的 掌握NS3的基本仿真方法 熟悉NS3的无线链路模型 改进NS3的无线链路模型 二、实验背景在原有的NS3的无线模型中,很难去控制链路的速率，延迟和错误等属性，例如在原有的模型中，错误率是不随距离变化的，即只要在可以传输的范围之内，错误率都是一样的，但是在实际中，随着距离的增加，错误率应该逐渐上升，而不是保持不变，因此我们在现有的模型中做出了一些改进，引入随着距离增加错误率逐渐增加的错误模型，并且引入丢头队列和丢尾队列来模拟不同队列的场景下传输速率的变化，同时加入定向网络的模型，实现定向传输的功能并且支持固定争用模型，即在冲突范围内，随着用户数量的增加，收包率逐渐下降。 三、实验原理1.错误模型 上图是基于NS3的错误模型节点分布图，如图所示，节点0分布在半径为100的圆的中心，其余100个节点以节点0为中心半径为100的圆内随机分布，同时节点0向周围节点发送数据，传输距离为100. 在NS3原有的错误模型中，节点0向各个节点发送数据的丢包率是一样的，但是实际场景中随着距离的增加，丢包率会逐渐上升，经过研究和调查，我们所构建的丢包率曲线如下图 2.队列模型在NS3的原有队列模型中使用的是丢尾队列，当发送数据包的队列已满时，丢尾队列会丢弃队列的最后的数据包，以控制数据包的发送率，我们引入了丢头队列，即当队列已满时，主动丢弃队列的头部的数据包，因为当队列已满时，表明队列的头部数据包非常的大，导致发送时间过长，使得后面的数据包处于等待过程中。因此丢头队列机制也会使得数据包的发送速率提升。 3.定向网络在NS3现有的模型中,无线网络采用的时广播的方式，中心节点发送数据之后，其余的节点都会收到数据包，我们引入了定向网路的模型，即在显示场景中，通过摆放天线的朝向，可以定向的向部分节点发送数据，两者对比如图： 图三：定向网络和非定向网络对比 在NS3中构造如上图所示的场景，在定向网络中只有定向的节点才会收到数据包，其余节点则不回收到数据包，而在非定向网络中，则是全部节点都会收到数据包，因此在两种场景下统计各个节点收到的数据包的数量就可以对比两者的特性。 4.固定争用实际场景中，在可传输的范围内，随着用户数量的增多，用户之间发生冲突的几率会逐渐增加，网络的性能将会逐渐下降，吞吐量逐渐下降，丢包率逐渐上升。 如图所示，仍然采用错误模型中的节点分布，中心节点向周围节点发送数据，同时不断扩大冲突范围，随着冲突范围的不断扩大，覆盖的用户数量就会不断的增加，吞吐量应该会逐渐下降，因此统计各个节点的丢包率应该会观察到随着冲突范围的增加，丢包率在逐渐上升。 四、实验过程1.错误模型测试 采用如图五中的节点分布，一共有101个节点，节点0在中心，另外一百个节点随机分布在半径为100的圆内，令中心节点向周围节点发送数据，统计各个节点收到的数据包。 采用所构造的错误模型曲线，统计丢包率，测试结果如图六所示，测试结果显示随着距离的增加，丢包率在逐渐的上升，因此符合预期要求。 另一方面，减少节点数量为21个，统计统计节点的收包特性图，如图七所示，图中绿色的部分表明节点正在收到数据包，其余表示因发生错误导致节点处于空闲状态，结果表明由于节点所处的距离不同，任何两个节点的收包特性是不一样的，因此也从另一方面验证了所构造的模型的合理性和正确性。 2.数据包队列测试 采用两种类型的队列机制:丢头队列和丢为队列，测试的机制如图八所示，一共有两个节点，节点0向节点1发送数据包，并分别采用两种队列机制，然后统计节点1的收包特性。 如图所示为测试结果，测试结果表明，丢头队列和丢尾队列都可以改变丢包率，并且可以看出丢头队列的延迟比丢尾队列的延迟更小。 如图所示曲线为队列有限级的测试曲线，所发送的数据包分为数据包和控制包 3.定向传输测试 上图为测试定向网络时的节点分布图，其中节点1，3，4，7，10，11为定向网络节点，当使用定向网络传输模式时，中心节点0向这些节点定向传输数据，其余节点则应不能收到数据包，而当使用非定向网络传输模式时，所有节点都应该可以收到数据包。 测试结果如上图，蓝色为非定向网络，黄色为定向网络，结果表明，当使用非定向网络时，全部节点都可以收到数据包，当使用定向网络时，只有定向网络节点才可以收到数据包，非定向网络节点无法收到数据包。 4.固定争用测试 如图所示，横轴为冲突范围所覆盖的用户数量，测试结果表明：随着冲突范围的不断扩大，覆盖的用户数量逐渐增多，因此导致的冲突逐渐增多，丢包率逐渐上升，收包率逐渐下降。 五、实验小结实验过程中，我们遇到了很多的问题，首先在实验环境的搭建过程中，刚开始搭建的是基于NS3-dev的环境，在代码测试的过程中遇到了很多的问题，之后又搭建了NS3-dce的环境进行测试。同时，在测试代码的时候也有很多的问题，由于机器的处理速度有限，仿真测试结果往往需要很长时间才会出来，也花费了我们很多的精力。 在之后的过程中，我们将继续改进这个模型，构建宏基站和微基站的体系架构，并在此架构上面探索单小区模型和大规模网络场景模型下的基站调度策略。","tags":[{"name":"课程","slug":"课程","permalink":"https://www.delta1037.cn/tags/%E8%AF%BE%E7%A8%8B/"},{"name":"NS3","slug":"NS3","permalink":"https://www.delta1037.cn/tags/NS3/"}]},{"title":"敏捷开发笔记","date":"2018-11-11T16:00:00.000Z","path":"2018/School/敏捷开发笔记/","text":"敏捷开发笔记 敏捷知识基础 迭代计划会议、迭代验收会议、每日站立会议、迭代回顾会议 聚焦客户价值，激发团队潜能、适应变化 自动化、变化的需求 story 故事描述了对于系统或软件的客户或用户有价值的一个功能点 组成 简短描述 针对故事描述交流，澄清细节 记录和传递故事细节的测试信息，用来确定故事是否开发完成 格式： 作为X（什么用户角色 为了Y（目的 希望得到什么（系统提供什么功能 3-3-4 三个角色：PO、master、开发人员 三个工件： 产品清单 迭代清单 燃尽图 四个会议 收集story 价值分析 识别用户角色 编写story 确定优先级 估计 分解Story 分解原则：每个格式提供相对完整的功能 好的story 独立 便于沟通 有价值 易于估计 可测试 持续集成 持续集成工作产品，一天集成多次，每次集成有自动化的测试环境（包含测试） 测试驱动开发 快速新增测试 运行所有测试 做改动 所有测试通过 重构，消除重复设计，设计优化结构 测试用例 快速：测试运行够快 独立用例之间互相独立 可重复：任何环境、可重复 自足验证：足够的自动化测试验证逻辑 及时：及时写测试用例","tags":[{"name":"敏捷开发","slug":"敏捷开发","permalink":"https://www.delta1037.cn/tags/%E6%95%8F%E6%8D%B7%E5%BC%80%E5%8F%91/"}]},{"title":"Linux小系统（一）-小系统制作","date":"2018-10-05T16:00:00.000Z","path":"2018/Linux/Linux小系统（一）-小系统制作/","text":"制作Linux小系统-外围文件系统定制 环境： - window10 - vmvare pro 14 - centos6.10-mini 一、Linux启动过程分析 BIOS MBR&#x2F;GPT Master Boot Record and Disk partitions Globally Unique Identifier Parttion Table Format OS Loader Window:NTLDR&#x2F;BootMgr Linux:GRUB&#x2F;GRUB2 OS Kernel DOS:IO.SYS MSDOS.SYS Window:ntoskrnl.exe Linux:vmlinuz Application Manager DOS:command.com Window:explorer.exe Linux:init Applications… 二、启动bash&#x2F;boot中的init.img文件* 一个由OS loader载入的镜像文件 临时“根文件系统”&#x2F;boot&#x2F;grub&#x2F;grub.conf文件 title Linux 2.4 root (hd0,1) kernel &#x2F;boot&#x2F;vmlinuz ramdisk_size&#x3D;8192 root&#x3D;LABEL&#x3D;&#x2F; initrd &#x2F;boot&#x2F;initrd.img 制作根文件系统 使用原来的kernel，initd自己的init*.img 如何生成img文件. 表示当前目录 $ find . | cpio -H newc -o | gzip &gt; &#x2F;boot&#x2F;initrd.img 解压生成的img(不小心删掉了自己的系统文件夹，可以用这个方法恢复) $ mv initramfs.img initramfs.img.gz # 添加gz后缀$ gunzip initramfs.img.gz # 解压$ mkdir temp # 创建目录并将解压后的文件丢进去$ cpio -i -F ..&#x2F;initramfs.img # 解压刚刚丢进temp的文件 制作init Application Manager init是开机后grub引导进入系统后执行的，所以想要开机进去之后得到一个bash，就得在这个里面定制过程 bash是一个命令，所以只要执行这个命令，就可以得到一个bash， text12# 查找命令find，可使用通配符*$ find / -name &quot;bash&quot; 可执行文件&amp;动态库 随意创建一个目录作为我们小系统的根目录，创建必要的文件夹（拷入小系统的路径与大系统路径一致，例如bash在bin目录中，就要在小系统根目录下创建bin目录然后将bash拷入） bash执行还需要有其依赖的动态库，我们的小系统启动起来是独立于大系统的，所以我们要将其依赖的动态库也拷进我们的小系统 text123# 查新指令依赖的动态库$ ldd /可执行文件路径$ ldd /bin/bash 拷贝可执行文件依赖动态库脚本 #!&#x2F;bin&#x2F;bash use : .&#x2F;script.sh &#x2F;可执行文件 &#x2F;动态库目录 dependList&#x3D;$( ldd $1 | awk ‘{if (match($3,”&#x2F;“)){ print $3}}’ ) echo $dependListcp $dependList $2 拷贝目录下的所有可执行文件依赖的动态库脚本 #!&#x2F;bin&#x2F;bash use : .&#x2F;script.sh &#x2F;可执行文件目录 &#x2F;动态库目录 for m in $(ls $1) do dependList&#x3D;$( ldd $1&#x2F;$m | awk ‘{if (match($3,”&#x2F;“)){ print $3}}’ ) cp $dependList $2done 三、管理设备 udev : 管理、监控主机设备的服务程序 依赖与sysfs文件系统（挂载于&#x2F;sys） 规则文件&#x2F;lib&#x2F;udev 配置文件&#x2F;etc&#x2F;udev 自动在&#x2F;dev目录下创建设备节点 &#x2F;proc目录：通过 &#x2F;proc 文件系统，在运行时访问内核内部数据结构、改变内核设置的机制 &#x2F;sys目录：硬件设备的驱动程序信息 通过执行&#x2F;sbin&#x2F;start_udev，就可以检测到所有的设备 text12# 查看当前机器所有设备$ ls /dev 四、挂载磁盘 磁盘也是一种设备 在linux上挂载磁盘，磁盘一般是在dev目录里的，但是在上面的管理设备部分，当列出当前机器设备时，并没有看到有关sd之类的，这是因为*缺少驱动程序 Linux的驱动在&#x2F;lib&#x2F;modules目录，可以看到有不同的版本号 text1234$ lsmod # 列出当前机器所使用的所有驱动$ modinfo # 查看驱动具体介绍，包括驱动依赖关系$ insmod # 加载指定的驱动$ modprobe # 载入制定模块或者载入一组相依的模块，需要有依赖关系moudules.dep 磁盘所需驱动 scsi_transport_spi.ko mptbase.ko mptscsih.ko mptspi.ko crc-t10dif.ko sd_mod.ko etx4文件系统驱动 mbcache.ko jbd2.ko ext4.ko 当加载完磁盘和文件系统驱动，就可以挂载和读写原来的文件系统了 五、登录login login认证体系（PAM） &#x2F;etc&#x2F;pam.d &#x2F;lib&#x2F;security 六、使用&#x2F;sbin&#x2F;init启动系统&#x2F;sbin&#x2F;init的工作： &#x2F;etc&#x2F;rc.sysinit probe devices:udevd fsck remount &#x2F;etc&#x2F;rc service &#x2F;sbin&#x2F;mingetty login prompt &#x3D; mingetty+&#x2F;bin&#x2F;login 七、联网 网卡驱动： e1000.ko ping：查看网络是否连通 ethtool：查看网卡信息 ifup、ifdown：启动，关闭网卡 mentohust：连接校园网的工具 ssh：连接到远程主机，或者被远程主机连接 scp：基于ssh在两台主机之间拷贝文件","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.delta1037.cn/tags/Linux/"},{"name":"Kernel","slug":"Kernel","permalink":"https://www.delta1037.cn/tags/Kernel/"},{"name":"小系统","slug":"小系统","permalink":"https://www.delta1037.cn/tags/%E5%B0%8F%E7%B3%BB%E7%BB%9F/"}]},{"title":"Linux小系统（三）-U盘启动","date":"2018-10-03T16:00:00.000Z","path":"2018/Linux/Linux小系统（三）-U盘启动/","text":"U盘启动小系统 环境： Window10 CentOs虚拟机 制作启动盘 找一个不常用的U盘，分出来一小部分作为启动分区，剩余的作为日常使用（最好在window上分盘。。。） 在虚拟机上挂载U盘，启动分区格式化 $ mkfs.ext4 &#x2F;dev&#x2F;uBootPart 将分出来的启动分区添加上启动标志 $ fdisk &#x2F;dev&#x2F;uBootPart -a 再次fdisk -l 之后看到U盘的启动分区的boot下有个* 4.向启动分区中安装grub,&#x2F;mnt是挂载位置 text1$ grub-install --root-directory=/mnt /dev/uBootPart 必要文件拷贝 &#x2F;boot&#x2F;grub&#x2F;grub.conf (内容做适当修改) boot&#x2F;vmlinuz* boot&#x2F;initramfs.img","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.delta1037.cn/tags/Linux/"},{"name":"Kernel","slug":"Kernel","permalink":"https://www.delta1037.cn/tags/Kernel/"},{"name":"小系统","slug":"小系统","permalink":"https://www.delta1037.cn/tags/%E5%B0%8F%E7%B3%BB%E7%BB%9F/"}]},{"title":"Linux小系统（二）-内核编译","date":"2018-10-03T16:00:00.000Z","path":"2018/Linux/Linux小系统（二）-内核编译/","text":"Linux内核编译 内核下载与解压内核下载内核下载地址 解压text1$ tar -xvf linux-*.tar.xz 编译安装开发环境text1234$ yum groupinstall &#x27;Development Tools&#x27;$ yum install ncurses-devel$ yum install elfutils-libelf-devel$ yum install bc 参考文档Linux-4.4-x86_64 内核配置选项简介-作者：金步国 Linux 核心编译与管理-鸟哥 TIPS小系统需要实现的功能、 CPU 硬盘控制器 网络控制器 USB控制器 HID、Mass Storage 声卡控制器(可选) 个人总结 网络控制器：联网需要网卡驱动，在设备管理器里可以看到自己网卡是什么型号的，然后在设备驱动-&gt;网络设备支持-&gt;以太网设备支持里将自己网卡那一类勾上，其它可以不要（因为没有这类网卡） 能编译成模块的尽量编译成模块，这样内核会变小很多 编译过程text12$ make mrproper # 删除之前的核心功能配置文件,配置文件！！！$ make clean # 清理编译过程中的中间文件，不删除配置文件 text12345$ make menuconfig #选择模块$ make clean #清除$ make -j 4 #多线程编译$ make modules_install #安葬模块$ make install #一键安装","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.delta1037.cn/tags/Linux/"},{"name":"Kernel","slug":"Kernel","permalink":"https://www.delta1037.cn/tags/Kernel/"},{"name":"小系统","slug":"小系统","permalink":"https://www.delta1037.cn/tags/%E5%B0%8F%E7%B3%BB%E7%BB%9F/"}]},{"title":"Apache配置ssl","date":"2018-07-30T16:00:00.000Z","path":"2018/Deploy/Apache配置ssl/","text":"阿里云申请的ssl证书配置(Apache) 一、下载证书 下载证书 上传到服务器 解压到 &#x2F;etc&#x2F;apache2&#x2F;ssl (不存在则创建) 二、配置Apache 打开SSL模块 $ a2enmod ssl 配置conf 编辑apache2配置文件 $ vim &#x2F;etc&#x2F;apache2&#x2F;apache2.conf apache2配置文件 text123456&lt;Directory /var/www/&gt; Options Indexes FollowSymLinks #把none改为all AllowOverride all Require all granted&lt;/Directory&gt; 编辑port.conf文件 text1$ vim ports.conf port.conf配置 text1234#添加监听443端口&lt;IfModule ssl_module&gt; Listen 443&lt;/IfModule&gt; 配置default-ssl.conf text123456789#添加servernameServerName example.com#修改sslengineSSLEngine on#添加证书文件，按照阿里云给出的示例添加即可#证书的文件位置就是刚刚上传的位置SSLCertificateFile /etc/apache2/ssl/public.pemSSLCertificateKeyFile /etc/apache2/ssl/2146003231320408.keySSLCertificateChainFile /etc/apache2/ssl/chain.pem 三、启用启用刚刚的ssl配置 text1$ a2ensite default-ssl 重启apache服务器 text1$ service apache2 restart OK~","tags":[{"name":"SSL","slug":"SSL","permalink":"https://www.delta1037.cn/tags/SSL/"}]},{"title":"K8s概念笔记","date":"2018-05-03T16:00:00.000Z","path":"2018/Others/K8s概念笔记/","text":"K8s概念笔记 My Study of kuberneteskubernetes结构图-来源 基本概念和术语master**功能:**集群控制节点,负责整个集群的管理和控制,属于首脑 master节点上运行的关键进程 - Kubernetes API Server(kube-apiserver):提供HTTP Rest接口的关键服务进程,kubernetes里所有资源的增删查改操作的唯一入口,也是集群控制的入口进程 - Kubernetes Controller Manager(kube-controller-manager):kubernetes里资源对象的自动化控制中心 - Kubernetes Scheduler(kube-scheduler):负责资源调度(Pod调度)的进程 Node除了Master,kubernetes中的其它机器被称为node节点,node节点是kubernetes集群中的负载节点,每个node都会被分配工作负载(docker容器),当某个node出错时,该节点的任务会被master自动转移到其它节点上.node上的关键进程 - kubelet:负责pod对应的容器的创建,启动停止等任务,同时与master密切协作,实现集群管理 - kube-proxy:实现kubernetes Service的通信与负载均衡 - Docker engine(docker):Docker引擎,负责本机的容器创建和管理 Pod每个pod有一个根容器Pause,还有一个或者多个用户业务容器Why kubernetes have Pod? - 在一组容器作为一个单元时,很难对整体进行操作,引入业务无关并且不易死亡的Pause容器作为Pod的根容器,以它的状态代表整个容器组的状态 - Pod里的多个业务共享Pause里的IP,共享Pause容器挂接的Volume,既简化了业务之间的通信问题,也解决了文件共享问题 Label**功能:**Label可以附加到各种资源对象上,例如node,pod,service,rc等,一个资源对象可以定义任意数量的Label,同一个Label也可以添加到任意数量的资源对象上去,以提供Label Selector来选择对象 标签选择方式: - 等式:name&#x3D;redis-slave,name!&#x3D;redis-slave - 集合:name in (redis-master,redis-slave),name not in (redis-master,redis-slave) Label和Label Selector 共同构成了kubernetes系统中最核心的应用模型,使得被管理对象能够被精细的分组管理,实现整个集群的高可用性 Replication Controller(RC)管理 Pods 的生命周期。它们确保指定数量的 Pods 会一直运行，还有实现资源伸缩。 - 定义RC实现Pod的创建与副本数量的自动控制 - RC 通过Lable Selector机制实现对副本的自动控制 - 通过改变RC的Pod副本数量，实现Pod的扩容或缩容 - 通过改变RC里Pod模板中的镜像版本，实现Pod的滚动更新 DeploymentDeployment可以认为是RC的升级版，最大的区别是我们可以随时知道POD容器的部署进度 使用场景: 创建一个Deployment对象来生成RC并完成Pod副本的创建过程 检查Deployment的状态看部署动作是否完成 更新deployment以创建新的Pod(升级) 如果当前Deployment不稳定则回滚到早先版本 暂停Deployment以便于一次修改多个PodTemplateSpec的配置项，之后再进行发布 扩展Deployment以应对高负载 查看Deployment的状态，以此作为发布是否成功的指标 清理不在需要的旧版本RC Horizontal Pod Autoscaler(HPA)HPA也是一种资源对象，通过追踪分析RC控制的pod的负载变化情况来确定是否需要针对性地调整目标pod的副本数（增加或者减少） Pod负载的度量指标: - CpuUtilizationPercentage（CPU利用率）,取所有副本自身CPU利用率的平均值（需要定义Pod Request值） - 应用程序自定义的度量指标，比如TPS或者QPS StatefulSet用于实现有状态的集群管理，可以将它看做Deployment&#x2F;RC的一个变种 特性: - StatefulSet里的每个Pod都有稳定、唯一的网络标识，可以用来发现集群的其他成员 - StatefulSet控制的Pod副本的启停顺序是受控的，如StatefulSet名叫zk,则第一个叫做zk-0，第二个叫做zk-2，依次类推 - Stateful里的Pod采用稳定的持久化存储卷，通过PV&#x2F;PVC实现 Service service定义了一个服务的访问入库地址，前端应用（Pod）通过这个入口地址访问其背后的一组由Pod副本组成的集群实例，Service与其后端Pod副本集群之间则是通过Label Selector来实现无缝对接的。RC的作用实际上是保证service服务能力和服务质量始终处于预期的标准。 一组Pod组成的服，客户端如何访问？每个Node上的kube-proxy进程负责把对service的请求转发的后端某个Pod的实例上，并在内部实现了服务的负载均衡与会话保持机制。但需要注意的是：service不是共用一个IP，而是每个Service分配了一个全局唯一的虚拟IP地址（ClusterIP），服务调用就变成一个TCP网络通信。 kubernetes的服务发现机制，Service对象都有一个唯一的ClusterIP以及唯一的名字，在老版本中通过自动注入环境变量将service的name与ClusterIP绑定，新版本中采用插件的方式引入了DNS系统，把service的name作为DNS域名，然后程序就可以通过service的name来建立通信连接了 外部系统访问service的关键在于3种IP，即： 1.Node IP node节点的IP地址，集群之外的节点访问集群内的服务时，必须要通过NodeIP进行访问 2.Pod IP pod的IP地址，Docker Engine根据dicker0网桥的IP地址段进行分类的一个虚拟的二层网络的IP地址 3.Cluster IP service的IP地址，虚拟的IP，它的特点：仅作用域service对象，由k8s管理和分配IP地址;无法被ping;只能结合service port组成一个具体的通信端口，单独的Cluster IP不具备通信基础;集群之内 Node&#x2F;pod&#x2F;cluster之间的通信与通常的IP路由与很大的不同 service的cluster IP无法供外部直接使用，但通过指定服务的port绑定在节点的port上，即可进行访问；当pod位于多个node时，通过nodeip:port访问到的是nodeip所在node上的pod,如需负载可以考虑使用硬件负载均衡器或者Nginx Volumevolume是pod中能够别多个容器访问的共享目录；k8s中volume定义在pod上，然后被pod中的多个容器挂载到具体的目录下；volume与pod的生命周期相同 类型: - emptyDir：Pod分配到node时创建的，它的初始内容为空，并且无需指定宿主机上对应的目录文件，pod从node上移除时，则emptyDir中的数据永久删除；emptyDir的用途有： - 临时空间 - 长时间任务的checkpoint点 - 一个容器需要从另一个容器获取数据的目录 hostPath，在pod上挂载宿主机的文件或目录， 主要用途： 容器应用生成的文件（如日志）需要永久保存时 需要访问宿主机的文件时 注意事项: 不同的node上具有相同配置的pod可能因为宿主机上的目录和文件不同而导致对Volume上目录和文件的访问结果不一致 hostPath无法纳入资源配额管理 NFS，使用NFS网络文件系统共享存储数据 其他类型：ceph、glusterfs等 Persistent Volume(PV) PV是k8s集群中某个网络存储中对应的一块存储，它和Volume的区别： PV只能是网络存储，不属于任何Node，但可以在每个Node上访问 PV独立于Pod定义 PV目前支持的类型涵盖了很多公有云平台存储（gce、aws）以及一些网络文件系统（NFS） Pod想申请PV时，需要先定义一个PVC（Persistent Volume Claim），然后在Pod的Volume中引用定义好的PVC Namespace Namespace通过将集群中的资源对象分配（逻辑上的）到不同的Namespace中，形成逻辑上的分组不同的项目、用户组等，便于实现多租户资源管理。 默认的namespace是default 声明资源对象时，在metadata一项中可以指定，如namespace: dev Annotation注解与Label类似，但具有严格的命名规则","tags":[{"name":"K8s","slug":"K8s","permalink":"https://www.delta1037.cn/tags/K8s/"}]},{"title":"Mysql error 2002","date":"2018-01-30T16:00:00.000Z","path":"2018/Bugsfix/Mysqlerror2002/","text":"Mysql运行报错：ERROR 2002 (HY000): Can&#39;t connect to local MySQL server through socket &#39;/var/run/mysqld/mysqld.sock&#39; (2) Mysql error2002配置 DigtalOcean Ubuntu17.04 Mysql5.7* Wordpress 问题 查看网站时显示连接数据库错误 后台登录Mysql显示 ERROR 2002 (HY000): Can’t connect to local MySQL server through socket ‘&#x2F;var&#x2F;run&#x2F;mysqld&#x2F;mysqld.sock’ (2) 解决 内存不足。。。 参考链接-增加交换区 生成交换空间 text1$ sudo fallocate -l 4G /swapfile 查看生成的文件 $ sudo ls -lh &#x2F;swapfile 输出的内容 text1$ -rw-r--r-- 1 root root 4.0G Apr 28 17:19 /swapfile 更改文件的权限 $ sudo sudo chmod 600 &#x2F;swapfile 设置交换空间并使交换空间可用 $ sudo mkswap &#x2F;swapfile$ sudo swapon &#x2F;swapfile 查看设置结果 $ free -m","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.delta1037.cn/tags/MySQL/"}]},{"title":"2018","date":"2017-12-31T16:00:00.000Z","path":"2018/Times/2018/","text":"To 2018 不要老是宅在学校，老是看书看漫画动漫。。。武汉的那些奇奇怪怪的街，或许很有趣呢，，，倒是出去过几次，走在繁华的街上，人来人往，有几丝惊恐，算了编不下去了。。。下次勇敢点! 是这座城接纳不了自己，还是自己接纳不了这座城。 哦～ 下学期要好好听课……这学期废了，听课率估计不到1%，期末预习真的是鸭梨大，，， 不要老是去想一些乱七八糟的事情，好好规划自己，虽然不想被灌输一些奇怪的知识，但还是要收拾好自己，知道自己要做什么 怎么感觉和别人老是沟不通呢……难道是API有问题么，，， 找找心在哪咯，，， 就酱，就这些。。。 最近好像能看懂诗集了，，语文老师看到这儿…肯定会大吃一鲸的吧…… 等会儿复制下再圈个重点&#x2F;&#x2F;期末预习过度后遗症 谢谢大佬送的肯德基日历～","tags":[{"name":"时光","slug":"时光","permalink":"https://www.delta1037.cn/tags/%E6%97%B6%E5%85%89/"}]},{"title":"短信收发功能分析","date":"2017-12-31T16:00:00.000Z","path":"2018/School/短信收发功能分析/","text":"短信接收与发送功能分析 华中科技大学 摘要本文主要介绍了短信的发送与接收功能，其中包含发信端向短信中心发送短信的过程、短信中心相互转发短信的过程，短信中心向收件人发送短信的过程，具体介绍了这三者之间的连接过程和网关在这三者之间的作用；此外介绍了短信中心的存储转发模式、网关、寄存器、移动交换中心、如何确认收件人的位置和不同的传输模式，具体介绍了网关在安全性方面的作用和短信发送所采用的协议；然后，简单介绍了短信的几种加密算法，并分析了算法的原理和不安全性体现；最后介绍了短信的发展过程，及其在发送内容方面的进步，和各种短信业务的分类及其简单介绍了在发送过程中路线的不同。 关键词：短信 发送 接收 短信协议 加密算法 短信发展 1.短信的发送与接收1.1手机编辑短信发送到短信中心1.1.1从手机编辑短信到发送到短信中心的大体流程首先发送端编辑短信，并且填写收件人的号码，然后手机内的芯片对文字信息进行编码，向串口写相应的AT指令，然后将信息传递到基带，由调制解调器调制成电磁波，最后该电磁波发送到短信中心。 1.1.2客户端与短信中心验证流程a．首先MS向MSC发起接入请求，其中包含MS的IMSI或TMSI号码；b，MSC向VLR发起接入请求，VLR在接入处理过程中可进行鉴权和加密；c，VLR向MSC回送接入证实消息；d，MSC向MS回送接入证实消息，允许MS进入GSM网络通讯；e，MS向MSC发送一条短消息，其中包含短消息的内容、目的SC地址；f，MSC向VLR查询MS是否可以发送短消息；g，VLR在确认MS具有短消息业务且没有被禁止后，通知MSC当前MS可以发送短消息，并提供MSISDN号码；h，MSC向IWMSC转发短消息，其中包含该条短消息的内容、源MS的MSISDN号码、目的SC地址；i，IWMSC向SC转发短消息，其中包含该条短消息的内容、源MS的MSISDN号码、目的SC地址；j，SC通知IWMSC已接受短消息；k，IWMSC通知MSC已接收短消息；l，MSC通知MS短消息发送成功。 1.1.3短信编码的规则对短信参数进行ＰＤＵ（ｐｒｏｔｏｃｏｌ ｄａｔａ ｕｎｉｔ）格式的编码，短信经过十六进制的编码后进行传送，其中不仅包含了消息字符，还包含了许多元数据，比如短信中心地址、字符编码格式、时间戳等 1.1.4关于短信字符的限制无论何时使用SS7协议的移动应用部分（MAP），SMSC和手机之间都会发送短消息。消息与MAP MO-和MT-ForwardSM操作，其有效载荷长度由信令协议的约束所限制发送以精确地140 个字节（140个字节×8比特&#x2F;字节&#x3D; 1120个比特），单条短信采用７位编码时最长可达１６０个字符，对于中文字符需要１６位编码，因此实际能发送的文本只有７０个字符，过长的短信会进行分割发送 1.2从短信中心到短信中心的转发1.2.1从短信中心到短信中心转发的大体过程首先短信中心对收到的信息进行初次解码，来确定收件人的号码和其他关键信息，然后以此来查找收件人的位置，然后将该短信发送到收件人所在位置的短信中心 1.2.2 短信中心的存储转发模式短信发出后先存储在ＳＭＳＣ（短信服务中心，ｓｈｏｒｔ ｍｅｓｓａｇｅ ｓｅｒｖｉｃｅ ｃｅｎｔｅｒ），然后由短信中心将短信信息发送给接收方，如果接收方不在服务区，ＳＭＳＣ就会自动保存该信息，等到接收方出现在服务区时再发送 1.2.3 网关（SMCGMSC）的作用获取来自SMSC传递的短消息，通过HLR读取路由信息，符合传送条件后，将SMS消息发送给收件人所处的基站 1.2.4归属地位置寄存器（HLR）归属地位置寄存器，用于存放和管理移动用户的相关信息，移动设备所在位置信息同样保存在HLR，HLR每隔一段时间就会记录位置信息，采用这样的机制，当进行服务时可以迅速查到收件人 1.2.5移动交换中心（MSC）移动交换中心，管控数据的连接与传送，当用户从一个服务区转至另一个服务区时，可以对区域进行切换 1.2.6 关于收件人位置的确定尽管您没有使用手机打电话，您的手机也在不停地发送和接收着信息。它通过被称为控制通道的通路与手机发射塔进行通信。这种通讯的目的是让手机系统了解自己所在的信号区域，以便在您移动时，手机可以切换到其他信号区域。每隔一段时间，手机和发射塔将交换数据包以确定一切工作正常。 1.2.7 跨网传输与同网传输跨网传输：不同运营商的短信中心之间相互发送，首先发信人先将信息发送到收信人运营商的短信中心，发送人运营商的短信中心将信息发送给收信人运营商的短信中心，收信人的短信中心再将该信息发送给收信人。 同网传输：相同运营商的短信中心之间互相发送，首先发信人将信息发送到短信中心，短信中心再将该信息发送给收信人。 1.3从短信中心到发送到收件人的手机中1.3.1从短信中心到发送到收件人手机的大体过程用户手机定时器触发开始读串口数据进行判断，当串口没有数据时，等待下一次定时器触发；当短信中心向收件人发送电磁波即串口有数据时，将串口的数据读入，然后收件人对收到的数据进行解码，最后对PDU编码的数据解析成文本，在手机端以UI界面显示 1.3.1接收端与短信中心的相互验证流程a, SC向GMSC发送短消息，其中包含短消息的内容、源SC地址、目的MS的MSISDN号码，另外还有SC存在短消息等待发送标识；b. GMSC向目的MS所属的HLR查询路由信息；c, HLR向GMSC返回查询结果，有两种情况：成功，返回路由信息其中包含目的MS所在的MSC号码，以及目的用户的IMSI、LMSI号码;;失败，返回错误原因，可能同时返回Alert_MSISDN号码。d. GMSC根据获得的路由信息向目的MSC发送短消息，其中包含短消息内容、源SC地址、目的MS的IMSI或LMSI号码；e. MSC向VLR查询目的MS的相关信息，包括MS是否可及等标志位；f. VLR向MSC发送寻呼请求消息，要求建立无线连接；g. MSC收到VLR的寻呼请求后，向MS发送寻呼请求；h. MS寻呼成功，进行接入过程；i. MSC发送接入请求消息通知VLR寻呼成功；j. VLR完成对MS的鉴权、数据的更新以及加密等操作后，通知MSC接入成功；k. MSC向MS发送接入证实消息；l. MSC向MS转发短消息，其中包括短消息内容和源SC地址；m. MS向MSC返回短消息成功接收消息；n. MSC通知GMSC，MS已成功接收短消息；o. GMSC通知SC，MS已成功接收短消息。行判断；当数据中有新短信的提示符时，按照ＰＤＵ短信的解码格式对该短信进行解码，并调用ＵＩ界面提示新短信到达 1.4短信的双向传输模式ＳＭＳ对发送的消息进行可靠的双向传输，即ＳＭＳ发送消息后会受到确认信息，获得发送的结果，对于不同的结果即发送成功或者发送失败会显示不同的信息给发送方 1.5短信的传输同步功能ＳＭＳ传输的同步性，即ＳＭＳ可以与数据、语音等业务一起进行同步传输，即便在业务信道数据量处于高峰时也能保证信息的顺利发送 1.6短信的PTP模式Ｐｅｅｒ ｔｏ ｐｅｅｒ的通信方式，发送方只需要知道对方的手机号码，就可以给对方发送信息，就先计算机的ｉｐ地址一样，一旦绑定，就可以通过该地址与其他地址建立连接 1.7 无状态通信SMS是一种无状态通信协议，其中每个SMS消息被认为完全独立于其他消息。使用SMS作为有状态对话（其中MO应答消息与特定MT消息配对）的通信信道的企业应用要求会话管理在协议外部维护 1.8 短信所采用的协议1.8.1 协议名称ＳＭＰＰ（ｓｈｏｒｔ ｍｅｓｓａｇｅ ｐｅｅｒ ｔｏ ｐｅｅｒ ｐｒｏｔｏｃｏｌ），对等短信信息协议 1.8.2 协议的功能1）定义了外部短信信息实体ＥＳＭＥ与短信息中心ＳＭＳＣ的数据通信接口 2）在ＥＳＭＥ和ＳＭＳＣ之间定义一系列的短信息交换操作 3）在ＥＳＭＥ和ＳＭＳＣ之间定义ＥＳＭＥ和ＳＭＳＣ交换的数据格式 1.8.3 各个运营商对协议的拓展各运营商基于ＳＭＰＰ协议开发了适合自己的协议标准：中国移动的ＣＭＰＰ协议，中国联通的ＳＧＩＰ协议，中国电信的ＳＭＧＰ协议 1.9 短信的发送与接收手机的信号频率很高，一般在900Mhz左右，靠电离层反射传播，打电话的手机信号传到最近的基站，也就是移动或者连通的信号塔，再由基站把高频信号频率降低，由基站和基站之间通信，这个信号是直线传播，遇到高的建筑物会被挡住，所以那些塔都竖的很高，传到接电话的手机附近的基站，再转成高频信号发给手机。 1.10 短信网关1.10.1 短信网关简介短信网关ISMG全称Internet Short Message Gateway，主要是为了解决各网络、各运营商之间的短信互通和SP的接入问题。它为使用单位收发短信而提供的一个动态数据交换平台系统。通过该系统的接口软件，可以将短信平台与各种系统和软件进行无缝高效相连，将应用单位的系统随时产生的动态信息转变成手机短信，通过梦网平台连接移动和联通的短信中心以端口特服号码进行实时中发送和接受，为各种系统（或软件）建立一个快速的短信双向（或单向）通道，以便手机用户采用短信方式与SP双向通信，接收SP提供的信息服务。 1.10.2 短信网关的组成及其功能短信网关各组成部分的功能为： （1）SMPP代理系统遵循SMPP 3.3版本协议与GSM网中短消息中心连接，实现高效、可靠的数据传输。该系统支持流量控制功能，能够根据SMSC的业务量进行发送流量控制。 （2）通信代理系统实现与SP等内容供应商的连接和协议互通。它基于TCP&#x2F;IP协议基础之上，利用CMPP协议与SP之间建立一条安全、高效的传输通道。该系统支持流量控制功能，能够根据本身的业务量进行接收流量控制。 （3）防火墙作为短信网关的重要功能组成部分，其功能是对短信网关内部其它相关模块进行保护，实现针对内外访问的包过滤和代理。 （4）短消息网关处理系统完成网关的业务处理，包括：向汇接网关进行路由查询，在本地建立短信网关ID、用户手机号码、SP ID及其IP地址对应表的缓存，建立用户手机号码段与SMSC（短信中心）地址的对应表，完成对数据分发功能的支持、计费原始话单的提供及处理等。 （5）短信网关计费系统提供短信网关的原始话单记录（CDR）。 （6）业务管理系统包括业务管理和网关监控功能。 1.10.3 短信网关与短信中心的连接短信网关与短信中心之间应采用专线方式互联 1.10.4 短信网关的安全性短信网关在硬件和软件结构设计上应采用分布式、模块化的设备，其中硬件设备可考虑采用多台主机，在网络上利用四层交换机实现负载分担工作，避免单点故障，实现设备的安全。 同时短信网关采用防火墙技术，可以支持IP包过滤和应用代理方式，防止外界的攻击，实现信息的安全。 短信网关与SP在进行CMPP协议的连接建立时，采用MD5对互相的身份进行认证，实现业务的安全。 短信网关与短信中心、计费中心之间的连接都采用专线方式，而且与计费中心的连接还要求计费中心侧加入防火墙，保障了现网设备的安全性不会由于与短信网关的连接而降低。 2.短信的安全性2.1 GSM标准的加密算法对于ＧＳＭ标准所使用的加密算法，短信的安全性已经被证实是不堪一击的，通过暴力破解可在２的３２次方时间内解出短信的具体内容， 2.2 GSM算法的改进可以使用强加密的ＣＤＭＡ标准，用于保密信息的传输 2.3 A5&#x2F;1算法2.3.1 算法简介A5 &#x2F; 1是用来产生为每个脉冲串的114位序列的密钥流被进行异或之前调制与114位。A5 &#x2F; 1使用一个64位的密钥和一个公认的22位帧号进行初始化。使用Comp128v1进行密钥生成的老式GSM实现有10个密钥位固定为零，从而产生有效的密钥长度的54位。这个弱点通过Comp128v2的引入得到纠正，该Comp128v2产生适当的64位密钥。 2.3.2 算法的破解利用了GSM通信加密中的两个安全漏洞，并且在普通商用硬件的帮助下，花费了55天的时间计算出了一个彩虹表。这个彩虹表的大小为984GB。得到了彩虹表之后，安全专家就可以在短短的九秒内确定用于加密通信数据的密钥了。 2.4 A5&#x2F;2算法密码基于四个带有不规则时钟的线性反馈移位寄存器和一个非线性组合器的组合 2.5 A5&#x2F;3算法（KASUMI）KASUMI算法在3GPP技术规范中规定。KASUMI是128位密钥和64位输入和输出的分组密码。KASUMI的核心是一个八轮Feistel网络。主要Feistel网络中的轮函数是不可逆的类Feistel网络变换。在每一轮中，循环函数都使用一个循环密钥，该循环密钥由使用固定密钥调度从原始128位密钥导出的八个16位子密钥组成。 2.6 短信不安全方面a.通过固定网络传输的通信数据没有受到加密保护；b.无法抵御某些主动攻击；c.只有连接至安全的固定网络才可以保证GSM的通信安全；d.GSM中的合法拦截只是一种事后补救措施；e.终端识别码不可信任。 3.短信的发展及其分类3.１．SMS短信仅支持发送文本，根据发送对象和客户是否处理漫游状态，基础短信业务可分为网内点对点短信、网间点对点短信、国际短信、短信国际漫游。 3.2. 移动梦网短信业务移动梦网短信业务是移动梦网服务的重要组成部分，是中国移动向客户提供的基于移动梦网短信平台的数据应用服务总称。移动梦网短信业务由与中国移动签约的合作伙伴提供，目前已接入数百家内容提供商（简称SP），提供了数万种业务。 3.3．ＥＭＳ短信可以支持发送格式文本、音效、小型图片、以及照片。其中音效是语音短信业务，语音短信业务是指把你想说的话语通过固定电话、小灵通或者手机进行录音，发给一个或多个用户进行收听你的留言，同时，你还可以根据电话的提示音，进行语音短信的接收、转发、查询、回复和语音短信点播等操作。它弥补了传统的文字短信难以传递声音和信息输入不便的缺憾，解决了那些因为不熟悉拼音使用，长时间徘徊在短信之外的人们发送短信的难题，也有效地解决了电话、小灵通或手机与之间发送短信的互联互通问题。 3.4．ＭＭＳ彩信可以支持文本短信息、动画、音频、视频文件。彩信的英文名是MMS，它是Multimedia Messaging Service的缩写，意为多媒体信息服务，通常又称为彩信。它最大的特色就是支持多媒体功能，能够传递功能全面的内容和信息，这些信息包括文字、图像、声音、数据等各种多媒体格式的信息。 彩信在技术上实际并不是一种短信，而是在GPRS网络的支持下，以WAP无线应用协议为载体传送图片、声音和文字等信息。彩信业务可实现即时的手机端到端、手机终端到互联网或互联网到手机终端的多媒体信息传送。 4.短信业务的分类１．网内点对点通信用户在手机上编辑信息内容，输入对方手机号码，选择发送将一条短信发送到接收方手机的短信业务，单条最大长度为140个字节，或者70个中文字符 ２．网间短信业务中国移动和中国联通实现短信的互联互通，移动用户和联通用户可通过手机发送短信 ３．国际短信中国移动和全球89个国家和地区的134个移动运营商实现了短信互通，即移动用户可以和港澳台、东南亚、北美、南美等国家和地区的主要移动运营商的用户收发短信 ４．短信国际漫游中国移动用户漫游与中国移动签署了GSM漫游协议的国家和地区后，可以使用当地移动网络和国内移动用户收发短信 5.参考文献 [1] 维基百科SMS https://en.wikipedia.org/wiki/SMS [2] 互动百科 短信http://www.baike.com/wiki/%E7%9F%AD%E4%BF%A1 [3] 维基百科 KASUMI算法 https://en.wikipedia.org/wiki/KASUMI [4] 智能手机电话短信实验模块设计http://rf.eefocus.com/article/id-257105 [5] 短信平台在移动办公中的设计与实现https://wenku.baidu.com/view/91d83d987f1922791788e800.html [6] 多媒体短信https://zh.wikipedia.org/wiki/%E5%A4%9A%E5%AA%92%E9%AB%94%E7%9F%AD%E8%A8%8A [7] 移动CMPP通信原理及短信协议解析https://wenku.baidu.com/view/53dba4ee9b89680203d82549.html?re=view [8] 移动网络名词理解http://m.blog.csdn.net/karen_wang&#x2F;article&#x2F;details&#x2F;7650433","tags":[{"name":"课程","slug":"课程","permalink":"https://www.delta1037.cn/tags/%E8%AF%BE%E7%A8%8B/"},{"name":"SMS","slug":"SMS","permalink":"https://www.delta1037.cn/tags/SMS/"}]},{"title":"Permission denied (publickey)","date":"2017-12-05T16:00:00.000Z","path":"2017/Bugsfix/Permissiondenied(publickey)/","text":"SSH连接时出现Permission denied (publickey)错误 Permission denied (publickey)问题描述在用Linux终端使用ssh root@server_ip来连接到远程服务器时，出现Permission denied (publickey).提示 问题原因首先ssh连接服务器是需要一对秘钥的，包括私钥和公钥，私钥（&#x2F;.ssh&#x2F;id_rsa）保存在本地服务器上，而公钥（&#x2F;.ssh&#x2F;id_rsa.pub）保存在远程服务器上（~&#x2F;.ssh&#x2F;authorized_keys文件内）。当使用ssh进行连接时，本地向远程服务器发起连接，服务器会随机生成一个字符串发送给登陆的用户（发起登陆的客户端），用户对该字符串使用私钥加密之后发送给服务器，服务器使用公钥对加密后的字符串解密，如果解密后的字符串与之前发送给客户端的字符串一致，则判断为登陆成功。 综上，Permission denied(publickey)的问题可能如下1、远程服务器没有添加公钥2、远程服务器公钥文件夹权限错误 一、公钥没有添加如果服务器端根本就没有添加公钥是断然不可能通过认证的 Solution客户端已经有秘钥对：通过其它方式登录到远程服务器，查看.&#x2F;ssh&#x2F;authorized_keys文件中是否添加了公钥，若没有可直接将公钥内容拷贝到该文件末尾客户端没有秘钥对：通过ssh-keygen命令生成秘钥对，默认文件夹是&#x2F;.ssh文件夹，将.ssh文件夹内id_rsa.pub的内容拷贝到服务器上的.&#x2F;ssh&#x2F;authorized_keys文件末尾（若服务器上.&#x2F;ssh&#x2F;authorized_keys不存在则也可以使用ssh-keygen来生成文件结构） 二、远程服务器.ssh权限问题远程服务器~&#x2F;.ssh文件夹及其文件权限不对，包括1、authorized_keys文件权限2、.ssh文件夹权限3、.ssh文件夹所有权 Solution通过其它方式登录到远程服务器，如果是阿里云则可以在网页中通过验证之后打开一个终端，然后进行如下操作 更改文件所有权 text12$ chown -R your_user:your_user ~/.ssh//我用root登录，your_user是root 更改文件夹权限 text1$ chmod 700 ～/.ssh 更改authorized_keys文件权限 text1$ chmod 600 ~/.ssh/authorized_keys 参考文献 https://askubuntu.com/questions/311558/ssh-permission-denied-publickey","tags":[{"name":"SSH","slug":"SSH","permalink":"https://www.delta1037.cn/tags/SSH/"}]},{"title":"美化Ubuntu","date":"2017-12-04T16:00:00.000Z","path":"2017/Deploy/美化Ubuntu/","text":"Ubuntu美化（安装macUbuntu主题） 推荐一个装双系统的博客：最近刚装了双系统，重新布置了下Ubuntu的界面，这个博客不错，装双系统可以看一下http://blog.csdn.net/fesdgasdgasdg/article/details/54183577 下载壁纸略。。。（壁纸好看就行了17 张程序员壁纸推荐） 下载主题图标等tip:使用install安装时可能会出现找不到这个安装包的问题，可以使用‘星’符（正则表达式匹配） text1$ sudo apt-get install macbuntu* 来看本地有哪些包可以安装 text1234$ sudo add-apt-repository ppa:noobslab/macbuntu$ sudo apt-get update$ sudo apt-get install macbuntu-os-icons-lts-v7$ sudo apt-get install macbuntu-os-ithemes-lts-v7 安装Plank Docktext1$ sudo apt-get install plank 将plank添加到开机启动-&gt;使用gnome-session(启动器中搜索,打开并将启动命令填入) unity-tweak-tool 安装并打开unity-tweak-tool，修改安装的主题 个人认为可以添加热区使鼠标移到此位置时可以平铺打开的所有界面，及其方便界面之间的切换 另附想要继续美化可以参考第一个链接，可能需要科学上网，鄙人认为只要有plank方便操作就可以了 终端配置简书：五分钟入门Terminator 安装新字体 将新字体拷入&#x2F;usr&#x2F;share&#x2F;fonts中 运行以下命令更新字体缓存 $ sudo fc-cache -f -v 参考链接 http://www.noobslab.com/2016/04/macbuntu-1604-transformation-pack-for.html -http://www.linuxidc.com/Linux/2016-06/131947.htm","tags":[{"name":"美化","slug":"美化","permalink":"https://www.delta1037.cn/tags/%E7%BE%8E%E5%8C%96/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://www.delta1037.cn/tags/Ubuntu/"}]},{"title":"9.27~10.28计划","date":"2017-09-26T16:00:00.000Z","path":"2017/Times/9.27~10.28计划/","text":"9.27~10.28计划 本月计划：9.27-10.1：1）学习机器学习算法–贝叶斯，向量机；学习对数据的处理 2）学习Python的基本语法结构，能够理解Python写的机器学习程序 3）算法导论学习29章线性规划 10.1-10.7：1）完善多线程的知识结构，参考深入理解计算机系统的网络编程和并发编程，将socket服务端改写出一个多线程程序 2）算法导论30-31章多项式与快速傅里叶变换和数论算法，解决15-16章动态规划和贪心算法题目，理解红黑树删除部分 3）深入理解计算机系统复习第三章程序的程序级表示，学习第四章处理器体系结构，了解汇编语言内部原理 4）CTK+，改写计算器程序，有图形页面 5）解决ping解包错误问题 6）编译时自己写makefile和CMakeList.txt 10.8-10.14：1）学习Linux系统管理 2）算法导论第32章字符串匹配，写23-24关于树的题目 3）深入理解计算机系统第五章-优化程序性能，写3-4章课后习题 10.15-10.21：1）学习TCP&#x2F;IP 2）算法导论34章-NP完全性，写二叉树和红黑树题目 3）深入理解计算机系统第六章-存储器的层次结构，第五章课后习题 10.22-10.28：1）继续学习shell脚本，完善知识体系的不足 2）算法导论35章-近似算法，写数论算法的题目 3）深入理解计算机系统第七章-链接，第六章课后习题 总计划：每日一道leetcode，若easy则两道，以理解为主 吾志所向,一往无前 愈挫愈勇,再接再厉","tags":[{"name":"时光","slug":"时光","permalink":"https://www.delta1037.cn/tags/%E6%97%B6%E5%85%89/"}]},{"title":"状态机","date":"2017-09-12T16:00:00.000Z","path":"2017/Algorithm/状态机/","text":"有限状态机介绍 参考文献 有限状态机状态机：表示有限个状态以及在这些状态之间的转移和动作等行为的数学模型 有限状态机的下一个状态和输出，是由输入和当前状态决定的。 分类：接收器和识别器：接收器和识别器（序列检测器）产生一个二元输出，是或者否回答输入是否被机器接受，所有有限状态机的状态是称为接受或者不接受。 在所有处理都被处理，若当前状态是接受状态，输入被接受，否则被拒绝。 开始状态：一个没有起点的箭头 接受（最终）状态：接受状态（最终状态）是机器回报到目前为止，输入的字符串属于它所接收的内容之状态，状态图中通常将其标注为双圆圈 开始状态也可以是接受状态，此情况下自动机会接受空字符串，。如果开始状态不是接受状态，且没有可以连到任何接受状态的箭头，那么此自动机就不会“接受”任何输入 变换器：两种变换器： 1.Moore机，摩尔型有限状态机。 只使用进入动作的有限状态机，也就是输出只依赖于状态 2.Mealy机，米莉型有限状态机。 只使用输入动作的有限状态机，也就是输出依赖于输入和状态","tags":[{"name":"状态机","slug":"状态机","permalink":"https://www.delta1037.cn/tags/%E7%8A%B6%E6%80%81%E6%9C%BA/"}]},{"title":"CMake笔记","date":"2017-08-23T16:00:00.000Z","path":"2017/C_C++/CMake笔记/","text":"CMake笔记 CMake它首先允许开发者编写一种平台无关的 CMakeList.txt 文件来定制整个编译流程，然后再根据目标用户的平台进一步生成所需的本地化 Makefile 和工程文件 linux平台使用cmake流程 编写 CMake 配置文件 CMakeLists.txt 。 执行命令 cmake CMakeListPath 生成 Makefile 使用 make 命令进行编译。make使用 编写CMakeList.txt文件基本版12345678910111213141516#CMake 最低版本号要求cmake_minimum_required (VERSION 2.8)#项目信息project (project_name)#指定生成目标add_executable(target_name main.c)#CMake 最低版本号要求cmake_minimum_required (VERSION 2.8)#项目信息project (project_name)# 使用变量set(SOURCE_FILES file1.c file2.c main.c)set（SOURCE_FILES file1.c file2.c main.c [apend ...]) # 追加方式添加#指定生成目标add_executable(target_name $&#123;SOURCE_FILES&#125;) 添加源文件目录1234# 添加源文件目录aux_source_directory(srcPath DIR_SRCS)# 指定生成目标add_executable(target_name $&#123;DIR_SRCS&#125;) 添加头文件目录12# 包含头文件目录include_directories(includeFilePath) 添加子目录子目录中也有有一个CMakeList.txt，子目录下生成一个链接库 12345# 查找当前目录源文件，将名称aux_source_directory(srcPath DIR_SRCS)# 生成链接库add_library(library_name $&#123;DIR_SRCS&#125;) 在主函数中添加链接库 123add_excutable(target_name $&#123;SRCS&#125;)# 在指定生成目标之后添加链接库target_link_library(target_name $&#123;library_name&#125;) 添加链接库12# 所有编译目标都链接的库link_libraries(library_name1 library_name2) 12# 指定动态链接库的搜索路径link_directories(DLLPath) 12# 添加链接库target_link_libraries(target_name $&#123;BOOST_LIBRARIES&#125;) 123# 在指定目录中搜索一个库，并且包含在变量中# 查找并添加动态库(添加一部分)find_library(MY_LIB library_name1 libraryPath) 其它text12# 设置编译参数add_definitions(&quot;-Wall -g&quot;) text12# 添加编译依赖add_dependencies() text1234567# 设置目标属性set_target_properties()# eg：set_target_properties($&#123;project_name&#125; PROPERTIES SOVERSION 0.0.1 PUBLIC_HEADER &quot;include/gtstack.h;include/gttypes.h&quot; ) text1234567# 设置版本号set(VERSION_MAJOR 1) # 最大的版本编号set(VERSION_MINOR 0) # 其次于major的版本号set(VERSION_PATCH 0) # 其次于minor的版本号set(VERSION_TWEAK 0) # 其次于patch的版本号# 版本号：MAJOR.MINOR.PATCH.TWEAK （semver语义化版本号的规则） text12# 输出信息message([SEND_ERROR | STATUS | FATAL_ERROR] “message to display”) 逻辑语法text12LESS,GREATER,EQUAL # 数字比较STRLESS、STRGREATER、STREQUAL # 字符串比较 text1234567if(CONDITION1)...elseif(CONDITION2)...else(CONDITION3)...endif text1234567891011121314151617# 1foreach(loop_var arg1 arg2...) ...endforeach(loop_var)# 2foreach(loop_var RANGE total) ...endforeach(loop_var)# 3foreach(loop_var RANGE start stop [step]) ...endforeach(loop_var)# 4foreach(loop_var IN [LISTS [list1 [...]]] [ITEMS [item1 [...]]]) ...endforeach(loop_var) text123while(CONDITION) ...endwhile(CONDITION) text1234# Logic operationif(FALSE AND (FALSE OR TRUE)) ...endif()","tags":[{"name":"编译","slug":"编译","permalink":"https://www.delta1037.cn/tags/%E7%BC%96%E8%AF%91/"}]},{"title":"Ping笔记(二)","date":"2017-08-23T16:00:00.000Z","path":"2017/Linux/Ping笔记(二)/","text":"Ping的c语言实现 函数介绍(续)重要的函数: socketint socket(int family, int type, int protocol); 返回值:成功时返回文件描述符 &#x2F; 失败时返回-1 头文件: #include &lt;sys&#x2F;socket.h&gt; 函数作用:创建一个套接字 一般为了执行网络I&#x2F;O，一个进程必须做的第一件事就是调用socket函数 函数参数第一个参数family：指明套接字中使用的协议族信息。 常见值有: 第二个参数type：指明套接口类型，也即套接字的数据传输方式。 常见值有: 在常见的使用socket进行网络编程中，经常使用SOCK_STREAM和SOCK_DGRAM，也就是TCP和UDP编程。在本项目中，我们将使用SOCK_RAW（原始套接字）。 原始套接字的主要作用在三个方面： 1.通过原始套接字发送&#x2F;接收 ICMP 协议包。 2.接收发向本级的，但 TCP&#x2F;IP 协议栈不能处理的IP包。 3.用来发送一些自己制定源地址特殊作用的IP包（自己写IP头）。 ping 命令使用的就是 ICMP 协议，因此我们不能直接通过建立一个 SOCK_STREAM或SOCK_DGRAM 来发送协议包，只能自己构建 ICMP 包通过 SOCK_RAW 来发送。 第三个参数 protocol：指明协议类型。 常见值有： 图片描述信息 参数 protocol 指明了所要接收的协议包。 如果指定了 IPPROTO_ICMP，则内核碰到ip头中 protocol 域和创建 socket 所使用参数 protocol 相同的 IP 包，就会交给我们创建的原始套接字来处理。 因此，一般来说，要想接收什么样的数据包，就应该在参数protocol里来指定相应的协议。当内核向我们创建的原始套接字交付数据包的时候，是包括整个IP头的，并且是已经重组好的IP包。如下所示： 图片描述信息 这里的数据也就是前面所说的时间戳。 但是，当我们发送IP包的时候，却不用自己处理IP首部，IP首部由内核自己维护，首部中的协议字段被设置成调用 socket 函数时传递给它的第三个参数。 我们发送 IP 包时，发送数据时从 IP 首部的第一个字节开始的，所以只需要构造一个如下所示的数据缓冲区就可以了。 图片描述信息 如果想自己处理 IP 首部，则需要设置 IP_HDRINCL 的 socket 选项，如下所示： int flag &#x3D; 1; setsocketopt(sockfd, IPPROTO_TO, IP_HDRINCL, &amp;flag, sizeof(int)); 此时，我们需要构造如下所示的数据缓冲区。 注意，我们自己填充 IP 首部时，也不是填充 IP 首部的所有字段，而是应该将 IP 首部的 id 字段设置为0，表示让内核来处理这个字段。同时，内核还会自动完成 IP 首部的校验和的计算并填充。 最后介绍发送和接收 IP 包的两个函数：recvfrom 和 sendto。 text123456789101112#include &lt;sys/socket.h&gt;ssize_t recvfrom(int sockfd, void * buff, size_t nbytes, int flags, struct sockaddr * from, socklen_t * addrlen);ssize_t sendto(int sockfd, const void * buff, size_t nbytes, int flags,const struct sockaddr * to, socklen_t addrlen);成功时返回读写的字节数，失败时返回-1。sockfd参数：套接字描述符。buff参数：指向读入或写出缓冲区的指针。nbytes参数：读写字节数。flags参数：本项目中设置为0。recvfrom 的 from 参数指向一个将由该函数在返回时填写数据发送者的地址信息的结构体，而该结构体中填写的字节数则放在 addrlen 参数所指的整数中。sendto 的 to 参数指向一个含有数据报接收者的地址信息的结构体，其大小由addrlen参数指定。 校验和算法检验和算法在 TCP&#x2F;IP 协议族中是比较常见的算法。 IP、ICMP、UDP和TCP报文头部都有校验和字段，不过IP、TCP、UDP只针对首部计算校验和， 而 ICMP 对首部和报文数据一起计算校验和。 检验和算法可以分成两步来实现。 首先在发送端，有以下三步： 1.把校验和字段置为0。 2.对需要校验的数据看成以16bit为单位的数字组成，依次进行二进制求和。 3.将上一步的求和结果取反，存入校验和字段。 其次在接收端，也有相应的三步： 1. 对需要校验的数据看成以16bit为单位的数字组成，依次进行二进制求和，包括校验和字段。 2. 将上一步的求和结果取反。 3. 判断最终结果是否为0。如果为0，说明校验和正确。如果不为0，则协议栈会丢掉接收到的数据。 从上可以看出，归根到底，校验和算法就是二进制反码求和。由于先取反后相加与先相加后取反，得到的结果是一样的，所以上面的步骤都是先求和后取反。 下面用C语言来实现校验和算法，代码如下： text12345678910111213141516171819202122/** * addr 指向需校验数据缓冲区的指针 * len 需校验数据的总长度（字节单位） */unsigned short checkSum(unsigned short *addr, int len)&#123; unsigned int sum = 0; while(len &gt; 1)&#123; sum += *addr++; len -= 2; &#125; // 处理剩下的一个字节 if(len == 1)&#123; sum += *(unsigned char *)addr; &#125; // 将32位的高16位与低16位相加 sum = (sum &gt;&gt; 16) + (sum &amp; 0xffff); sum += (sum &gt;&gt; 16); return (unsigned short) ~sum;&#125; 上面的代码首先定义了一个32位无符号整型的变量sum，用来保存16bit二进制数字相加的结果，由于16bit相加可能会产生进位，所以这里使用32位变量来保存结果，其中高16bit保存的是相加产生的进位。 然后下面的 while 循环，对数据按16bit累加求和。 接下来的if语句判断是否还剩下8bit（一字节）。如果校验的数据为奇数个字节，会剩下最后一字节。把最后一个字节视为一个2字节数据的高字节，这个2字节数据的低字节为0，继续累加。 之后的两行代码作用是将 sum 高16bit的值加到低16bit上，即把累加中最高位的进位加到最低位上。（sum &gt;&gt; 16）将高16bit右移到低16bit，（sum &amp; 0xffff）将高16bit全部置为0。注意，这两步都不会改变sum原来的值。 进行了两次相加可以保证 sum 高16bit都为0，没有进位了。 最后取反，并返回。 扩展： 为什么使用二进制反码求和，而不是原码或补码呢？ 这是因为，使用反码计算校验和比较简单和快速。对于网络通信来说，最重要的就是效率和速度。 编码实现整个程序的流程图如下所示： 图片描述信息 第一步，首先创建原始套接字。 第二步，封装 ICMP 报文，向目的IP地址发送 ICMP 报文，1秒后接收 ICM P响应报文，并打印 TTL，RTT。 第三步：循环第二步N次，本项目设置为5。 第四步:输出统计信息。 栗子:text123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/time.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;netdb.h&gt;#define ICMP_SIZE (sizeof(struct icmp))#define ICMP_ECHO 8#define ICMP_ECHOREPLY 0#define BUF_SIZE 1024#define NUM 5 // 发送报文次数#define UCHAR unsigned char#define USHORT unsigned short#define UINT unsigned int// ICMP报文数据结构struct icmp&#123; UCHAR type; // 类型 UCHAR code; // 代码 USHORT checksum; // 校验和 USHORT id; // 标识符 USHORT sequence; // 序号 struct timeval timestamp; // 时间戳&#125;;// IP首部数据结构struct ip&#123; // 主机字节序判断 #if __BYTE_ORDER == __LITTLE_ENDIAN UCHAR hlen:4; // 首部长度 UCHAR version:4; // 版本 #endif #if __BYTE_ORDER == __BIG_ENDIAN UCHAR version:4; UCHAR hlen:4; #endif UCHAR tos; // 服务类型 USHORT len; // 总长度 USHORT id; // 标识符 USHORT offset; // 标志和片偏移 UCHAR ttl; // 生存时间 UCHAR protocol; // 协议 USHORT checksum; // 校验和 struct in_addr ipsrc; // 32位源ip地址 struct in_addr ipdst; // 32位目的ip地址&#125;;char buf[BUF_SIZE] = &#123;0&#125;;USHORT checkSum(USHORT *, int); // 计算校验和float timediff(struct timeval *, struct timeval *); // 计算时间差void pack(struct icmp *, int); // 封装一个ICMP报文int unpack(char *, int, char *); // 对接收到的IP报文进行解包int main(int argc, char * argv[])&#123; struct hostent *host; struct icmp sendicmp; struct sockaddr_in from; struct sockaddr_in to; int fromlen = 0; int sockfd; int nsend = 0; int nreceived = 0; int i, n; in_addr_t inaddr; memset(&amp;from, 0, sizeof(struct sockaddr_in)); memset(&amp;to, 0, sizeof(struct sockaddr_in)); if(argc &lt; 2)&#123; printf(&quot;use : %s hostname/IP address \\n&quot;, argv[0]); exit(1); &#125; // 生成原始套接字 if((sockfd = socket(AF_INET, SOCK_RAW, IPPROTO_ICMP)) == -1)&#123; printf(&quot;socket() error \\n&quot;); exit(1); &#125; // 设置目的地址信息 to.sin_family = AF_INET; // 判断是域名还是ip地址 if(inaddr = inet_addr(argv[1]) == INADDR_NONE)&#123; // 是域名 if((host = gethostbyname(argv[1])) == NULL)&#123; printf(&quot;gethostbyname() error \\n&quot;); exit(1); &#125; to.sin_addr = *(struct in_addr *)host-&gt;h_addr_list[0]; &#125;else&#123; // 是ip地址 to.sin_addr.s_addr = inaddr; &#125; // 输出域名ip地址信息 printf(&quot;ping %s (%s) : %d bytes of data.\\n&quot;, argv[1], inet_ntoa(to.sin_addr), (int)ICMP_SIZE); //循环发送报文、接收报文 for(i = 0; i &lt; NUM; i++)&#123; nsend++; // 发送次数加1 memset(&amp;sendicmp, 0, ICMP_SIZE); pack(&amp;sendicmp, nsend); // 发送报文 if(sendto(sockfd, &amp;sendicmp, ICMP_SIZE, 0, (struct sockaddr *)&amp;to, sizeof(to)) == -1)&#123; printf(&quot;sendto() error \\n&quot;); continue; &#125; // 接收报文 if((n = recvfrom(sockfd, buf, BUF_SIZE, 0, (struct sockaddr *)&amp;from, &amp;fromlen)) &lt; 0)&#123; printf(&quot;recvform() error \\n&quot;); continue; &#125; nreceived++; // 接收次数加1 if(unpack(buf, n, inet_ntoa(from.sin_addr)) == -1)&#123; printf(&quot;unpack() error \\n&quot;); &#125; sleep(1); &#125; // 输出统计信息 printf(&quot;--- %s ping statistics ---\\n&quot;, argv[1]); printf(&quot;%d packets transmitted, %d received, %%%d packet loss\\n&quot;, nsend, nreceived, (nsend - nreceived) / nsend * 100); return 0;&#125;/** * addr 指向需校验数据缓冲区的指针 * len 需校验数据的总长度（字节单位） */USHORT checkSum(USHORT *addr, int len)&#123; UINT sum = 0; while(len &gt; 1)&#123; sum += *addr++; len -= 2; &#125; // 处理剩下的一个字节 if(len == 1)&#123; sum += *(UCHAR *)addr; &#125; // 将32位的高16位与低16位相加 sum = (sum &gt;&gt; 16) + (sum &amp; 0xffff); sum += (sum &gt;&gt; 16); return (USHORT) ~sum;&#125;/** * 返回值单位：ms * begin 开始时间戳 * end 结束时间戳 */float timediff(struct timeval *begin, struct timeval *end)&#123; int n; // 先计算两个时间点相差多少微秒 n = ( end-&gt;tv_sec - begin-&gt;tv_sec ) * 1000000 + ( end-&gt;tv_usec - begin-&gt;tv_usec ); // 转化为毫秒返回 return (float) (n / 1000);&#125;/** * icmp 指向需要封装的ICMP报文结构体的指针 * sequence 该报文的序号 */void pack(struct icmp * icmp, int sequence)&#123; icmp-&gt;type = ICMP_ECHO; icmp-&gt;code = 0; icmp-&gt;checksum = 0; icmp-&gt;id = getpid(); icmp-&gt;sequence = sequence; gettimeofday(&amp;icmp-&gt;timestamp, 0); icmp-&gt;checksum = checkSum((USHORT *)icmp, ICMP_SIZE);&#125;/** * buf 指向接收到的IP报文缓冲区的指针 * len 接收到的IP报文长度 * addr 发送ICMP报文响应的主机IP地址 */int unpack(char * buf, int len, char * addr)&#123; int i, ipheadlen; struct ip * ip; struct icmp * icmp; float rtt; // 记录往返时间 struct timeval end; // 记录接收报文的时间戳 ip = (struct ip *)buf; // 计算ip首部长度，即ip首部的长度标识乘4 ipheadlen = ip-&gt;hlen &lt;&lt; 2; // 越过ip首部，指向ICMP报文 icmp = (struct icmp *)(buf + ipheadlen); // ICMP报文的总长度 len -= ipheadlen; // 如果小于ICMP报文首部长度8 if(len &lt; 8)&#123; printf(&quot;ICMP packets\\&#x27;s length is less than 8 \\n&quot;); return -1; &#125; // 确保是我们所发的ICMP ECHO回应 if(icmp-&gt;type != ICMP_ECHOREPLY || icmp-&gt;id != getpid())&#123; printf(&quot;ICMP packets are not send by us \\n&quot;); return -1; &#125; // 计算往返时间 gettimeofday(&amp;end, 0); rtt = timediff(&amp;icmp-&gt;timestamp, &amp;end); // 打印ttl，rtt，seq printf(&quot;%d bytes from %s : icmp_seq=%u ttl=%d rtt=%fms \\n&quot;, len, addr, icmp-&gt;sequence, ip-&gt;ttl, rtt); return 0; 执行提示 socket() error 错误，也就是调用 socket 函数的时候出现了错误。这是因为我们创建的是原始套接字，原始套接字必须有 root 权限才能创建，所以我们可以加 sudo 执行 Ping笔记(一) 参考文献参考文献一","tags":[{"name":"Ping","slug":"Ping","permalink":"https://www.delta1037.cn/tags/Ping/"}]},{"title":"Ping笔记(一)","date":"2017-08-23T16:00:00.000Z","path":"2017/Linux/Ping笔记(一)/","text":"Ping的c语言实现 Ping和ICMPPing简介:ping 命令是用来查看网络上另一个主机系统的网络连接是否正常的一个工具 ping类似于声呐系统: ping 命令使用回显请求和回显应答消息。具体表现是向网络上的另一个主机系统发送 ICMP 报文，如果指定系统得到了报文，它将把报文一模一样地传回给发送者 ping 命令所使用到的 TCP&#x2F;IP 协议：ICMP 协议 ping执行后的返回内容 : 1.显示出被测试系统主机名和相应 IP 地址 111.13.101.208 (111.13.101.208) 2.返回给当前主机的 ICMP 报文顺序号 icmp_seq&#x3D;3 3.ttl 生存时间和往返时间 rtt（单位是毫秒，即千分之一秒) ttl&#x3D;51 time&#x3D;16.6 ms 以ping baidu.com为例: 64 bytes from 111.13.101.208 (111.13.101.208): icmp_seq&#x3D;1 ttl&#x3D;51 time&#x3D;16.4 ms 64 bytes from 111.13.101.208 (111.13.101.208): icmp_seq&#x3D;2 ttl&#x3D;51 time&#x3D;17.3 ms 64 bytes from 111.13.101.208 (111.13.101.208): icmp_seq&#x3D;3 ttl&#x3D;51 time&#x3D;16.6 ms ICMP介绍ICMP 是（Internet Control Message Protocol）Internet 控制报文协议。它是 TCP&#x2F;IP 协议族的一个子协议，用于在 IP 主机、路由器之间传递控制消息。 - 控制消息有：目的不可达消息，超时信息，重定向消息，时间戳请求和时间戳响应消息，回显请求和回显应答消息 注意ICMP协议是-IP层-的一个协议，。这是因为ICMP报文在发送给报文接收方时可能要经过若干子网，会牵涉到路由选择等问题，所以ICMP报文需通过IP协议来发送，是IP层的 ICMP报文格式:1.回显 请求 报文其中类型为 0，代码为 0。 2.回显 应答 报文其中类型为 8，代码为 0。 3.校验和字段：包括数据在内的整个 ICMP 协议数据包的校验和，具体实现方法会在下面详细介绍。 4.标识符字段：用于唯一标识 ICMP 报文，本项目使用程序的进程 id。因为如果同时在两个命令行终端执行 ping 命令的话， 每个 ping 命令都会接收到所有的回显应答，所以需要根据标识符来判断回显应答是否应该接收。 5.序号字段：ICMP 报文的序号。 6.数据字段：也就是报文，本项目中我们将发送报文的时间戳放入数据字段，这样当接收到该报文应答的时候可以取出发送时间戳， 将接收应答的时间戳减去发送时间戳就是报文往返时间（rtt）。提前预告一下，这里使用gettimeofday()API函数获取时间戳，详细介绍会在函数介绍部分说明。 - c语言数据结构表示: ICMP 报文 C 语言实现可以用下面的数据结构表示： struct icmp{ unsigned char type; &#x2F;&#x2F; 类型 unsigned char code; &#x2F;&#x2F; 代码 unsigned short checksum; &#x2F;&#x2F; 校验和 unsigned short id; &#x2F;&#x2F; 标识符 unsigned short sequence; &#x2F;&#x2F; 序号 struct timeval timestamp; &#x2F;&#x2F; 时间戳 }; unsigned char 正好一字节，也就是 8bit，unsigned short 二字节，也就是 16bit，unsigned int4 字节（32bit）， 不过上面没用到。其中 struct timeval 类型可能有人不清楚，不过没关系，函数部分说明。 IP报文首部C语言实现的数据结构表示 &gt; struct ip{ unsigned char version:4; &#x2F;&#x2F; 版本 unsigned char hlen:4; &#x2F;&#x2F; 首部长度 unsigned char tos; &#x2F;&#x2F; 服务类型 unsigned short len; &#x2F;&#x2F; 总长度 unsigned short id; &#x2F;&#x2F; 标识符 unsigned short offset; &#x2F;&#x2F; 标志和片偏移 unsigned char ttl; &#x2F;&#x2F; 生存时间 unsigned char protocol; &#x2F;&#x2F; 协议 unsigned short checksum; &#x2F;&#x2F; 校验和 struct in_addr ipsrc; &#x2F;&#x2F; 32位源ip地址 struct in_addr ipdst; &#x2F;&#x2F; 32位目的ip地址 }; 地址信息表示编写网络应用程序时,要使用地址信息指定数据传输给哪个主机 地址信息内容 1.地址族，基于IPv4的地址族还是IPv6的地址族。 2.IP地址。 3.端口号。 地址信息的结构体(一) struct sockaddr_in{ sa_family_t sin_family; &#x2F;&#x2F; 地址族 uint16_t sin_port; &#x2F;&#x2F; 端口号 struct in_addr sin_addr; &#x2F;&#x2F; 32位IP地址 char sin_zero[8]; &#x2F;&#x2F; 不使用 }; 其中struct in_addr结构体定义如下： struct in_addr{ in_addr_t s_addr; &#x2F;&#x2F; 32位IP地址 }; in_addr_t使用如下宏指令定义，也就是无符号整型32位。 #define in_addr_t uint32_t 地址信息的结构体(二) struct sockaddr{ sa_family_t sin_family; &#x2F;&#x2F; 地址族 char sa_data[14]; &#x2F;&#x2F; IP地址和端口 }; 成员sa_data保存的信息包含 IP 地址和端口号，剩余部分填充0。 网络编程中常用struct sockaddr_in,因为填充数据更方便 网络编程接口函数定义使用的是struct sockaddr,因为它是最先开始使用的 两个结构体之间的转换: 定义地址信息时使用 struct sockaddr_in 结构体，然后将该结构体类型转为 struct sockaddr 结构体类型传递给网络编程接口函数 字节顺序的转换主机字节序与网络字节序在不同 CPU 中，4字节整型数值1在内存空间的保存方式是不同的。 4字节整型数值1可用二进制表示如下： 00000000 00000000 00000000 00000001 而有些CPU则以倒序保存 00000001 00000000 00000000 00000000 所以，如果发送主机与接收主机CPU字节序不一样则就会出现问题。 引申上面的问题，这就涉及到CPU解析数据的方式，其方式有2种： - 大端序（Big Endian）：高位字节存放到低位地址。 - 小端序（Little Endian）：高位字节存放到高位地址。由于不同CPU字节序不一样，因此，在通过网络传输数据时约定统一方式，这种约定称为网络字节序（Network Byte Order），非常简单——统一为大端序。 所以，进行网络传输数据前，需要先把数据数组转化为 大端序 格式再进行网络传输。接收到网络数据后，需要转换本机字节序格式然后进行后续处理。不过，幸运地是这些工作不需要我们自己完成，系统会自动转换的。 用到字节序转换的地方我们唯一需要转换的是向struct sockaddr_in结构体变量填充IP地址和端口号数据的时候。当然，系统已经提供了一些函数，只需调用相应函数即可。 转换字节序的函数有： unsigned short htons(unsigned short); unsigned short ntohs(unsigned short); unsigned long htonl(unsigned long); unsigned long ntohl(unsigned long); 上面的函数非常简单，通过函数名就能知道它们的功能， htonl&#x2F;htons 中的h代表主机（host）字节序，n代表网络（network）字节序，s指的是 short，l指的是 long （需要注意一下，linux 中 long 类型只占4个字节，跟int类型一样）。 示例: text1234567891011121314151617181920#include &lt;stdio.h&gt;#include &lt;arpa/inet.h&gt;int main(void)&#123; unsigned short hosts = 0x1234; unsigned short nets; unsigned long hostl = 0x12345678; unsigned long netl; nets = htons(hosts); netl = htonl(hostl); printf(&quot;Host ordered short: %#x \\n&quot;, hosts); printf(&quot;Network ordered short: %#x \\n&quot;, nets); printf(&quot;Host ordered long: %#lx \\n&quot;, hostl); printf(&quot;Network ordered long: %#lx \\n&quot;, netl); return 0;&#125; 大家通过上面的程序也可以判断自己主机是大端序的还是小端序的,Intel 系列 CPU 采用的都是小端序标准 函数介绍函数gettimeofday()#include &lt;sys&#x2F;time.h&gt; int gettimeofday(struct timeval *tv, struct timezone *tz); 该函数的作用是把当前的时间放入 struct timeval 结构体中返回。 注意： 1.精确级别,微秒级别 2.受系统时间修改影响 3.返回的秒数是从1970年1月1日0时0分0秒开始 其参数 tv 是保存获取时间结果的结构体，参数 tz 用于保存时区结果。 结构体 timeval 的定义为： struct timeval { long int tv_sec; &#x2F;&#x2F; 秒数 long int tv_usec; &#x2F;&#x2F; 微秒数 } 结构体timezone的定义为： struct timezone { int tz_minuteswest;&#x2F;格林威治时间往西方的时差&#x2F; int tz_dsttime; &#x2F;DST 时间的修正方式&#x2F; } timezone 参数若不使用则传入0即可，本项目传入0。 text1234567891011121314151617181920212223242526272829303132333435/** * 本程序实现计算程序运行时间 */#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/time.h&gt;// 计算时间差，单位：msfloat timediff(struct timeval *begin, struct timeval *end)&#123; int n; // 先计算两个时间点相差多少微秒 n = ( end-&gt;tv_sec - begin-&gt;tv_sec ) * 1000000 + ( end-&gt;tv_usec - begin-&gt;tv_usec ); // 转化为毫秒返回 return (float) (n / 1000);&#125;int main(void)&#123; struct timeval begin, end; gettimeofday(&amp;begin, 0); // 这里让程序挂起一秒 printf(&quot;do something here...&quot;); sleep(1); gettimeofday(&amp;end, 0); printf(&quot;running time : %fms\\n&quot;, timediff(&amp;begin, &amp;end)); return 0;&#125; 大约都运行了1秒钟时间。但有时候多1毫秒，有时候又恰好1秒。这是因为系统中运行的程序不只本程序一个，有时候恰好遇到内核进行进程切换需要时间 inet_addr 函数#include &lt;arpa&#x2F;inet.h&gt; in_addr_t inet_addr(const char *string); 该函数的作用是将用点分十进制字符串格式表示的IP地址转换成32位大端序整型。 成功时返回32位大端序整型数值，失败时返回 INADDR_NONE 。 简单的示例: text1234567891011121314151617#include &lt;stdio.h&gt;#include &lt;arpa/inet.h&gt;int main(void)&#123; char *addr1 = &quot;1.2.3.4&quot;; char *addr2 = &quot;192.168.1.1&quot;; in_addr_t data; data = inet_addr(addr1); printf(&quot; %s -&gt; %#lx \\n&quot;, addr1, (long)data ); data = inet_addr(addr2); printf(&quot; %s -&gt; %#lx \\n&quot;, addr2, (long)data ); return 0;&#125; inet_ntoa 函数char * inet_ntoa(struct in_addr addr); 该函数的作用与 inet_addr 正好相反。将32位大端序整型格式IP地址转换为点分十进制格式。 成功时返回转换的字符串地址值，失败时返回-1。 简单的示例 text123456789101112131415161718#include &lt;stdio.h&gt;#include &lt;arpa/inet.h&gt;int main(void)&#123; struct in_addr addr1, addr2; char * str1, * str2; addr1.s_addr = htonl(0x1020304); addr2.s_addr = htonl(0xc0a80101); str1 = inet_ntoa(addr1); str2 = inet_ntoa(addr2); printf(&quot;%#lx -&gt; %s \\n&quot;, (long)addr1.s_addr, str1); printf(&quot;%#lx -&gt; %s \\n&quot;, (long)addr2.s_addr, str2); return 0;&#125; 函数两次执行的结果怎么是一样的，其实这是 C 语言编程中常会出现的陷阱。 我们可以再看下上面函数的定义，注意该函数返回值类型为 char 指针类型，大家看出端倪了吗？ inet_addr函数在执行过程中，在内部会申请内存并保存结果字符串，然后返回内存地址。所以调用完该函数应该将字符串复制到其他内存空间。 因为再次调用该函数时，之前保存的字符串很有可能被覆盖。知道了原因，大家可以动手修改上面的代码了。 首先定义一个接收缓冲区 char buf[20]; ，然后使用 memcpy(buf, str1, sizeof(str)) 将 inet_ntoa 函数生成的字符串保存缓冲区。 记住，memcpy 函数在头文件 #include &lt;string.h&gt; 中声明的，需要加上这个头文件。 函数 gethostbyname –根据域名获取IP地址#include &lt;netdb.h&gt; struct hostent * gethostbyname(const char * hostname); 成功时返回hostent结构体地址，失败时返回NULL指针。 struct hosten结构体定义如下： struct hostent{ char * h_name; char ** h_aliases; char h_addrtype; char h_length; char ** h_addr_list; }; 我们最关心的是h_addr_list成员，它保存的就是域名对应IP地址。由于一个域名对应的IP地址不止一个，所以h_addr_list成员是char **类型，相当于二维字符数组。 下面通过一张图来表示h_addr_list成员的参数，希望大家可以加深对hostent结构体的理解。 图片描述信息 简单的示例 text123456789101112131415161718192021222324#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;netdb.h&gt;int main(int argc, char *argv[])&#123; int i; struct hostent *host; if(argc &lt; 2)&#123; printf(&quot;Use : %s &lt;hostname&gt; \\n&quot;, argv[0]); exit(1); &#125; host = gethostbyname(argv[1]); for(i = 0; host-&gt;h_addr_list[i]; i++)&#123; printf(&quot;IP addr %d : %s \\n&quot;, i+1, inet_ntoa(*(struct in_addr *)host-&gt;h_addr_list[i])); &#125; return 0;&#125; 上面代码中，打印IP地址是出现了令人困惑的类型转换。 host-&gt;h_addr_list[i]得到的是字符串指针，但该字符串指针实际指向的是struct in_addr结构体变量地址值。 (struct in_addr *)host-&gt;h_addr_list[i]将字符串指针转换为struct in_addr结构体指针。 由于inet_ntoa参数类型是struct in_addr而不是struct in_addr ，所以用运算符取出struct in_addr结构体的值。 Ping笔记(二) 参考文献参考文献一","tags":[{"name":"Ping","slug":"Ping","permalink":"https://www.delta1037.cn/tags/Ping/"}]},{"title":"Makefile笔记","date":"2017-08-22T16:00:00.000Z","path":"2017/C_C++/Makefile笔记/","text":"Makefile笔记 makefile用来制定编译的规则及其其它更复杂的操作。并且能实现整个工程的自动化编译，提高编译效率 一、基础语法123# Makefile 格式:target : prerequisites &lt;tab&gt; command 目标：target 文件名 : 可以是多个，即使是最终目标文件 操作的名字：伪目标 通过 .PHONY 来声明clean是一个伪目标，而不是一个目标文件,例： 123.PHONY: cleanclean: rm *.o temp 前置条件：prerequisites一组文件名 ： 用空格分开 只要有一个前置条件的文件有过更新，目标就要重新构建 命令：command由一行或者多行的shell命令组成，命令之前必须有tab键 1. 每行命令在一个单独的shell中执行，这些shell之间没有继承关系 2. 多行命令依赖解决： 1、加上.ONESHELL: 2、 用逗号分隔 3、添加换行转义 二、其它注释text123# 这是注释target : prerequisites &lt;tab&gt; command 回声 echoing在执行每一条命令时都会在终端打印这条命令，在命令之前加上@可以关闭 通配符Makefile通配符与bash一致，主要有： : 可以匹配任何字符 ？: 匹配任意单个字符 […] : 匹配一个单字符范围, 模式匹配对文件名进行类似正则运算的匹配,适应于大量同类型的文件 1%.o : %.c 变量变量可以用等号赋值，访问时可以使用$(Variable)来访问 所以在使用美元符号的时候可以使用$$来转义 赋值： 1234567891011VARIABLE = value# 在执行时扩展，允许递归扩展。VARIABLE := value# 在定义时扩展。VARIABLE ?= value# 只有在该变量为空时才设置值。VARIABLE += value# 将值追加到变量的尾端。 内置变量 $(CC) ： 指向当前使用的编译器 $(MAKE) ：指向当前使用的Make工具 自动变量 $@ : 指代当前需要生成的目标 $&lt; ： 指代第一个前置条件 $? ： 指代比目标更新的所有前置条件 $^ ： 指代所有前置条件 判断和循环判断 12345ifeq ($(CC),gcc) libs=$(libs_for_gcc)else libs=$(normal_libs)endif 循环 12345LIST = one two threeall: for i in $(LIST); do \\ echo $$i; \\ done 函数格式 123$(function arguments)# 或者$&#123;function arguments&#125; shell函数1srcfiles := $(shell echo src/&#123;00..99&#125;.txt) wildcard函数1srcfiles := $(wildcard src/*.txt) subst 函数1$(subst from,to,text) patsubst函数1$(patsubst pattern,replacement,text) 替换后缀名1min: $(OUTPUT:.js=.min.js) Makefile 执行通过make命令工具来解释makefile中的指令,makefile告诉make需要怎么去编译和链接目标程序,make还能根据当前文件情况确定哪些文件需要重新编译 1$ make # 自动寻找Makefile 1$ make -f Makefile 1$ make --file=Makefile 附：编译和链接基本流程 源文件–编译–&gt;中间文件 中间文件–链接–&gt;可执行文件 编译链接细节 编译时，编译器需要的是语法，函数与变量的声明是否正确，只要正确就能生成中间文件 链接时，主要是链接函数和全局变量，连接时只管中间目标文件 在中间文件过多时，可以给中间文件打包 注中间文件： Windows：*.obj UNIX ： *.o 打包文件： Window ： 库文件（Library File) .lib Unix ： Archive File， .a 参考文献参考博客","tags":[{"name":"编译","slug":"编译","permalink":"https://www.delta1037.cn/tags/%E7%BC%96%E8%AF%91/"}]},{"title":"Linux Socket笔记","date":"2017-08-21T16:00:00.000Z","path":"2017/CN/LinuxSocket笔记/","text":"C Socket学习样例：使用代码记录基础的执行流程 源代码客户端代码1234567891011121314151617181920212223242526272829303132#include &lt;stdio.h&gt;#include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;#include &lt;string.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;zconf.h&gt;int main() &#123; //创建套接字 int sock=socket(AF_INET,SOCK_STREAM,0); //向特定的服务器发起请求 struct sockaddr_in serv_addr; memset(&amp;serv_addr,0,sizeof(serv_addr));//用0填充每个字节 serv_addr.sin_family=AF_INET; //使用ipv4 serv_addr.sin_addr.s_addr=inet_addr(&quot;127.0.0.1&quot;); serv_addr.sin_port=htons(1234); //端口 // 连接服务端 connect(sock,(struct sockaddr*)&amp;serv_addr,sizeof(serv_addr)); //读取服务器传回的数据 char buffer[40]; read(sock,buffer,sizeof(buffer)-1); printf(&quot;Message from server:%s\\n&quot;,buffer); //关闭套接字 close(sock); return 0;&#125; 服务端代码123456789101112131415161718192021222324252627282930313233343536#include &lt;stdio.h&gt;#include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;#include &lt;string.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;zconf.h&gt;int main() &#123; //创建 int serv_sock =socket(AF_INET,SOCK_STREAM,IPPROTO_TCP); //将套接字绑定ip,端口 struct sockaddr_in serv_addr; memset(&amp;serv_addr,0,sizeof(serv_addr)); //填充每个字节用0 serv_addr.sin_family=AF_INET; //使用ipv4 serv_addr.sin_addr.s_addr=inet_addr(&quot;127.0.0.1&quot;); //本机(即服务器)IP地址 serv_addr.sin_port=htons(1234); //使用的端口 bind(serv_sock,(struct sockaddr*)&amp;serv_addr, sizeof(serv_addr)); //开始监听 listen(serv_sock,20); //接收客户端请求 struct sockaddr_in clnt_addr; socklen_t clnt_addr_size =sizeof(clnt_addr); int clnt_sock=accept(serv_sock,(struct sockaddr*)&amp;clnt_addr,&amp;clnt_addr_size); //向客户端发送数据 char str[]=&quot;hello world&quot;; write(clnt_sock,str,sizeof(str)); //关闭套接字 close(clnt_sock); close(serv_sock); return 0;&#125;","tags":[{"name":"Socket","slug":"Socket","permalink":"https://www.delta1037.cn/tags/Socket/"}]},{"title":"Shell脚本样例","date":"2017-08-21T16:00:00.000Z","path":"2017/Linux/Shell脚本样例/","text":"Shell脚本样例： 文件夹排序：对 当前目录&#x2F;当前目录+子目录 按照文件名排序 非递归阶乘：非递归的阶乘问题（考虑到$?返回值无法返回大数字） 文件解压：支持zip、tar、tar.gz、tar.bz2压缩文件类型的解压 获得某个目录下前N个最大的文件：获得指定或默认目录下的前N个文件或者所有文件 一、文件夹排序脚本1.1对当前目录对当前目录所有的文件夹名称及其文件名称进行排序的操作 1234567891011121314#/bin/bash#对文件路径的本目录的所有文件的文件名进行排序path=$1files=$(ls $path)for filename in $files #循环遍历当前文件夹内的所有文件名及其文件夹名do echo $filename&gt;&gt;sort.txt #将输出的文件名重定向到test.txtdoneecho &quot;排序之后:&quot;sort test.txt #对文件排序并输出rm test.txt #删除文件 1.2对当前目录及其子目录对当前目录及其子目录所有的文件夹名称及其文件名称进行排序的操作 123456789101112131415161718#!/bin/bash#对文件路径本目录及其所有子目录文件名排序function ergodic()&#123; for filename in $(ls $1) #循环遍历当前文件夹内的所有文件名及其文件夹名 do if [ -d $1&quot;/&quot;$filename ] #判断是否存在子目录 then ergodic $1&quot;/&quot;$filename #对函数ergodic进行递归调用 else echo $filename&gt;&gt;test.txt #将输出的文件名重定向到test.txt fi done&#125;ergodic $1 #函数开始执行的位置,$1为输入的第一个参数echo &quot;排序之后:&quot;sort test.txt #对文件排序并输出rm test.txt #删除文件 二、非递归阶乘1234567891011121314151617181920212223242526#!/bin/bash# 计算阶乘# 由于$?无法返回大数字,使用全局变量存储返回的值let result=0let localreturn=0funFactorial()&#123; let num1=1 if [ $1 -gt $num1 ]; then let numSub=$1-1 funFactorial $numSub let result=$localreturn*$1 let localreturn=$result else let result=1 let localreturn=1; fi&#125;if [ -n &quot;$1&quot; ]; then funFactorial $1 echo result:$resultelse echo &quot;usage: factorial.sh [n]&quot; echo &quot;calculates a number&#x27;s factorial&quot;fi 三、文件解压1234567891011121314151617181920212223242526272829303132#!/bin/bash# usage: self_compression.sh [--list] or [source compressd file] [destination path]# self compression accroding to file name suffix# 不存在参数if [ &quot;&quot; = &quot;$1&quot; ]; then echo &quot;usage: self_compression.sh [--list] or [source compressd file] [destination path]&quot; echo &quot;self compression accroding to file name suffix&quot;else # 有参数 --list if [ &quot;--list&quot; = &quot;$1&quot; ]; then echo &quot;Support file types:zip tar tar.gz tar.bz2&quot; # 选择文件类型&amp;解压缩文件 else # get type file=$1 type=$&#123;file##*.&#125; # Choose type &amp; unzip if [ &quot;$type&quot; = &quot;zip&quot; ]; then unzip $1 -d $2 elif [ &quot;$type&quot; = &quot;tar&quot; ]; then tar -xf $1 -C $2 elif [ &quot;$type&quot; = &quot;gz&quot; ]; then tar -xzvf $1 -C $2 elif [ &quot;$type&quot; = &quot;bz2&quot; ]; then tar -xjvf $1 -C $2 else echo &quot;$type Not Suport!!&quot; fi fifi 四、获得某个目录下前N个最大的文件1234567891011121314151617181920212223#!/bin/bash# echo &quot;usage:file_size_get.sh [-n N] [-d DIR]&quot;# echo &quot;show top N largest files/directories&quot;# 获得指定或默认目录下的前N个文件或者所有文件# 存在参数if [ -n &quot;$1&quot; -o -n &quot;$3&quot; ];then # 有两个参数 if [ -n &quot;$1&quot; -a -n &quot;$3&quot; ];then du -ak $4 | sort -nr | head -$2 &gt; test.txt # 只有参数-n elif [ &quot;-n&quot; = &quot;$1&quot; ];then du -ak | sort -nr | head -$2 &gt; test.txt # 只有参数-d else du -ak $2 | sort -nr &gt; test.txt fi# 不存在参数else du -ah | sort -nr &gt; test.txtficat -n test.txtrm test.txt","tags":[{"name":"Shell","slug":"Shell","permalink":"https://www.delta1037.cn/tags/Shell/"}]},{"title":"算法导论笔记","date":"2017-08-07T16:00:00.000Z","path":"2017/Algorithm/算法导论笔记/","text":"算法导论记录：动态规划、贪心算法与图 一、动态规划概念：动态规划（dynamic programming&#x2F;DP）中的programming指的是一种表格法，并非编写计算机程序 动态规划应用于子问题重叠的情况，即不同的子问题有公共的子子问题 动态规划的设计： 1.刻画最优解的结构特征 2.递归地定义最优解的值 3.计算最优解的值（通常采用自底向上的方法） 4.利用计算出的信息构造一个最优解 朴素的递归算法由于反复求解相同的子问题而效率低下；动态规划对每个子问题只求解一次，，并将其保存下来，如果再次需要这个子问题的解，只需要查找保存的结果 动态规划两种等价的实现方法： 1.带备忘的自顶向下法 仍然按自然递归的形式编写过程，但是过程会保存每个子问题的解，当需要某个子问题的解时，会先进行查找是否有这个解，否则会计算这个解，并保存 2.自低向上法（按照逆拓扑排序，反序的拓扑排序）（自底向上表格法） 当求解某个子问题时，它所依赖的那些更小的子问题都已经求解完毕 动态规划的标识： 1.最优子结构 2.子问题重叠 剪切-粘贴：假定子问题的解不是其自身的最优解，那么我们可以剪切掉这些非最优解，将最优解粘贴进去，从而可以得到原问题的一个更优的解，这与原问题是最优解的假设是矛盾的 子问题无关：同一个原问题的一个子问题的解不影响另一个子问题的解 重叠子问题的性质：递归算法反复求解相同的子问题 如果每个子问题必须求解一次，自底向上动态规划算法会比自顶向下备忘算法快，因为自底向上算法没有递归调用的开销；如果子问题中的某些子问题不需要求解，自顶向下备忘算法就比较快 动态规划求解：找到状态转移方程和状态 二、贪心算法概念：贪心算法每一步在当时看起来是最佳的选择，总是做出局部最优的选择 贪心算法并不保证得到最优解，但对于很多问题可以得到最优解 首先考虑用动态规划算法，然后证明一直做贪心的选择可以得到最优解，从而得到一个贪心算法 贪心算法步骤： 确定问题的最优子结构 将最优化问题转化为对其做出一次选择之后，只剩下一个子问题需要求解的形式 证明做出贪心选择之后，原问题总是存在最优解，即贪心选择总是安全的 证明做出贪心选择之后，剩余的子问题满足性质： 最优解和贪心选择组合即可得到原问题的最优解，这样就得到了最优子结构 贪心算法进行选择时可能依赖之前做出的选择，但是不会依赖将来的选择或者是子问题的解 三、图3.1 图的表示 邻接链表：适用于稀疏图 邻接矩阵：适用于稠密图 邻接链表无法迅速判断一条边是否是图中的一条边（邻接矩阵则可以，但是消耗了更多的内存空间），如果使用邻接链表来表示图，一种可能的方法是用额外的数组来表示节点属性 3.2 图的遍历3.2.1 广度优先搜索：广度优先搜索树中两个节点的简单路径就是这两个节点间的最短路径 用队列来实现广度优先搜索 广度优先搜索将每个节点涂上黑色&#x2F;灰色&#x2F;白色，遇到白色节点为发现，对于灰色节点，该节点周围肯能存在尚未发现的节点，对于黑色节点，该节点周围所有的节点都已经被发现 队列里面的距离差值最大为一 对图进行广度优先搜索的过程中将创建一棵广度优先搜索树 3.2.2 深度优先搜索：深度优先搜索的前驱子图形成一个由多棵深度优先树构成的深度优先森林 若深度优先搜索中一个节点周围没有节点，则会回退到上一个节点，然后发现该节点周围的节点 发现时间和完成时间具有括号化结构（即嵌套）： 深度优先搜索在每个节点上面盖一个时间戳，一个是发现时间，第二个是搜索完成时间，对两个节点的时间戳，若重叠则必定是包含关系 边的分类： 树边&#x2F;后向边&#x2F;前向边&#x2F;横向边 对无向图，从来不会出现前向边和横向边 拓扑排序： 拓扑排序是图中节点的一种线性排序，其次若图中有环路则无法排出一个线性次序 与深度优先搜索有关 强连通分量：深度优先搜索的应用：将有向图分解为强连通分量 将图分解成强连通分量之后，这些算法将运行在每个连通分量上，然后根据连通分量之间的结构将各个结果组合起来，从而得到最终结果 强连通分量就是将环收缩，形成一个有向无环图 寻找强连通分量，图和改图的转置的强连通分量完全相同 分量图是一个有向无环图 单源最短路径单源最短路径的子路径也是最短路径 单源最短路径包含着其它的最短路径（最优子结构） 求解最短路径的图中不能包含权值为负值的环路 事实上，最短路径也不能包含权重为正值的环路（无效环路），只要删去该环路，就可以得到一个更短的路径 松弛： 维持节点的最短路径估计属性 过程：首先测试是否可以对两个节点的最短路径进行改善，测试方法是：将一个节点到中间节点加上中间节点到另一个节点的值与当前值进行比较，如果更小则更新节点的该属性值 Dijkstra算法和用于有向无环图的最短路径算法对每条边仅仅松弛一次，Bellman——Ford算法对每条边松弛节点数减一次 Bellman——Ford算法： Bellman——Ford算法通过对边进行松弛操作，来渐进的降低从源节点到每个节点的最短路径的估计值， 先对图进行拓扑排序。。降低时间复杂度 Dijkstra算法：（贪心算法） Dijkstra算法要求所有的边的权重是非负 Dijkstra算法在运行过程中维持的关键信息是一组节点集合，从源节点到该集合中的每个节点之间的最短路径都已经找到，使用一个最小优先队列来保存节点集合 四、树4.1 最小生成树最小生成树问题： 对于带有权重的图，找到一个无环子集，既能够将所有的节点连接起来，又使其具有最小的权重 两种最小生成树算法：（贪心算法） kruskal算法 prim算法 kruskal算法： 集合a是一个森林，每次加入到集合a中的安全边永远是权重最小的连接两个不同分量的边 prim算法： 集合a是一棵树，每次加入a中的安全边是连接a与a之外的某个节点的边权重最小的 使用一个最小优先队列，算法结束时，最小优先队列为空 4.2二叉树二叉搜索树上所花费的时间与这棵树的高度成正比 区分树的高度和深度 二叉搜索树： 左子树中的关键字的值小于根节点中关键字的值，右子树中关键字的值大于根节点中关键字的值 二叉搜索树的遍历： 先序遍历 中序遍历 后序遍历 其中序是指根节点的位置 二叉搜索树的查找 迭代比递归更加高效 比较关键字的值，大于向右，小于向左 插入和删除： 插入类似于查找，即查找到一个空的合适的位置，将该节点插入 删除则分为三种情况 将删除的节点没有孩子节点，直接删除 将删除的节点只有一个孩子节点，将这个孩子提升到将删除节点的位置，并修改将删除节点的父节点， 将删除的节点有两个孩子节点，查找将要删除节点的后继，并让该后继占据将要删除的节点的位置，让将删除节点的右子树部分成为那个后继的新的右子树，并且将删除节点的左子树成为那个后继的新的左子树 红黑树： 红黑树保证没有一条路径会比其它路径长出两倍，是近似平衡的，平衡二叉树是绝对平衡的 红黑树性质： 每个节点是红色的或者是黑色的 根节点是黑色的 每个叶节点是黑色的 如果一个节点是红色的，那么它的两个子节点是黑色的 对于每个节点，从该节点到其所有后代叶节点的简单路径上，均包含数目相同的黑色节点数，成为黑高 红黑树的旋转： 左旋和右旋 左旋是靠左边的节点下滑，夺取右子树的左子树作为自己的右子树，同时自己从新成为右子树的左子树 右旋是靠右边的节点下滑，夺取左子树的右子树作为自己的左子树，同事自己从新成为左子树的右子树 红黑树的插入： 红黑树的性质2或者4被破坏 插入的节点首先着色为红色 为保持红黑树的性质，调用辅助程序对红黑树的节点重新着色并进行旋转 红黑树的删除： 删除节点之后，调用辅助程序通过改变颜色和执行旋转来恢复红黑树性质 如果删除的节点是红色，则不需要对树进行恢复","tags":[{"name":"算法导论","slug":"算法导论","permalink":"https://www.delta1037.cn/tags/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA/"}]},{"title":"Hexo+Github搭建博客","date":"2017-08-07T16:00:00.000Z","path":"2017/Deploy/Hexo+Github搭建博客/","text":"花费了将近十个小时,查阅了上百篇资料,终于搭建好了自己的第一个博客,就以这第一篇博客纪念我走过的坑 预览网站 2023.0218：补充更新内容 一、注册GitHubGithub官网创建账户登录之后，新建一个名称为账户名.github.io的代码仓库，可以通过http://&lt;username&gt;.github.io来访问你的个人主页 二、安装基础环境2.1 Linux Linux版本太过久远，现在命令可能变化了 环境 系统版本：Ubuntu 17.04 安装Git使用以下命令 1$ sudo apt-get install git 检查版本 1$ git --version 安装Node.js 可以选择从官网的源码安装 从NodeSource安装 12345# 以 sudo 用户身份运行下面的命令，下载并执行 NodeSource 安装脚本$ curl -sL https://deb.nodesource.com/setup_14.x | sudo -E bash -# 安装 Node.jssudo apt install nodejs 检查版本 1$ node -v 安装npm执行命令： 1$ sudo apt-get install npm 2.2 Window Window上使用powershell作为终端环境 nvmwindow上使用nvm来管理nodejs的版本 主要命令： 123456789# 安装指定版本的nosdejsnvm install v12.14# 使用指定版本的nodejsnvm use v12.14# 列出所有版本的nodejs（前边带 * 的是当前正在使用的）nvm list# 其它命令使用方法如下命令查看nvm /? nodejs安装好之后，npm也自动一并安装了 三、Hexo配置安装hexo安装命令： 1$ npm install hexo-cli -g 博客初始化根目录： 1$ hexo init #初始化博客所在根目录 一些常用命令： 12$ hexo g #或者hexo generate //生成静态页面$ hexo s #或者hexo server 本地查看 打开http://localhost:4000/已经可以看到一篇内置的blog了 123$ hexo d #或者hexo deploy //部署博客到远程$ hexo new &quot;postName&quot; #新建文章$ hexo new page &quot;pageName&quot; #新建页面 本地查看hexo s命令可能出现错误，使用如下命令可以解决 1$ hexo s -s 更换主题(eg:yilia)12$ cd /blog/themes #切换到主题目录$ git clone https://github.com/litten/hexo-theme-yilia.git themes/yilia #克隆主题到本地,可以在github上搜索主题,替换相应链接就可以了 修改Hexo目录下的_config.yml配置文件中的theme属性，将其设置为yilia(根据主题名称设定) 使用hexo deploy部署如将代码部署到github，在配置文件 _config.xml中作如下修改： 1234deploy: type: git repo: git@github.com:&lt;**yourname&gt;**/&lt;**yourname&gt;**.github.io.git branch: master 使用如下命令,即可完成部署,即可在github上创建的仓库里看到代码 1$ hexo d 该处需要安装一个拓展 1$ npm install hexo-deployer-git --save 绑定域名在source目录下新建一个名为CNAME的文件，文件内填域名即可 参考 参考链接: - 令狐葱@前端笔记","tags":[{"name":"博客搭建","slug":"博客搭建","permalink":"https://www.delta1037.cn/tags/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"}]},{"title":"LAMP+WordPress搭建网站","date":"2017-08-07T16:00:00.000Z","path":"2017/Deploy/LAMP+WordPress搭建网站/","text":"LAMP+WordPress搭建博客网站 搭建LAMP（Linux, Apache, MySQL, PHP）环境安装Apache12sudo apt-get updatesudo apt-get install apache2 安装完成之后在浏览器页面输入http://your_server_IP_address可以看到Apache的配置页面 安装数据库MySQL1sudo apt-get install mysql-server php7.0-mysql 首先，我们要让MySQL创建它的存储信息的数据库目录结构，输入以下命令 1sudo mysql_install_db 然后运行一个简单的安全脚本，它会移除一些危险的默认的配置 1sudo mysql_secure_installation 它将会要求输入root密码，然后问是否想要修改密码，如果对现在的密码满意，就输入n或者no；对于剩下的问题，只需要enter键接受默认的配置就可以，这将会移除一些样例用户和数据库，使远程root登录不可用，并且加载这些新的规则来做出我们所做的更新 安装PHP安装 1sudo apt-get install php7.0 libapache2-mod-php7.0 php7.0-mcrypt 更改dir.conf文件： 1sudo nano /etc/apache2/mods-enabled/dir.conf 更改前： 123&lt;IfModule mod_dir.c&gt; DirectoryIndex index.html index.cgi index.pl index.php index.xhtml index.htm&lt;/IfModule&gt; 更改后：&lt;其中只是移动了ingdex.php的位置&gt; 123&lt;IfModule mod_dir.c&gt; DirectoryIndex index.php index.html index.cgi index.pl index.xhtml index.htm&lt;/IfModule&gt; 重启Apache： 1sudo service apache2 restart 测试PHP模块：创建新的文件 1sudo nano /var/www/html/info.php 输入文件内容 123&lt;?phpphpinfo();?&gt; 打开http://your_server_IP_address/info.php 查看测试结果，注意删除这个文件 text1sudo rm /var/www/html/info.php 安装Wordpress创建数据库用户登录数据库 1mysql -u root -p 创建新的用户，用户名假设为Wordpress 1CREATE DATABASE wordpress; 创建一个数据库用户 1CREATE USER wordpressuser@localhost IDENTIFIED BY &#x27;password&#x27;; 给这个用户新数据库的使用权 1GRANT ALL PRIVILEGES ON wordpress.* TO wordpressuser@localhost; 使操作生效并退出 12FLUSH PRIVILEGES;exit 下载WordPress并配置切换到～目录并获得WordPress的最新版本 12cd ~wget http://wordpress.org/latest.tar.gz 解压该文件 1tar xzvf latest.tar.gz 下载一些安装包 12sudo apt-get updatesudo apt-get install php7.0-gd libssh2-php 复制一个配置文件的副本 1cp wp-config-sample.php wp-config.php 获得安全秘钥 1curl -s https://api.wordpress.org/secret-key/1.1/salt/ 会得到类似的输出&lt;警告：不要拷贝下面的！！&gt; 12345678define(&#x27;AUTH_KEY&#x27;, &#x27;1jl/vqfs&lt;XhdXoAPz9 DO NOT COPY THESE VALUES c_j&#123;iwqD^&lt;+c9.k&lt;J@4H&#x27;);define(&#x27;SECURE_AUTH_KEY&#x27;, &#x27;E2N-h2]Dcvp+aS/p7X DO NOT COPY THESE VALUES &#123;Ka(f;rv?Pxf&#125;)CgLi-3&#x27;);define(&#x27;LOGGED_IN_KEY&#x27;, &#x27;W(50,&#123;W^,OPB%PB&lt;JF DO NOT COPY THESE VALUES 2;y&amp;,2m%3]R6DUth[;88&#x27;);define(&#x27;NONCE_KEY&#x27;, &#x27;ll,4UC)7ua+8&lt;!4VM+ DO NOT COPY THESE VALUES #`DXF+[$atzM7 o^-C7g&#x27;);define(&#x27;AUTH_SALT&#x27;, &#x27;koMrurzOA+|L_lG&#125;kf DO NOT COPY THESE VALUES 07VC*Lj*lD&amp;?3w!BT#-&#x27;);define(&#x27;SECURE_AUTH_SALT&#x27;, &#x27;p32*p,]z%LZ+7pAu:VY DO NOT COPY THESE VALUES C-?y+K0DK_+F|0h&#123;!_xY&#x27;);4define(&#x27;LOGGED_IN_SALT&#x27;, &#x27;i^/G2W7!-H2OQ+t$3 DO NOT COPY THESE VALUES t6**bRVFSD[Hi])-qS`|&#x27;);define(&#x27;NONCE_SALT&#x27;, &#x27;Q6]U:K?j4L%Z]&#125;h^q7 DO NOT COPY THESE VALUES 1%^qUswWgn+6&amp;xqHN&amp;%&#x27;); 打开配置文件 1nano wp-config.php 将秘钥替换配置中类似的位置 找到关于 DB_NAME, DB_USER, 和 DB_PASSWORD 的设置，并填写相应的刚刚配置数据库的信息 123456789// ** MySQL settings - You can get this info from your web host ** ///** The name of the database for WordPress */define(&#x27;DB_NAME&#x27;, &#x27;wordpress&#x27;);/** MySQL database username */define(&#x27;DB_USER&#x27;, &#x27;wordpressuser&#x27;);/** MySQL database password */define(&#x27;DB_PASSWORD&#x27;, &#x27;password&#x27;); 拷贝文件到根目录 1sudo rsync -avP ~/wordpress/ /var/www/html/ 更改文件的权限 1sudo chown -R demo:www-data * 创建上传目录并赋相应的权限 12mkdir /var/www/html/wp-content/uploadssudo chown -R :www-data /var/www/html/wp-content/uploads 完成安装并查看网站并完成最后的配置，打开网站地址：http://server_domain_name_or_IP 允许Apache使用固定连接功能编辑000-default.conf 1sudo nano /etc/apache2/sites-available/000-default.conf 做如下更改 12345678&lt;VirtualHost *:80&gt; ServerAdmin webmaster@localhost DocumentRoot /var/www/html ServerName server_domain_name_or_IP &lt;Directory /var/www/html/&gt; AllowOverride All &lt;/Directory&gt; . . . 重新启动部件 12//sudo a2enmod rewritesudo service apache2 restart 创建.htaccess文件 1touch /var/www/html/.htaccess 赋相应权限 1sudo chown :www-data /var/www/html/.htaccess 如果想要Wordpress自动更新这个文件 1chmod 664 /var/www/html/.htaccess If you want to update this file manually for the sake of a small security gain, you can allow the web server only read privileges by typing: 1chmod 644 /var/www/html/.htaccess 网站在不同vps之间的迁移VPS1上数据打包（备份）文件数据打包12cd /home/wwwroot/tar zcvf xxx.tar.gz 网站目录（如/home/wwwroot/vmvps.com） MySQL数据导出1mysqldump -u用户名 -p密码 数据库名 &gt; xxx.sql VPS2上数据转移（恢复）文件数据恢复（wget获取远程文件）123cd /home/wwwroot/wget http://www.xxx.com/xxx.tar.gz（从VPS1上获取文件）tar zxvf xxx.tar.gz MySQL数据导入 请先在phpmyadmin新建相应数据库和用户（与原数据库、用户同名）&lt;若不同名则有可能出现数据库连接错误&gt; 12wget http://www.xxx.com/xxx.sqlmysql -u你新建的用户名 -p用户名密码 你刚才新建的数据库名 &lt; xxx.sql 参考链接 How To Install Wordpress on Ubuntu 14.04 How To Install Linux, Apache, MySQL, PHP (LAMP) stack on Ubuntu 14.04 VPS之间网站数据的备份与恢复（网站迁移教程）【微魔部落原创】","tags":[{"name":"博客搭建","slug":"博客搭建","permalink":"https://www.delta1037.cn/tags/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"}]},{"title":"Git笔记","date":"2017-08-07T16:00:00.000Z","path":"2017/Project/Git笔记/","text":"Git笔记 参考链接:阮一峰的网络日志 基本概念:工作区:电脑里能看到的目录 暂存区(索引):.git目录下的index文件 版本库:隐藏的目录.git 创建仓库12345678#使用当前目录,初始化仓库$ git init# 新建一个目录，将其初始化为Git代码库$ git init [project-name]# 下载一个项目和它的整个代码历史$ git clone [url] 配置123456789# 显示当前的Git配置$ git config --list# 编辑Git配置文件$ git config -e [--global]# 设置提交代码时的用户信息$ git config [--global] user.name &quot;[name]&quot;$ git config [--global] user.email &quot;[email address]&quot; 增加删除文件123456789101112131415161718192021# 添加指定文件到暂存区$ git add [file1] [file2] ...# 添加指定目录到暂存区，包括子目录$ git add [dir]# 添加当前目录的所有文件到暂存区$ git add .# 添加每个变化前，都会要求确认# 对于同一个文件的多处变化，可以实现分次提交$ git add -p# 删除工作区文件，并且将这次删除放入暂存区$ git rm [file1] [file2] ...# 停止追踪指定文件，但该文件会保留在工作区$ git rm --cached [file]# 改名文件，并且将这个改名放入暂存区$ git mv [file-original] [file-renamed] 提交代码123456789101112131415161718# 提交暂存区到仓库区$ git commit -m [message]# 提交暂存区的指定文件到仓库区$ git commit [file1] [file2] ... -m [message]# 提交工作区自上次commit之后的变化，直接到仓库区$ git commit -a# 提交时显示所有diff信息$ git commit -v# 使用一次新的commit，替代上一次提交# 如果代码没有任何新变化，则用来改写上一次commit的提交信息$ git commit --amend -m [message]# 重做上一次commit，并包括指定文件的新变化$ git commit --amend [file1] [file2] ... 分支123456789101112131415161718192021222324252627282930313233343536373839404142#列出所有本地分支$ git branch#列出所有远程分支$ git branch -r#列出所有本地分支和远程分支$ git branch -a#新建一个分支，但依然停留在当前分支$ git branch [branch-name]#新建一个分支，并切换到该分支$ git checkout -b [branch]#新建一个分支，指向指定commit$ git branch [branch] [commit]#新建一个分支，与指定的远程分支建立追踪关系$ git branch --track [branch] [remote-branch]#切换到指定分支，并更新工作区$ git checkout [branch-name]#切换到上一个分支$ git checkout -#建立追踪关系，在现有分支与指定的远程分支之间$ git branch --set-upstream [branch] [remote-branch]#合并指定分支到当前分支$ git merge [branch]#选择一个commit，合并进当前分支$ git cherry-pick [commit]#删除分支$ git branch -d [branch-name]#删除远程分支$ git push origin --delete [branch-name]$ git branch -dr [remote/branch] 标签1234567891011121314151617181920212223242526# 列出所有tag$ git tag# 新建一个tag在当前commit$ git tag [tag]# 新建一个tag在指定commit$ git tag [tag] [commit]# 删除本地tag$ git tag -d [tag]# 删除远程tag$ git push origin :refs/tags/[tagName]# 查看tag信息$ git show [tag]# 提交指定tag$ git push [remote] [tag]# 提交所有tag$ git push [remote] --tags# 新建一个分支，指向某个tag$ git checkout -b [branch] [tag] 查看信息123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960# 显示有变更的文件$ git status# 显示当前分支的版本历史$ git log# 显示commit历史，以及每次commit发生变更的文件$ git log --stat# 搜索提交历史，根据关键词$ git log -S [keyword]# 显示某个commit之后的所有变动，每个commit占据一行$ git log [tag] HEAD --pretty=format:%s# 显示某个commit之后的所有变动，其&quot;提交说明&quot;必须符合搜索条件$ git log [tag] HEAD --grep feature# 显示某个文件的版本历史，包括文件改名$ git log --follow [file]$ git whatchanged [file]# 显示指定文件相关的每一次diff$ git log -p [file]# 显示过去5次提交$ git log -5 --pretty --oneline# 显示所有提交过的用户，按提交次数排序$ git shortlog -sn# 显示指定文件是什么人在什么时间修改过$ git blame [file]# 显示暂存区和工作区的差异$ git diff# 显示暂存区和上一个commit的差异$ git diff --cached [file]# 显示工作区与当前分支最新commit之间的差异$ git diff HEAD# 显示两次提交之间的差异$ git diff [first-branch]...[second-branch]# 显示今天你写了多少行代码$ git diff --shortstat &quot;@&#123;0 day ago&#125;&quot;# 显示某次提交的元数据和内容变化$ git show [commit]# 显示某次提交发生变化的文件$ git show --name-only [commit]# 显示某次提交时，某个文件的内容$ git show [commit]:[filename]# 显示当前分支的最近几次提交$ git reflog 远程同步1234567891011121314151617181920212223# 下载远程仓库的所有变动$ git fetch [remote]# 显示所有远程仓库$ git remote -v# 显示某个远程仓库的信息$ git remote show [remote]# 增加一个新的远程仓库，并命名$ git remote add [shortname] [url]# 取回远程仓库的变化，并与本地分支合并$ git pull [remote] [branch]# 上传本地指定分支到远程仓库$ git push [remote] [branch]# 强行推送当前分支到远程仓库，即使有冲突$ git push [remote] --force# 推送所有分支到远程仓库$ git push [remote] --all 撤销12345678910111213141516171819202122232425262728293031# 恢复暂存区的指定文件到工作区$ git checkout [file]# 恢复某个commit的指定文件到暂存区和工作区$ git checkout [commit] [file]# 恢复暂存区的所有文件到工作区$ git checkout .# 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变$ git reset [file]# 重置暂存区与工作区，与上一次commit保持一致$ git reset --hard# 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变$ git reset [commit]# 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致$ git reset --hard [commit]# 重置当前HEAD为指定commit，但保持暂存区和工作区不变$ git reset --keep [commit]# 新建一个commit，用来撤销指定commit# 后者的所有变化都将被前者抵消，并且应用到当前分支$ git revert [commit]# 暂时将未提交的变化移除，稍后再移入$ git stash$ git stash pop 其它12# 生成一个可供发布的压缩包$ git archive emmm。。。1$ git checkout . / git checkout--&lt;file&gt; #会用暂存区全部或者指定文件替换工作区的文件.危险操作! 会清除工作区中未添加到暂存区的活动 12$ git checkout HEAD . / git checkout HEAD &lt;file&gt; #会用HEAD指向的master分支中的全部或者部分文件替换暂存区以及工作区中的文件. #**危险操作******! 不但会清除工作区中未提交的改动,也会清除暂存区中未提交的改动 Git服务器自己搭建一台Git服务器作为私有仓库使用 因吹斯听…have a try","tags":[{"name":"Git","slug":"Git","permalink":"https://www.delta1037.cn/tags/Git/"}]}]